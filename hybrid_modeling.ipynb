{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module P2H_CapacityExpansion.\n",
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/git`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "include(\"./P2H_CapacityExpansion.jl\")\n",
    "cd(\"/cluster/home/danare/git\")\n",
    "Pkg.activate(\".\")\n",
    "using .P2H_CapacityExpansion\n",
    "using DataFrames\n",
    "using Parameters\n",
    "using Flux\n",
    "using Surrogates\n",
    "using ScikitLearn\n",
    "using LinearAlgebra, Random, Statistics\n",
    "using JuMP\n",
    "using XLSX\n",
    "using MathOptAI\n",
    "using PlotlyJS\n",
    "using Ipopt\n",
    "using Clustering\n",
    "using CSV\n",
    "using Dates\n",
    "using StatsBase, MultivariateStats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/cluster/home/danare/git/P2H_CapacityExpansion/results/500_scenarios_V3.txt\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file = \"/cluster/home/danare/git/P2H_CapacityExpansion/results/500_scenarios_V3.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 15)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = P2H_CapacityExpansion.read_txt_file(file);\n",
    "df = select(df, Not(:ENS))\n",
    "size(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split the Data into Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = P2H_CapacityExpansion.partitionTrainTest(df, [:Cost,:Generation, :Emission], 0.7)\n",
    "\n",
    "### scale the data ###\n",
    "X_train_scaled, ŒºX, œÉX  = P2H_CapacityExpansion.scaling(X_train)\n",
    "X_test_scaled = (X_test .- ŒºX) ./ œÉX\n",
    "y_train_scaled, Œºy, œÉy  = P2H_CapacityExpansion.scaling(y_train)\n",
    "    \n",
    "# remove np.nan #\n",
    "for i in eachindex(X_test_scaled)\n",
    "    if isnan(X_test_scaled[i])\n",
    "        X_test_scaled[i] = 0.0\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train the Surrogate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚îå Warning: Layer with Float32 parameters got Float64 input.\n",
      "‚îÇ   The input will be converted, but any earlier layers may be very slow.\n",
      "‚îÇ   layer = Dense(12 => 500, relu)\n",
      "‚îÇ   summary(x) = 12√ó32 Matrix{Float64}\n",
      "‚îî @ Flux /cluster/home/danare/.julia/packages/Flux/hiqg1/src/layers/stateless.jl:60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1 : Training loss = 0.2235748562321015, R2 score : 0.9687247801882584\n",
      "Epoch = 2 : Training loss = 0.162899993193753, R2 score : 0.9848429962732638\n",
      "Epoch = 3 : Training loss = 0.13074388488791194, R2 score : 0.9923484146040519\n",
      "Epoch = 4 : Training loss = 0.11316863062894518, R2 score : 0.9917783925790882\n",
      "Epoch = 5 : Training loss = 0.09759323065157448, R2 score : 0.9948492982929152\n",
      "Epoch = 6 : Training loss = 0.0939522445638875, R2 score : 0.9945241232773744\n",
      "Epoch = 7 : Training loss = 0.0893676149295337, R2 score : 0.9946388730421675\n",
      "Epoch = 8 : Training loss = 0.08404186551152454, R2 score : 0.9938131335807555\n",
      "Epoch = 9 : Training loss = 0.080763129915028, R2 score : 0.9955717679892564\n",
      "Epoch = 10 : Training loss = 0.085121162531885, R2 score : 0.9954227607742229\n",
      "Epoch = 11 : Training loss = 0.07375674937440521, R2 score : 0.9965179476705324\n",
      "Epoch = 12 : Training loss = 0.07710580484262741, R2 score : 0.9960374897428491\n",
      "Epoch = 13 : Training loss = 0.07502724095637286, R2 score : 0.9958519008893562\n",
      "Epoch = 14 : Training loss = 0.07242793181787222, R2 score : 0.99595831106106\n",
      "Epoch = 15 : Training loss = 0.07077982871158661, R2 score : 0.9945295863487116\n",
      "Epoch = 16 : Training loss = 0.07251228972923403, R2 score : 0.995089260626803\n",
      "Epoch = 17 : Training loss = 0.06854802350538058, R2 score : 0.99633201145693\n",
      "Epoch = 18 : Training loss = 0.07035942355213268, R2 score : 0.9962712604530564\n",
      "Epoch = 19 : Training loss = 0.06635907419617063, R2 score : 0.9970528330731849\n",
      "Epoch = 20 : Training loss = 0.06932397197443918, R2 score : 0.9950315738049341\n",
      "Epoch = 21 : Training loss = 0.06520545449741777, R2 score : 0.9954891196774687\n",
      "Epoch = 22 : Training loss = 0.06275235901952214, R2 score : 0.9962624385941892\n",
      "Epoch = 23 : Training loss = 0.06628926023771754, R2 score : 0.9958050664540455\n",
      "Epoch = 24 : Training loss = 0.06699027576465137, R2 score : 0.996608713768524\n",
      "Epoch = 25 : Training loss = 0.0606999953660158, R2 score : 0.9968490870600201\n",
      "Epoch = 26 : Training loss = 0.06409177746296549, R2 score : 0.9972118029530511\n",
      "Epoch = 27 : Training loss = 0.06059738202404199, R2 score : 0.9971857230619925\n",
      "Epoch = 28 : Training loss = 0.07391146507615184, R2 score : 0.996158846392452\n",
      "Epoch = 29 : Training loss = 0.059772089234234424, R2 score : 0.9971527523453777\n",
      "Epoch = 30 : Training loss = 0.058109748381323496, R2 score : 0.9970638874394615\n",
      "Epoch = 31 : Training loss = 0.055230084667549834, R2 score : 0.9975163650624504\n",
      "Epoch = 32 : Training loss = 0.06555201988563121, R2 score : 0.9970478621703689\n",
      "Epoch = 33 : Training loss = 0.05682893455273134, R2 score : 0.9975760907621516\n",
      "Epoch = 34 : Training loss = 0.05978767243703845, R2 score : 0.9969920784545883\n",
      "Epoch = 35 : Training loss = 0.056114546731980304, R2 score : 0.9975162107510178\n",
      "Epoch = 36 : Training loss = 0.0610328943728428, R2 score : 0.9973252391820479\n",
      "Epoch = 37 : Training loss = 0.05887335665146288, R2 score : 0.9977528435734102\n",
      "Epoch = 38 : Training loss = 0.054587401281011486, R2 score : 0.9978409500206337\n",
      "Epoch = 39 : Training loss = 0.06770059846668329, R2 score : 0.997349586222096\n",
      "Epoch = 40 : Training loss = 0.06178543057231669, R2 score : 0.9968561692330236\n",
      "Epoch = 41 : Training loss = 0.05516508215240609, R2 score : 0.9979724012562365\n",
      "Epoch = 42 : Training loss = 0.058472992132622394, R2 score : 0.9974819556779988\n",
      "Epoch = 43 : Training loss = 0.0560253400421605, R2 score : 0.9971376012554439\n",
      "Epoch = 44 : Training loss = 0.06579897386658813, R2 score : 0.9969854276659648\n",
      "Epoch = 45 : Training loss = 0.05544545916893589, R2 score : 0.9970268267442461\n",
      "Epoch = 46 : Training loss = 0.049292978277765014, R2 score : 0.9973118321027531\n",
      "Epoch = 47 : Training loss = 0.04988790007410736, R2 score : 0.9975571676597116\n",
      "Epoch = 48 : Training loss = 0.05411563892626046, R2 score : 0.9972805193721621\n",
      "Epoch = 49 : Training loss = 0.05051189490985599, R2 score : 0.9980182915522845\n",
      "Epoch = 50 : Training loss = 0.04944290600715495, R2 score : 0.9969861345322868\n",
      "Epoch = 51 : Training loss = 0.051444393493178475, R2 score : 0.9976651399698867\n",
      "Epoch = 52 : Training loss = 0.04893101564146425, R2 score : 0.9978546533784834\n",
      "Epoch = 53 : Training loss = 0.0540340510281073, R2 score : 0.99654115786503\n",
      "Epoch = 54 : Training loss = 0.053711336839994954, R2 score : 0.9973187041416502\n",
      "Epoch = 55 : Training loss = 0.054110796969875835, R2 score : 0.997870984756449\n",
      "Epoch = 56 : Training loss = 0.052858486995654395, R2 score : 0.9976534830503315\n",
      "Epoch = 57 : Training loss = 0.05788519692470332, R2 score : 0.9974874871908874\n",
      "Epoch = 58 : Training loss = 0.049369899477881785, R2 score : 0.9977374993451418\n",
      "Epoch = 59 : Training loss = 0.052372873088517055, R2 score : 0.9971273468886082\n",
      "Epoch = 60 : Training loss = 0.05296222566053516, R2 score : 0.9974819671053623\n",
      "Epoch = 61 : Training loss = 0.05642104589082106, R2 score : 0.9975471939386409\n",
      "Epoch = 62 : Training loss = 0.04980593397346591, R2 score : 0.9973770364928634\n",
      "Epoch = 63 : Training loss = 0.0533943257154549, R2 score : 0.9977759246511787\n",
      "Epoch = 64 : Training loss = 0.04709716186363836, R2 score : 0.9974795089313474\n",
      "Epoch = 65 : Training loss = 0.045763560894291, R2 score : 0.9976698336450199\n",
      "Epoch = 66 : Training loss = 0.051665964666490594, R2 score : 0.9976282301415413\n",
      "Epoch = 67 : Training loss = 0.05000186516689976, R2 score : 0.9980247271602797\n",
      "Epoch = 68 : Training loss = 0.05280487437919648, R2 score : 0.997015991142502\n",
      "Epoch = 69 : Training loss = 0.046660455976059174, R2 score : 0.9973547586606469\n",
      "Epoch = 70 : Training loss = 0.053562640645459285, R2 score : 0.9976736966297766\n",
      "Epoch = 71 : Training loss = 0.05396818285594512, R2 score : 0.997761424779534\n",
      "Epoch = 72 : Training loss = 0.04785655067995476, R2 score : 0.9979490534273586\n",
      "Epoch = 73 : Training loss = 0.043790679309333974, R2 score : 0.997704850012328\n",
      "Epoch = 74 : Training loss = 0.04712950025246338, R2 score : 0.9976157200984813\n",
      "Epoch = 75 : Training loss = 0.04445257331413685, R2 score : 0.9979515679799466\n",
      "Epoch = 76 : Training loss = 0.05233309926488159, R2 score : 0.9978949074481842\n",
      "Epoch = 77 : Training loss = 0.058524681036813866, R2 score : 0.9970520362728611\n",
      "Epoch = 78 : Training loss = 0.048922043531174145, R2 score : 0.9978230759023518\n",
      "Epoch = 79 : Training loss = 0.04708124137349305, R2 score : 0.9981907702960203\n",
      "Epoch = 80 : Training loss = 0.04865948132591728, R2 score : 0.9982802856664842\n",
      "Epoch = 81 : Training loss = 0.05780067861175502, R2 score : 0.9978973394458809\n",
      "Epoch = 82 : Training loss = 0.044252339326505956, R2 score : 0.9979965712717112\n",
      "Epoch = 83 : Training loss = 0.04799071260374273, R2 score : 0.9979070376710129\n",
      "Epoch = 84 : Training loss = 0.0515329450221012, R2 score : 0.9980915456199746\n",
      "Epoch = 85 : Training loss = 0.04608318275970491, R2 score : 0.9977453912826024\n",
      "Epoch = 86 : Training loss = 0.04492708165158156, R2 score : 0.9980729369213034\n",
      "Epoch = 87 : Training loss = 0.045034542682560255, R2 score : 0.9981387420564459\n",
      "Epoch = 88 : Training loss = 0.04545939037632275, R2 score : 0.9980905724081442\n",
      "Epoch = 89 : Training loss = 0.04563572730966883, R2 score : 0.998206606099619\n",
      "Epoch = 90 : Training loss = 0.04708318534650676, R2 score : 0.9978428508393111\n",
      "Epoch = 91 : Training loss = 0.046686802296479916, R2 score : 0.9981166414134701\n",
      "Epoch = 92 : Training loss = 0.04590949193892797, R2 score : 0.9980735757092836\n",
      "Epoch = 93 : Training loss = 0.05229795058293782, R2 score : 0.9979438816877915\n",
      "Epoch = 94 : Training loss = 0.0456681962044595, R2 score : 0.9978795887067742\n",
      "Epoch = 95 : Training loss = 0.04519372946613484, R2 score : 0.9977295545241968\n",
      "Epoch = 96 : Training loss = 0.04419317776992207, R2 score : 0.9976212980927335\n",
      "Epoch = 97 : Training loss = 0.046023772632215125, R2 score : 0.9980408725145768\n",
      "Epoch = 98 : Training loss = 0.04393960323030017, R2 score : 0.9980984403242694\n",
      "Epoch = 99 : Training loss = 0.054104425949033606, R2 score : 0.9976292687983905\n",
      "Epoch = 100 : Training loss = 0.04951991714584104, R2 score : 0.9974994778284065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Main.P2H_CapacityExpansion.Surrogate(Chain(Dense(12 => 500, relu), Dense(500 => 3)), Float32[-0.09269529 0.023661204 0.5819961; -0.093335144 0.054316446 0.59909123; ‚Ä¶ ; -0.103215314 0.08897336 0.62995565; -0.21935277 -0.19978185 0.8653148])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### train ML model and compute R2 ### \n",
    "sg = P2H_CapacityExpansion.neural_network_model_flux(X_train_scaled, y_train_scaled, X_test_scaled, y_test, œÉy, Œºy; hidden_layer=500, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Read the Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚îå Info: Each time-series is averaged in 5-hourly steps\n",
      "‚îî @ Main.P2H_CapacityExpansion /cluster/home/danare/git/P2H_CapacityExpansion/utils/load_data.jl:76\n"
     ]
    }
   ],
   "source": [
    "# load input\n",
    "config = P2H_CapacityExpansion.read_yaml_file();\n",
    "data = P2H_CapacityExpansion.load_cep_data(config=config);\n",
    "ts_data = P2H_CapacityExpansion.load_timeseries_data_full(config=config);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Instantiate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚îå Info: Reading the data ...\n",
      "‚îî @ Main.P2H_CapacityExpansion /cluster/home/danare/git/P2H_CapacityExpansion/src/opt.jl:19\n",
      "‚îå Info: Investment mode is on.\n",
      "‚îî @ Main.P2H_CapacityExpansion /cluster/home/danare/git/P2H_CapacityExpansion/src/opt.jl:88\n"
     ]
    }
   ],
   "source": [
    "cep = P2H_CapacityExpansion.run_opt(ts_data=ts_data, data=data, config=config, surrogate=true, solver=Ipopt.Optimizer)\n",
    "\n",
    "@unpack ùìñ, ùì®, ùì£, ùì°, ùì¢, ùìõ, ùìí = P2H_CapacityExpansion.get_sets(cep=cep)\n",
    "\n",
    "##################### cost optimization #####################\n",
    "\n",
    "P2H_CapacityExpansion.setup_opt_costs_fix!(cep, config, data.data,vcat(cep.sets[\"non_dispatch\"], cep.sets[\"dispatch\"], ùì¢, String[s for s in cep.sets[\"discharging\"]], cep.sets[\"conversion\"]))\n",
    "\n",
    "#JuMP.fix.(cep.model[:COST][\"var\", :, :], 0; force=true);\n",
    "@variable(cep.model, COST_VAR[y ‚àà ùì®] ‚â• 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Embedd the Surogate into the Optimization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "techs = [f for f ‚àà cep.sets[\"invest_tech\"] if f != \"ENS\"]\n",
    "\n",
    "for y ‚àà ùì®, r ‚àà ùì°\n",
    "    x_vec = [cep.model[:TotalCapacityAnnual][r, g, y] for g ‚àà techs]\n",
    "    x_scaled = (x_vec ) #.- ŒºX) ./ œÉX\n",
    "    prediction, formulation = MathOptAI.add_predictor(cep.model, sg.model, x_scaled)\n",
    "    y_rescaled = prediction #.* œÉy .+ Œºy\n",
    "\n",
    "    ##### Cost approximation ###\n",
    "    @constraint(cep.model, COST_VAR[y] .>= y_rescaled[1])\n",
    "\n",
    "    ##### Generation  ###\n",
    "    #TODO H2 and electricity combined as sum\n",
    "    @constraint(cep.model, y_rescaled[2] .>= data.data[\"demand\"][r,y,\"electricity\"] + data.data[\"demand\"][r,y,\"H2\"])\n",
    "\n",
    "    ##### Emission reduction  ###\n",
    "    @constraint(cep.model, sum(data.data[\"budget\"][r,y] for r ‚àà ùì°).>= y_rescaled[3] )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ 1.4802442849183444 COST_{cap,2030,P\\_Wind\\_Offshore\\_Transitional} + 1.4802442849183444 COST_{cap,2030,S\\_Battery\\_Li-Ion} + 1.4802442849183444 COST_{cap,2030,P\\_Wind\\_Onshore\\_Avg} + 1.4802442849183444 COST_{cap,2030,X\\_Electrolysis} + 1.4802442849183444 COST_{cap,2030,trans\\_H2} + 1.4802442849183444 COST_{cap,2030,P\\_PV\\_Utility\\_Avg} + 1.4802442849183444 COST_{cap,2030,P\\_Gas\\_CCGT} + 1.4802442849183444 COST_{cap,2030,D\\_Gas\\_H2\\_out} + 1.4802442849183444 COST_{cap,2030,trans\\_elec} + 1.4802442849183444 COST_{cap,2030,D\\_Battery\\_Li-Ion\\_out} + 1.4802442849183444 COST_{cap,2030,ENS} + 1.4802442849183444 COST_{cap,2030,P\\_Biomass} + 1.4802442849183444 COST_{cap,2030,S\\_Gas\\_H2} + 1.4802442849183444 COST_{cap,2030,P\\_H2\\_OCGT} + 1.4802442849183444 COST_{cap,2030,X\\_ATR\\_CCS} + COST_{cap,2040,P\\_Wind\\_Offshore\\_Transitional} + COST_{cap,2040,S\\_Battery\\_Li-Ion} + COST_{cap,2040,P\\_Wind\\_Onshore\\_Avg} + COST_{cap,2040,X\\_Electrolysis} + COST_{cap,2040,trans\\_H2} + COST_{cap,2040,P\\_PV\\_Utility\\_Avg} + COST_{cap,2040,P\\_Gas\\_CCGT} + COST_{cap,2040,D\\_Gas\\_H2\\_out} + COST_{cap,2040,trans\\_elec} + COST_{cap,2040,D\\_Battery\\_Li-Ion\\_out} + COST_{cap,2040,ENS} + COST_{cap,2040,P\\_Biomass} + COST_{cap,2040,S\\_Gas\\_H2} + COST_{cap,2040,P\\_H2\\_OCGT} + COST_{cap,2040,X\\_ATR\\_CCS} + [[\\ldots\\text{60 terms omitted}\\ldots]] + COST_{fix,2040,P\\_H2\\_OCGT} + COST_{fix,2040,S\\_PHS} + COST_{fix,2040,D\\_Battery\\_Li-Ion\\_in} + COST_{fix,2040,X\\_ATR\\_CCS} + COST\\_VAR_{2040} + 0.6755641688257986 COST_{fix,2050,P\\_Wind\\_Offshore\\_Transitional} + 0.6755641688257986 COST_{fix,2050,S\\_Battery\\_Li-Ion} + 0.6755641688257986 COST_{fix,2050,D\\_Hydro\\_Reservoir\\_out} + 0.6755641688257986 COST_{fix,2050,P\\_Wind\\_Onshore\\_Avg} + 0.6755641688257986 COST_{fix,2050,X\\_Electrolysis} + 0.6755641688257986 COST_{fix,2050,trans\\_H2} + 0.6755641688257986 COST_{fix,2050,P\\_PV\\_Utility\\_Avg} + 0.6755641688257986 COST_{fix,2050,P\\_Coal\\_Hardcoal} + 0.6755641688257986 COST_{fix,2050,P\\_Gas\\_CCGT} + 0.6755641688257986 COST_{fix,2050,D\\_Gas\\_H2\\_out} + 0.6755641688257986 COST_{fix,2050,S\\_Hydro\\_Reservoir} + 0.6755641688257986 COST_{fix,2050,trans\\_elec} + 0.6755641688257986 COST_{fix,2050,D\\_Gas\\_H2\\_in} + 0.6755641688257986 COST_{fix,2050,P\\_Nuclear} + 0.6755641688257986 COST_{fix,2050,D\\_Battery\\_Li-Ion\\_out} + 0.6755641688257986 COST_{fix,2050,D\\_PHS\\_in} + 0.6755641688257986 COST_{fix,2050,ENS} + 0.6755641688257986 COST_{fix,2050,D\\_PHS\\_out} + 0.6755641688257986 COST_{fix,2050,P\\_Biomass} + 0.6755641688257986 COST_{fix,2050,S\\_Gas\\_H2} + 0.6755641688257986 COST_{fix,2050,P\\_H2\\_OCGT} + 0.6755641688257986 COST_{fix,2050,S\\_PHS} + 0.6755641688257986 COST_{fix,2050,D\\_Battery\\_Li-Ion\\_in} + 0.6755641688257986 COST_{fix,2050,X\\_ATR\\_CCS} + 0.6755641688257986 COST\\_VAR_{2050} $"
      ],
      "text/plain": [
       "1.4802442849183444 COST[cap,2030,P_Wind_Offshore_Transitional] + 1.4802442849183444 COST[cap,2030,S_Battery_Li-Ion] + 1.4802442849183444 COST[cap,2030,P_Wind_Onshore_Avg] + 1.4802442849183444 COST[cap,2030,X_Electrolysis] + 1.4802442849183444 COST[cap,2030,trans_H2] + 1.4802442849183444 COST[cap,2030,P_PV_Utility_Avg] + 1.4802442849183444 COST[cap,2030,P_Gas_CCGT] + 1.4802442849183444 COST[cap,2030,D_Gas_H2_out] + 1.4802442849183444 COST[cap,2030,trans_elec] + 1.4802442849183444 COST[cap,2030,D_Battery_Li-Ion_out] + 1.4802442849183444 COST[cap,2030,ENS] + 1.4802442849183444 COST[cap,2030,P_Biomass] + 1.4802442849183444 COST[cap,2030,S_Gas_H2] + 1.4802442849183444 COST[cap,2030,P_H2_OCGT] + 1.4802442849183444 COST[cap,2030,X_ATR_CCS] + COST[cap,2040,P_Wind_Offshore_Transitional] + COST[cap,2040,S_Battery_Li-Ion] + COST[cap,2040,P_Wind_Onshore_Avg] + COST[cap,2040,X_Electrolysis] + COST[cap,2040,trans_H2] + COST[cap,2040,P_PV_Utility_Avg] + COST[cap,2040,P_Gas_CCGT] + COST[cap,2040,D_Gas_H2_out] + COST[cap,2040,trans_elec] + COST[cap,2040,D_Battery_Li-Ion_out] + COST[cap,2040,ENS] + COST[cap,2040,P_Biomass] + COST[cap,2040,S_Gas_H2] + COST[cap,2040,P_H2_OCGT] + COST[cap,2040,X_ATR_CCS] + [[...60 terms omitted...]] + COST[fix,2040,P_H2_OCGT] + COST[fix,2040,S_PHS] + COST[fix,2040,D_Battery_Li-Ion_in] + COST[fix,2040,X_ATR_CCS] + COST_VAR[2040] + 0.6755641688257986 COST[fix,2050,P_Wind_Offshore_Transitional] + 0.6755641688257986 COST[fix,2050,S_Battery_Li-Ion] + 0.6755641688257986 COST[fix,2050,D_Hydro_Reservoir_out] + 0.6755641688257986 COST[fix,2050,P_Wind_Onshore_Avg] + 0.6755641688257986 COST[fix,2050,X_Electrolysis] + 0.6755641688257986 COST[fix,2050,trans_H2] + 0.6755641688257986 COST[fix,2050,P_PV_Utility_Avg] + 0.6755641688257986 COST[fix,2050,P_Coal_Hardcoal] + 0.6755641688257986 COST[fix,2050,P_Gas_CCGT] + 0.6755641688257986 COST[fix,2050,D_Gas_H2_out] + 0.6755641688257986 COST[fix,2050,S_Hydro_Reservoir] + 0.6755641688257986 COST[fix,2050,trans_elec] + 0.6755641688257986 COST[fix,2050,D_Gas_H2_in] + 0.6755641688257986 COST[fix,2050,P_Nuclear] + 0.6755641688257986 COST[fix,2050,D_Battery_Li-Ion_out] + 0.6755641688257986 COST[fix,2050,D_PHS_in] + 0.6755641688257986 COST[fix,2050,ENS] + 0.6755641688257986 COST[fix,2050,D_PHS_out] + 0.6755641688257986 COST[fix,2050,P_Biomass] + 0.6755641688257986 COST[fix,2050,S_Gas_H2] + 0.6755641688257986 COST[fix,2050,P_H2_OCGT] + 0.6755641688257986 COST[fix,2050,S_PHS] + 0.6755641688257986 COST[fix,2050,D_Battery_Li-Ion_in] + 0.6755641688257986 COST[fix,2050,X_ATR_CCS] + 0.6755641688257986 COST_VAR[2050]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opex_discounted = sum(\n",
    "    1 / ((1 + config[\"r\"])^(y - ùì®[1] - 10)) * (\n",
    "        sum(cep.model[:COST][\"fix\", y, g] for g ‚àà ùìñ) +\n",
    "        COST_VAR[y]\n",
    "    ) for y ‚àà ùì®\n",
    ")\n",
    "\n",
    "@objective(cep.model, Min, sum(\n",
    "    1 / ((1 + config[\"r\"])^(y - ùì®[1] - 10)) *\n",
    "    sum(cep.model[:COST][\"cap\", y, g] for g ‚àà cep.sets[\"invest_all\"])\n",
    "    for y ‚àà ùì® \n",
    ") + opex_discounted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = P2H_CapacityExpansion.optimize_and_output(cep=cep, config=config, data=data, ts_data=ts_data, name=\"scenario_v3\", short_sol=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{VariableRef}:\n",
       " moai_Affine[1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total variables: 6369\n"
     ]
    },
    {
     "ename": "UndefKeywordError",
     "evalue": "UndefKeywordError: keyword argument `count_variable_in_set_constraints` not assigned",
     "output_type": "error",
     "traceback": [
      "UndefKeywordError: keyword argument `count_variable_in_set_constraints` not assigned\n",
      "\n",
      "Stacktrace:\n",
      " [1] num_constraints(model::Model)\n",
      "   @ JuMP ~/.julia/packages/JuMP/LKjRR/src/constraints.jl:1716\n",
      " [2] top-level scope\n",
      "   @ ~/git/P2H_CapacityExpansion/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X20sdnNjb2RlLXJlbW90ZQ==.jl:2"
     ]
    }
   ],
   "source": [
    "println(\"Total variables: \", JuMP.num_variables(cep.model))\n",
    "println(\"Total constraints: \", JuMP.num_constraints(cep.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VariableRef\u001b[90m (alias for \u001b[39m\u001b[90mGenericVariableRef{Float64}\u001b[39m\u001b[90m)\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "typeof(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
