{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module P2H_CapacityExpansion.\n",
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/git`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "include(\"./P2H_CapacityExpansion.jl\")\n",
    "cd(\"/cluster/home/danare/git\")\n",
    "Pkg.activate(\".\")\n",
    "using .P2H_CapacityExpansion\n",
    "using JuMP, MathOptAI\n",
    "using DataFrames\n",
    "using ScikitLearn\n",
    "using JuMP\n",
    "using Ipopt\n",
    "using MathOptAI\n",
    "using Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/cluster/home/danare/git/P2H_CapacityExpansion/results/aggregated_results/500_scenarios.txt\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file = \"/cluster/home/danare/git/P2H_CapacityExpansion/results/aggregated_results/500_scenarios.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1391, 13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = P2H_CapacityExpansion.read_txt_file(file);\n",
    "size(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split the Data into Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = P2H_CapacityExpansion.partitionTrainTest(df, :Cost, 0.8)\n",
    "\n",
    "### scale the data ###\n",
    "X_train_scaled, μX, σX  = P2H_CapacityExpansion.scaling(X_train)\n",
    "X_test_scaled = (X_test .- μX) ./ σX\n",
    "y_train_scaled, μy, σy  = P2H_CapacityExpansion.scaling(y_train)\n",
    "    \n",
    "# remove np.nan #\n",
    "for i in eachindex(X_test_scaled)\n",
    "    if isnan(X_test_scaled[i])\n",
    "        X_test_scaled[i] = 0.0\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1 : Training loss = 4477.265735886937, R2 score : -0.1075189418118685\n",
      "Epoch = 2 : Training loss = 4666.618991447867, R2 score : -0.10314121529647391\n",
      "Epoch = 3 : Training loss = 4384.643487633775, R2 score : -0.09166871894016348\n",
      "Epoch = 4 : Training loss = 4263.7224153860225, R2 score : -0.07875303492545616\n",
      "Epoch = 5 : Training loss = 4019.186645233374, R2 score : -0.060220234469183564\n",
      "Epoch = 6 : Training loss = 3788.941315944246, R2 score : -0.0338087262505542\n",
      "Epoch = 7 : Training loss = 3686.355745698158, R2 score : -0.010893152511065596\n",
      "Epoch = 8 : Training loss = 3580.14036805574, R2 score : 0.010668380663022559\n",
      "Epoch = 9 : Training loss = 3538.3563376533257, R2 score : 0.02726994874705535\n",
      "Epoch = 10 : Training loss = 3437.268941946542, R2 score : 0.049943405449826894\n",
      "Epoch = 11 : Training loss = 3369.190586625243, R2 score : 0.07150092358139959\n",
      "Epoch = 12 : Training loss = 3346.5887908521345, R2 score : 0.09033549768096372\n",
      "Epoch = 13 : Training loss = 3242.3296565973073, R2 score : 0.11524397395210872\n",
      "Epoch = 14 : Training loss = 3170.360911913913, R2 score : 0.14053303877428103\n",
      "Epoch = 15 : Training loss = 3155.0885110381696, R2 score : 0.16376256412530932\n",
      "Epoch = 16 : Training loss = 3042.029973709326, R2 score : 0.19207500916774845\n",
      "Epoch = 17 : Training loss = 3021.1788232377967, R2 score : 0.21919807473315778\n",
      "Epoch = 18 : Training loss = 2990.86669872476, R2 score : 0.24920342328898415\n",
      "Epoch = 19 : Training loss = 2778.008792113352, R2 score : 0.2809264422803892\n",
      "Epoch = 20 : Training loss = 2748.8169810326517, R2 score : 0.3057543620667431\n",
      "Epoch = 21 : Training loss = 2648.804461691877, R2 score : 0.34268094362629586\n",
      "Epoch = 22 : Training loss = 2499.9536288179083, R2 score : 0.3759899995551885\n",
      "Epoch = 23 : Training loss = 2386.8724271650794, R2 score : 0.41168433721197695\n",
      "Epoch = 24 : Training loss = 2345.8222774376945, R2 score : 0.44844470166078\n",
      "Epoch = 25 : Training loss = 2229.350951285671, R2 score : 0.47641560171215236\n",
      "Epoch = 26 : Training loss = 2186.440051572786, R2 score : 0.5057310409727294\n",
      "Epoch = 27 : Training loss = 2069.4762723793497, R2 score : 0.5275197003729879\n",
      "Epoch = 28 : Training loss = 1982.6710622190571, R2 score : 0.5493047133493655\n",
      "Epoch = 29 : Training loss = 1985.4457601094418, R2 score : 0.5657576847679509\n",
      "Epoch = 30 : Training loss = 1927.6399959754601, R2 score : 0.5729257845937876\n",
      "Epoch = 31 : Training loss = 1959.3589841161165, R2 score : 0.5828674574750768\n",
      "Epoch = 32 : Training loss = 1864.1873529746244, R2 score : 0.5977927726648209\n",
      "Epoch = 33 : Training loss = 1868.9760115369618, R2 score : 0.6034908078740863\n",
      "Epoch = 34 : Training loss = 1825.400130996601, R2 score : 0.6124082050062798\n",
      "Epoch = 35 : Training loss = 1821.3845321737606, R2 score : 0.6210139859139501\n",
      "Epoch = 36 : Training loss = 2102.755957514262, R2 score : 0.6260165722964108\n",
      "Epoch = 37 : Training loss = 2005.3836968854177, R2 score : 0.6375042764842778\n",
      "Epoch = 38 : Training loss = 1806.086225814367, R2 score : 0.6459948796450714\n",
      "Epoch = 39 : Training loss = 1810.7811331989096, R2 score : 0.6548126368524148\n",
      "Epoch = 40 : Training loss = 1738.4430263848612, R2 score : 0.6604912638225623\n",
      "Epoch = 41 : Training loss = 1722.827112993748, R2 score : 0.6667974992433983\n",
      "Epoch = 42 : Training loss = 1757.5525462520209, R2 score : 0.6680728987989106\n",
      "Epoch = 43 : Training loss = 1709.643428678993, R2 score : 0.6764386560700772\n",
      "Epoch = 44 : Training loss = 1709.8949327993093, R2 score : 0.6766269633408981\n",
      "Epoch = 45 : Training loss = 1779.0153729829856, R2 score : 0.6793718606522781\n",
      "Epoch = 46 : Training loss = 1723.397867439462, R2 score : 0.6866824664191008\n",
      "Epoch = 47 : Training loss = 1675.4280789876157, R2 score : 0.6932828814601618\n",
      "Epoch = 48 : Training loss = 1662.6225316301525, R2 score : 0.6913509500858366\n",
      "Epoch = 49 : Training loss = 1750.4327433469484, R2 score : 0.6934709300733557\n",
      "Epoch = 50 : Training loss = 1652.1669986368083, R2 score : 0.7021114707266529\n",
      "Epoch = 51 : Training loss = 1641.862271075626, R2 score : 0.7070503958902685\n",
      "Epoch = 52 : Training loss = 1684.8739126173498, R2 score : 0.70899808773711\n",
      "Epoch = 53 : Training loss = 1692.3627604940277, R2 score : 0.7120360942245613\n",
      "Epoch = 54 : Training loss = 1611.5801680791292, R2 score : 0.7156625483690424\n",
      "Epoch = 55 : Training loss = 1747.8805167932305, R2 score : 0.7204000348188736\n",
      "Epoch = 56 : Training loss = 1696.5689363827487, R2 score : 0.7219089087702197\n",
      "Epoch = 57 : Training loss = 1649.544586730518, R2 score : 0.7256074538210919\n",
      "Epoch = 58 : Training loss = 1706.9084196047818, R2 score : 0.7224567153890613\n",
      "Epoch = 59 : Training loss = 1573.354411776975, R2 score : 0.7338403641626283\n",
      "Epoch = 60 : Training loss = 1576.208137347544, R2 score : 0.7339263879949663\n",
      "Epoch = 61 : Training loss = 1568.560379083208, R2 score : 0.7385707314049559\n",
      "Epoch = 62 : Training loss = 1557.793019034022, R2 score : 0.7395321780291306\n",
      "Epoch = 63 : Training loss = 1617.552781136023, R2 score : 0.7430103283081544\n",
      "Epoch = 64 : Training loss = 1575.6417845581932, R2 score : 0.7482634020490639\n",
      "Epoch = 65 : Training loss = 1558.304152628072, R2 score : 0.7495752020924225\n",
      "Epoch = 66 : Training loss = 1540.5438089713775, R2 score : 0.7503717628808628\n",
      "Epoch = 67 : Training loss = 1536.7249863370716, R2 score : 0.755362695152997\n",
      "Epoch = 68 : Training loss = 1582.4293479096118, R2 score : 0.7572518589170559\n",
      "Epoch = 69 : Training loss = 1638.4609280044226, R2 score : 0.7590213441844917\n",
      "Epoch = 70 : Training loss = 1510.9657849304967, R2 score : 0.7634767311278486\n",
      "Epoch = 71 : Training loss = 1572.2994261953256, R2 score : 0.7633781233304358\n",
      "Epoch = 72 : Training loss = 1656.343770630497, R2 score : 0.7662744634741037\n",
      "Epoch = 73 : Training loss = 1496.5507860935206, R2 score : 0.76914620583478\n",
      "Epoch = 74 : Training loss = 1490.3688327828756, R2 score : 0.7715538901330965\n",
      "Epoch = 75 : Training loss = 1525.4808657549643, R2 score : 0.7723005267582898\n",
      "Epoch = 76 : Training loss = 1493.9402047157716, R2 score : 0.7781793627594961\n",
      "Epoch = 77 : Training loss = 1547.9371060823364, R2 score : 0.7771239766179954\n",
      "Epoch = 78 : Training loss = 1482.7467566992311, R2 score : 0.7787212857863202\n",
      "Epoch = 79 : Training loss = 1537.398474165004, R2 score : 0.7803995053869056\n",
      "Epoch = 80 : Training loss = 1520.987926743871, R2 score : 0.7815561977535803\n",
      "Epoch = 81 : Training loss = 1540.0526766648395, R2 score : 0.7816090439924119\n",
      "Epoch = 82 : Training loss = 1517.447168693268, R2 score : 0.7810830106834843\n",
      "Epoch = 83 : Training loss = 1467.4506021317818, R2 score : 0.7826755539875007\n",
      "Epoch = 84 : Training loss = 1480.5754551544464, R2 score : 0.7816462786085338\n",
      "Epoch = 85 : Training loss = 1442.8901874435892, R2 score : 0.7835505318526133\n",
      "Epoch = 86 : Training loss = 1485.4894711806191, R2 score : 0.7840570931755735\n",
      "Epoch = 87 : Training loss = 1430.112483262158, R2 score : 0.7871066904298339\n",
      "Epoch = 88 : Training loss = 1483.5077376370218, R2 score : 0.7863519832744368\n",
      "Epoch = 89 : Training loss = 1621.263321934844, R2 score : 0.7877202871477437\n",
      "Epoch = 90 : Training loss = 1469.877949611746, R2 score : 0.788673380425414\n",
      "Epoch = 91 : Training loss = 1586.41956515964, R2 score : 0.7899985426855447\n",
      "Epoch = 92 : Training loss = 1474.7729138984955, R2 score : 0.788563315899897\n",
      "Epoch = 93 : Training loss = 1483.685980389605, R2 score : 0.7922038237351561\n",
      "Epoch = 94 : Training loss = 1429.3075430015865, R2 score : 0.7939304009675248\n",
      "Epoch = 95 : Training loss = 1405.7947755880493, R2 score : 0.7948172380189213\n",
      "Epoch = 96 : Training loss = 1598.2512226516394, R2 score : 0.7967944273523393\n",
      "Epoch = 97 : Training loss = 1589.172435837684, R2 score : 0.7946830879299738\n",
      "Epoch = 98 : Training loss = 1405.5458084482084, R2 score : 0.7974580744362609\n",
      "Epoch = 99 : Training loss = 1407.264908346341, R2 score : 0.8032247799368437\n",
      "Epoch = 100 : Training loss = 1448.3109121391242, R2 score : 0.8020592416864922\n",
      "Epoch = 101 : Training loss = 1390.2429883350358, R2 score : 0.8007950460067645\n",
      "Epoch = 102 : Training loss = 1393.930219746322, R2 score : 0.8017648079654329\n",
      "Epoch = 103 : Training loss = 1424.1383276191548, R2 score : 0.8034242074667111\n",
      "Epoch = 104 : Training loss = 1422.2915690108705, R2 score : 0.80243675268967\n",
      "Epoch = 105 : Training loss = 1401.5264858582036, R2 score : 0.8032124151906062\n",
      "Epoch = 106 : Training loss = 1513.9225112268393, R2 score : 0.8049862352272465\n",
      "Epoch = 107 : Training loss = 1515.687642441379, R2 score : 0.8002302143170049\n",
      "Epoch = 108 : Training loss = 1449.414862507378, R2 score : 0.8061283391555405\n",
      "Epoch = 109 : Training loss = 1368.321504614336, R2 score : 0.8097621307093776\n",
      "Epoch = 110 : Training loss = 1400.5505375962891, R2 score : 0.8091144789089878\n",
      "Epoch = 111 : Training loss = 1373.0814528430967, R2 score : 0.8064132346300267\n",
      "Epoch = 112 : Training loss = 1356.790686025894, R2 score : 0.8082090071482773\n",
      "Epoch = 113 : Training loss = 1396.8118042019632, R2 score : 0.8086432268914718\n",
      "Epoch = 114 : Training loss = 1442.6913519934785, R2 score : 0.8099912423839178\n",
      "Epoch = 115 : Training loss = 1363.5711782442258, R2 score : 0.8110697896926904\n",
      "Epoch = 116 : Training loss = 1347.9107141529055, R2 score : 0.8086879573545389\n",
      "Epoch = 117 : Training loss = 1392.2409643132053, R2 score : 0.8109672410582103\n",
      "Epoch = 118 : Training loss = 1341.9280461055769, R2 score : 0.811546748629553\n",
      "Epoch = 119 : Training loss = 1393.7911998265618, R2 score : 0.8119551156980381\n",
      "Epoch = 120 : Training loss = 1352.47522601764, R2 score : 0.8109792022219435\n",
      "Epoch = 121 : Training loss = 1361.2414668897072, R2 score : 0.8130642860291725\n",
      "Epoch = 122 : Training loss = 1352.4619412525094, R2 score : 0.8154283356164066\n",
      "Epoch = 123 : Training loss = 1394.44372948771, R2 score : 0.8130585376764309\n",
      "Epoch = 124 : Training loss = 1415.1534746685902, R2 score : 0.8102081913814454\n",
      "Epoch = 125 : Training loss = 1477.0862831143168, R2 score : 0.8116680449079747\n",
      "Epoch = 126 : Training loss = 1342.700913678399, R2 score : 0.8173803419707288\n",
      "Epoch = 127 : Training loss = 1366.2916639108453, R2 score : 0.8168552880829256\n",
      "Epoch = 128 : Training loss = 1321.9611106802233, R2 score : 0.8182255705531611\n",
      "Epoch = 129 : Training loss = 1392.8307421279253, R2 score : 0.8150951110382503\n",
      "Epoch = 130 : Training loss = 1329.7762868147101, R2 score : 0.8162378181683707\n",
      "Epoch = 131 : Training loss = 1378.7333574168545, R2 score : 0.8157047905371226\n",
      "Epoch = 132 : Training loss = 1351.354219745389, R2 score : 0.8145100532462738\n",
      "Epoch = 133 : Training loss = 1442.0643752118667, R2 score : 0.817477534764495\n",
      "Epoch = 134 : Training loss = 1364.1229737334006, R2 score : 0.8184054449260524\n",
      "Epoch = 135 : Training loss = 1379.3317817582501, R2 score : 0.8165105790449408\n",
      "Epoch = 136 : Training loss = 1300.9211444580299, R2 score : 0.8192874115362216\n",
      "Epoch = 137 : Training loss = 1397.4723438564822, R2 score : 0.8190928015151798\n",
      "Epoch = 138 : Training loss = 1305.2212833745016, R2 score : 0.8193268437634592\n",
      "Epoch = 139 : Training loss = 1309.044522673106, R2 score : 0.818485124036753\n",
      "Epoch = 140 : Training loss = 1452.752499269067, R2 score : 0.8164377037271138\n",
      "Epoch = 141 : Training loss = 1400.4028255682197, R2 score : 0.8167985702542488\n",
      "Epoch = 142 : Training loss = 1391.5539295416083, R2 score : 0.8170033070927791\n",
      "Epoch = 143 : Training loss = 1329.2181701951747, R2 score : 0.8199477938266478\n",
      "Epoch = 144 : Training loss = 1347.5621817304934, R2 score : 0.8194969137104741\n",
      "Epoch = 145 : Training loss = 1333.7155557046476, R2 score : 0.8189869577548189\n",
      "Epoch = 146 : Training loss = 1281.480724958877, R2 score : 0.8206641947295024\n",
      "Epoch = 147 : Training loss = 1395.2734966689734, R2 score : 0.8218669800864012\n",
      "Epoch = 148 : Training loss = 1579.021914729862, R2 score : 0.8205763364868974\n",
      "Epoch = 149 : Training loss = 1359.9262589906082, R2 score : 0.8218166817533441\n",
      "Epoch = 150 : Training loss = 1288.0245119050253, R2 score : 0.8203521763947795\n",
      "Epoch = 151 : Training loss = 1287.7157077617783, R2 score : 0.8202413558930544\n",
      "Epoch = 152 : Training loss = 1344.3438431170348, R2 score : 0.8211268148874203\n",
      "Epoch = 153 : Training loss = 1337.9926289894597, R2 score : 0.8192898646757143\n",
      "Epoch = 154 : Training loss = 1280.8960094848553, R2 score : 0.8181027239245765\n",
      "Epoch = 155 : Training loss = 1286.7032000512527, R2 score : 0.8188827530883833\n",
      "Epoch = 156 : Training loss = 1303.677593286089, R2 score : 0.8195989512300054\n",
      "Epoch = 157 : Training loss = 1288.2256428222004, R2 score : 0.8207154504277879\n",
      "Epoch = 158 : Training loss = 1315.2281285911906, R2 score : 0.8214891092781568\n",
      "Epoch = 159 : Training loss = 1305.745678771314, R2 score : 0.8212040230823403\n",
      "Epoch = 160 : Training loss = 1337.629395121293, R2 score : 0.8218149480720605\n",
      "Epoch = 161 : Training loss = 1253.2692114363472, R2 score : 0.8211196410638617\n",
      "Epoch = 162 : Training loss = 1312.8674448136803, R2 score : 0.8225889835690527\n",
      "Epoch = 163 : Training loss = 1310.8244217334034, R2 score : 0.8200423506600025\n",
      "Epoch = 164 : Training loss = 1269.0208096298381, R2 score : 0.8216530944011606\n",
      "Epoch = 165 : Training loss = 1273.5934495994513, R2 score : 0.8216790350432043\n",
      "Epoch = 166 : Training loss = 1263.5396691020444, R2 score : 0.8205063483643746\n",
      "Epoch = 167 : Training loss = 1268.5522893850537, R2 score : 0.8228107901681386\n",
      "Epoch = 168 : Training loss = 1391.7047045865504, R2 score : 0.8205786100839771\n",
      "Epoch = 169 : Training loss = 1261.3831496255862, R2 score : 0.820521829072047\n",
      "Epoch = 170 : Training loss = 1266.244926340074, R2 score : 0.8205667834781737\n",
      "Epoch = 171 : Training loss = 1278.7316871255423, R2 score : 0.8225388006389871\n",
      "Epoch = 172 : Training loss = 1408.303166790832, R2 score : 0.8226976065816138\n",
      "Epoch = 173 : Training loss = 1372.0633721128643, R2 score : 0.8219918580045151\n",
      "Epoch = 174 : Training loss = 1269.5558200595406, R2 score : 0.8220273484279886\n",
      "Epoch = 175 : Training loss = 1371.5199438959573, R2 score : 0.8245555722112672\n",
      "Epoch = 176 : Training loss = 1269.244907049824, R2 score : 0.8230471410907727\n",
      "Epoch = 177 : Training loss = 1300.5469677516883, R2 score : 0.8216850043919784\n",
      "Epoch = 178 : Training loss = 1304.54073097723, R2 score : 0.8247389042594818\n",
      "Epoch = 179 : Training loss = 1289.9383448979838, R2 score : 0.8235859298238231\n",
      "Epoch = 180 : Training loss = 1259.2653218897983, R2 score : 0.8211089398610236\n",
      "Epoch = 181 : Training loss = 1266.3945023790538, R2 score : 0.8217355345993934\n",
      "Epoch = 182 : Training loss = 1242.468528506567, R2 score : 0.8225653851431547\n",
      "Epoch = 183 : Training loss = 1245.090085255585, R2 score : 0.8207716350669388\n",
      "Epoch = 184 : Training loss = 1279.6490308951131, R2 score : 0.8192236635091396\n",
      "Epoch = 185 : Training loss = 1250.9317961768281, R2 score : 0.8242330218751192\n",
      "Epoch = 186 : Training loss = 1290.9281088190971, R2 score : 0.81949549555128\n",
      "Epoch = 187 : Training loss = 1266.9350183945712, R2 score : 0.8238800292133028\n",
      "Epoch = 188 : Training loss = 1272.1739920743291, R2 score : 0.8227705074973564\n",
      "Epoch = 189 : Training loss = 1266.3491559446716, R2 score : 0.8248333343640103\n",
      "Epoch = 190 : Training loss = 1249.4275911184523, R2 score : 0.8227989076836995\n",
      "Epoch = 191 : Training loss = 1373.4720136416045, R2 score : 0.8232022057682366\n",
      "Epoch = 192 : Training loss = 1273.0357557886796, R2 score : 0.8260617159504543\n",
      "Epoch = 193 : Training loss = 1314.163594966312, R2 score : 0.8253948741110619\n",
      "Epoch = 194 : Training loss = 1244.6982001645101, R2 score : 0.8273237868488261\n",
      "Epoch = 195 : Training loss = 1227.591059104144, R2 score : 0.825769578361479\n",
      "Epoch = 196 : Training loss = 1238.4225934598085, R2 score : 0.8250032176531467\n",
      "Epoch = 197 : Training loss = 1320.3523603892154, R2 score : 0.8245592733363989\n",
      "Epoch = 198 : Training loss = 1220.0996062326774, R2 score : 0.8245261504953991\n",
      "Epoch = 199 : Training loss = 1214.2917184769678, R2 score : 0.8265905926806296\n",
      "Epoch = 200 : Training loss = 1410.5273059477909, R2 score : 0.8262738891290585\n",
      "Epoch = 201 : Training loss = 1261.4883813650058, R2 score : 0.8231680320671781\n",
      "Epoch = 202 : Training loss = 1273.6569893367641, R2 score : 0.8269183221444217\n",
      "Epoch = 203 : Training loss = 1297.577379953947, R2 score : 0.8280105855721732\n",
      "Epoch = 204 : Training loss = 1216.5774598113067, R2 score : 0.8260883214566012\n",
      "Epoch = 205 : Training loss = 1221.1950452958079, R2 score : 0.8279851127437702\n",
      "Epoch = 206 : Training loss = 1203.717007510096, R2 score : 0.8285906576119917\n",
      "Epoch = 207 : Training loss = 1220.7607813822976, R2 score : 0.8289028138090908\n",
      "Epoch = 208 : Training loss = 1271.9402902863867, R2 score : 0.828484336016696\n",
      "Epoch = 209 : Training loss = 1231.3016805291818, R2 score : 0.828773702128591\n",
      "Epoch = 210 : Training loss = 1242.234445735705, R2 score : 0.828496696047143\n",
      "Epoch = 211 : Training loss = 1231.9221508948924, R2 score : 0.830397495293808\n",
      "Epoch = 212 : Training loss = 1242.1373958609088, R2 score : 0.8308443057175927\n",
      "Epoch = 213 : Training loss = 1332.0865629594102, R2 score : 0.8284653986574642\n",
      "Epoch = 214 : Training loss = 1236.9053309051683, R2 score : 0.8316242603775371\n",
      "Epoch = 215 : Training loss = 1314.9315494839236, R2 score : 0.8302613745787699\n",
      "Epoch = 216 : Training loss = 1255.2563993536312, R2 score : 0.8260717201927017\n",
      "Epoch = 217 : Training loss = 1258.5577364835165, R2 score : 0.8290302849131794\n",
      "Epoch = 218 : Training loss = 1234.993294959392, R2 score : 0.8265243918370165\n",
      "Epoch = 219 : Training loss = 1192.999965678016, R2 score : 0.833025945970918\n",
      "Epoch = 220 : Training loss = 1236.1716791777303, R2 score : 0.8333529217444436\n",
      "Epoch = 221 : Training loss = 1235.4910813366337, R2 score : 0.8325483506089287\n",
      "Epoch = 222 : Training loss = 1248.780410783754, R2 score : 0.830535918764144\n",
      "Epoch = 223 : Training loss = 1335.7527537174362, R2 score : 0.8309253293326971\n",
      "Epoch = 224 : Training loss = 1324.6599060339893, R2 score : 0.8301556813833482\n",
      "Epoch = 225 : Training loss = 1366.2609213410522, R2 score : 0.8277272887737668\n",
      "Epoch = 226 : Training loss = 1252.408421175943, R2 score : 0.8280036857115926\n",
      "Epoch = 227 : Training loss = 1229.4454678901666, R2 score : 0.8323497212838514\n",
      "Epoch = 228 : Training loss = 1196.9157087957258, R2 score : 0.8301834254132054\n",
      "Epoch = 229 : Training loss = 1269.8410312910733, R2 score : 0.8316091617525698\n",
      "Epoch = 230 : Training loss = 1202.5182929416355, R2 score : 0.8328296390755259\n",
      "Epoch = 231 : Training loss = 1193.560336760292, R2 score : 0.8308836954900269\n",
      "Epoch = 232 : Training loss = 1180.9905226230621, R2 score : 0.8326509344890931\n",
      "Epoch = 233 : Training loss = 1188.590029927681, R2 score : 0.8320838118541558\n",
      "Epoch = 234 : Training loss = 1303.2186472767548, R2 score : 0.830403084496968\n",
      "Epoch = 235 : Training loss = 1255.356472985082, R2 score : 0.8337649960199827\n",
      "Epoch = 236 : Training loss = 1218.5034863417097, R2 score : 0.8333700623041406\n",
      "Epoch = 237 : Training loss = 1186.6074383310277, R2 score : 0.8318129160652742\n",
      "Epoch = 238 : Training loss = 1208.6649314343072, R2 score : 0.8314686784393511\n",
      "Epoch = 239 : Training loss = 1264.5901849630068, R2 score : 0.8360831730010028\n",
      "Epoch = 240 : Training loss = 1268.5019100215152, R2 score : 0.8329282178173392\n",
      "Epoch = 241 : Training loss = 1243.4257508289043, R2 score : 0.8335099070863015\n",
      "Epoch = 242 : Training loss = 1184.2129855944956, R2 score : 0.8345975052748646\n",
      "Epoch = 243 : Training loss = 1221.4825951097896, R2 score : 0.8330514197972612\n",
      "Epoch = 244 : Training loss = 1397.9805462514753, R2 score : 0.8369517274213667\n",
      "Epoch = 245 : Training loss = 1521.120683464215, R2 score : 0.8301083963519746\n",
      "Epoch = 246 : Training loss = 1217.3131923538317, R2 score : 0.8359130771924286\n",
      "Epoch = 247 : Training loss = 1267.2390781238996, R2 score : 0.8328533281391468\n",
      "Epoch = 248 : Training loss = 1190.7824427018063, R2 score : 0.8353218744796737\n",
      "Epoch = 249 : Training loss = 1210.182268159531, R2 score : 0.8353821270809776\n",
      "Epoch = 250 : Training loss = 1189.6419084007791, R2 score : 0.8367009013082689\n",
      "Epoch = 251 : Training loss = 1209.716835563989, R2 score : 0.8365702182889485\n",
      "Epoch = 252 : Training loss = 1171.0025745861822, R2 score : 0.8352794065396478\n",
      "Epoch = 253 : Training loss = 1177.2434412198102, R2 score : 0.8334680118315525\n",
      "Epoch = 254 : Training loss = 1295.122902754185, R2 score : 0.8344275460376098\n",
      "Epoch = 255 : Training loss = 1222.9450428914681, R2 score : 0.8360880287721771\n",
      "Epoch = 256 : Training loss = 1177.906376831823, R2 score : 0.837753666889818\n",
      "Epoch = 257 : Training loss = 1174.6287683854214, R2 score : 0.8353851460702111\n",
      "Epoch = 258 : Training loss = 1184.3795399425699, R2 score : 0.8350774778366487\n",
      "Epoch = 259 : Training loss = 1243.0436774998261, R2 score : 0.8386858847757911\n",
      "Epoch = 260 : Training loss = 1195.7678488793133, R2 score : 0.8364243919727484\n",
      "Epoch = 261 : Training loss = 1169.8778110348064, R2 score : 0.836134014479493\n",
      "Epoch = 262 : Training loss = 1224.1122377785525, R2 score : 0.835595750126519\n",
      "Epoch = 263 : Training loss = 1195.7373057989766, R2 score : 0.8382025010818399\n",
      "Epoch = 264 : Training loss = 1218.6926380953344, R2 score : 0.8384445170624895\n",
      "Epoch = 265 : Training loss = 1268.9227385745523, R2 score : 0.8375271600868629\n",
      "Epoch = 266 : Training loss = 1265.0290831456082, R2 score : 0.8367173947601867\n",
      "Epoch = 267 : Training loss = 1367.94188764284, R2 score : 0.8393773041793051\n",
      "Epoch = 268 : Training loss = 1168.2978029997228, R2 score : 0.8366151317596827\n",
      "Epoch = 269 : Training loss = 1156.292249320651, R2 score : 0.8396013862935713\n",
      "Epoch = 270 : Training loss = 1294.9224491453856, R2 score : 0.8367657728103072\n",
      "Epoch = 271 : Training loss = 1182.2749451681864, R2 score : 0.8367322827105977\n",
      "Epoch = 272 : Training loss = 1192.4359911247122, R2 score : 0.8385070179591931\n",
      "Epoch = 273 : Training loss = 1192.9746277246543, R2 score : 0.8359599107756333\n",
      "Epoch = 274 : Training loss = 1190.8258371696197, R2 score : 0.839212293457861\n",
      "Epoch = 275 : Training loss = 1202.679726360513, R2 score : 0.8388118339624585\n",
      "Epoch = 276 : Training loss = 1258.459620702181, R2 score : 0.8393753771914045\n",
      "Epoch = 277 : Training loss = 1312.6304583789633, R2 score : 0.8421470771859536\n",
      "Epoch = 278 : Training loss = 1201.5921225444877, R2 score : 0.8383298077071768\n",
      "Epoch = 279 : Training loss = 1209.5223424966387, R2 score : 0.8407584809087616\n",
      "Epoch = 280 : Training loss = 1149.5741817591002, R2 score : 0.8392015603664903\n",
      "Epoch = 281 : Training loss = 1169.0178939747295, R2 score : 0.8400517896118738\n",
      "Epoch = 282 : Training loss = 1152.4907238423395, R2 score : 0.8404343213490002\n",
      "Epoch = 283 : Training loss = 1357.0944408255516, R2 score : 0.8343342023359148\n",
      "Epoch = 284 : Training loss = 1150.7385982613769, R2 score : 0.841770993659583\n",
      "Epoch = 285 : Training loss = 1283.829935801115, R2 score : 0.8406960833961085\n",
      "Epoch = 286 : Training loss = 1144.6455852590877, R2 score : 0.8415960672642578\n",
      "Epoch = 287 : Training loss = 1148.5563441609306, R2 score : 0.8414069593307166\n",
      "Epoch = 288 : Training loss = 1150.4622480028825, R2 score : 0.8415973272672295\n",
      "Epoch = 289 : Training loss = 1147.8389425127627, R2 score : 0.8422471817049645\n",
      "Epoch = 290 : Training loss = 1166.7912567862504, R2 score : 0.839968369346937\n",
      "Epoch = 291 : Training loss = 1261.15067527277, R2 score : 0.8400479442719283\n",
      "Epoch = 292 : Training loss = 1151.6026676078495, R2 score : 0.8430949308302401\n",
      "Epoch = 293 : Training loss = 1166.8161793441222, R2 score : 0.8395666173443371\n",
      "Epoch = 294 : Training loss = 1190.8315840040286, R2 score : 0.843149882090729\n",
      "Epoch = 295 : Training loss = 1309.3881238210115, R2 score : 0.8419742962031795\n",
      "Epoch = 296 : Training loss = 1140.823192306533, R2 score : 0.8411561724671058\n",
      "Epoch = 297 : Training loss = 1204.3349980124467, R2 score : 0.841897883919023\n",
      "Epoch = 298 : Training loss = 1164.7992389426172, R2 score : 0.8399793747281266\n",
      "Epoch = 299 : Training loss = 1197.62730692788, R2 score : 0.8428867355073986\n",
      "Epoch = 300 : Training loss = 1177.465959782223, R2 score : 0.8436511604457946\n",
      "Epoch = 301 : Training loss = 1133.8123693676303, R2 score : 0.8415140828457457\n",
      "Epoch = 302 : Training loss = 1159.06420978282, R2 score : 0.8398369591035482\n",
      "Epoch = 303 : Training loss = 1191.7211249029035, R2 score : 0.839230982018498\n",
      "Epoch = 304 : Training loss = 1230.0968762700506, R2 score : 0.844608272706774\n",
      "Epoch = 305 : Training loss = 1197.3196190902227, R2 score : 0.8418556101638353\n",
      "Epoch = 306 : Training loss = 1134.0869791782159, R2 score : 0.8442297344515246\n",
      "Epoch = 307 : Training loss = 1148.1082141142097, R2 score : 0.8438886044983481\n",
      "Epoch = 308 : Training loss = 1124.82179970514, R2 score : 0.8441483520058579\n",
      "Epoch = 309 : Training loss = 1128.8983645679282, R2 score : 0.8430290536575359\n",
      "Epoch = 310 : Training loss = 1152.450893717704, R2 score : 0.8429050330797754\n",
      "Epoch = 311 : Training loss = 1175.5352979666895, R2 score : 0.8430406219519571\n",
      "Epoch = 312 : Training loss = 1200.5982815807672, R2 score : 0.8467763153340278\n",
      "Epoch = 313 : Training loss = 1138.3113829369167, R2 score : 0.8463484232653133\n",
      "Epoch = 314 : Training loss = 1173.7821324694928, R2 score : 0.8406581086128346\n",
      "Epoch = 315 : Training loss = 1138.5820788907276, R2 score : 0.8440252696671977\n",
      "Epoch = 316 : Training loss = 1128.0907619599816, R2 score : 0.8450928299685544\n",
      "Epoch = 317 : Training loss = 1148.7203545741897, R2 score : 0.8450767734239502\n",
      "Epoch = 318 : Training loss = 1169.0902743219472, R2 score : 0.8452108757204245\n",
      "Epoch = 319 : Training loss = 1167.429251036198, R2 score : 0.8461300797940683\n",
      "Epoch = 320 : Training loss = 1244.7031220902, R2 score : 0.8460700887170218\n",
      "Epoch = 321 : Training loss = 1134.360677724262, R2 score : 0.8446261573311546\n",
      "Epoch = 322 : Training loss = 1138.6911331638157, R2 score : 0.8468224283420183\n",
      "Epoch = 323 : Training loss = 1124.9599213784547, R2 score : 0.8443463375335409\n",
      "Epoch = 324 : Training loss = 1144.4847343499712, R2 score : 0.8476453430019548\n",
      "Epoch = 325 : Training loss = 1109.1131077558873, R2 score : 0.8468694216880344\n",
      "Epoch = 326 : Training loss = 1120.4826518266375, R2 score : 0.8447115008084912\n",
      "Epoch = 327 : Training loss = 1139.3538486048471, R2 score : 0.8485069632042642\n",
      "Epoch = 328 : Training loss = 1138.1500712041375, R2 score : 0.84758266016448\n",
      "Epoch = 329 : Training loss = 1262.9189121215036, R2 score : 0.8477964177794687\n",
      "Epoch = 330 : Training loss = 1116.6120355695273, R2 score : 0.8464037914980755\n",
      "Epoch = 331 : Training loss = 1107.1567647920238, R2 score : 0.8467443743586424\n",
      "Epoch = 332 : Training loss = 1119.4007413653162, R2 score : 0.845825029086793\n",
      "Epoch = 333 : Training loss = 1226.853274324815, R2 score : 0.8470147811819583\n",
      "Epoch = 334 : Training loss = 1191.9303697047474, R2 score : 0.8501315896995423\n",
      "Epoch = 335 : Training loss = 1229.2514057433862, R2 score : 0.8468257951932407\n",
      "Epoch = 336 : Training loss = 1132.5937491419504, R2 score : 0.845956334843914\n",
      "Epoch = 337 : Training loss = 1191.2255729428298, R2 score : 0.8485425560245837\n",
      "Epoch = 338 : Training loss = 1260.331294985984, R2 score : 0.8469345286360215\n",
      "Epoch = 339 : Training loss = 1160.379088206257, R2 score : 0.848470415064627\n",
      "Epoch = 340 : Training loss = 1137.047371651629, R2 score : 0.8475165872246933\n",
      "Epoch = 341 : Training loss = 1133.7244990669567, R2 score : 0.847050766841974\n",
      "Epoch = 342 : Training loss = 1210.9651024830428, R2 score : 0.8468749804945611\n",
      "Epoch = 343 : Training loss = 1140.260922076891, R2 score : 0.8482549478603694\n",
      "Epoch = 344 : Training loss = 1227.7056863084972, R2 score : 0.851114574555453\n",
      "Epoch = 345 : Training loss = 1102.7966452592568, R2 score : 0.8460888111968767\n",
      "Epoch = 346 : Training loss = 1099.572669754783, R2 score : 0.8490282984929609\n",
      "Epoch = 347 : Training loss = 1133.2032377496898, R2 score : 0.8523586163516492\n",
      "Epoch = 348 : Training loss = 1110.9034310210523, R2 score : 0.8477344667542699\n",
      "Epoch = 349 : Training loss = 1134.5352683393219, R2 score : 0.8466550976096594\n",
      "Epoch = 350 : Training loss = 1108.6211917932085, R2 score : 0.8514151581261098\n",
      "Epoch = 351 : Training loss = 1139.5156891894856, R2 score : 0.8448697297930075\n",
      "Epoch = 352 : Training loss = 1178.5187916409948, R2 score : 0.852011608435073\n",
      "Epoch = 353 : Training loss = 1128.4900292869952, R2 score : 0.852308876316356\n",
      "Epoch = 354 : Training loss = 1164.407461865021, R2 score : 0.8491392778732751\n",
      "Epoch = 355 : Training loss = 1137.7679704350533, R2 score : 0.8496629143882173\n",
      "Epoch = 356 : Training loss = 1153.0837189585184, R2 score : 0.8481280952194041\n",
      "Epoch = 357 : Training loss = 1085.2310011519803, R2 score : 0.8504578294311934\n",
      "Epoch = 358 : Training loss = 1134.4636682743649, R2 score : 0.8514194894921362\n",
      "Epoch = 359 : Training loss = 1141.3926509610183, R2 score : 0.8515420883648839\n",
      "Epoch = 360 : Training loss = 1084.5169655744978, R2 score : 0.8512855428135704\n",
      "Epoch = 361 : Training loss = 1121.873851111467, R2 score : 0.8481313566915706\n",
      "Epoch = 362 : Training loss = 1147.8379329468708, R2 score : 0.852550531384815\n",
      "Epoch = 363 : Training loss = 1136.405335165614, R2 score : 0.8512110117302384\n",
      "Epoch = 364 : Training loss = 1109.5939825009957, R2 score : 0.8516934315732131\n",
      "Epoch = 365 : Training loss = 1220.8788530912332, R2 score : 0.8521337144876177\n",
      "Epoch = 366 : Training loss = 1176.4502514146216, R2 score : 0.8528292525219029\n",
      "Epoch = 367 : Training loss = 1087.6148288078446, R2 score : 0.8528514174687765\n",
      "Epoch = 368 : Training loss = 1122.5307071843592, R2 score : 0.8507193743178225\n",
      "Epoch = 369 : Training loss = 1103.8072461185695, R2 score : 0.8517644567430059\n",
      "Epoch = 370 : Training loss = 1093.6346523453005, R2 score : 0.8547714404810546\n",
      "Epoch = 371 : Training loss = 1087.5171328311344, R2 score : 0.8535607941801642\n",
      "Epoch = 372 : Training loss = 1095.2234475844198, R2 score : 0.852429467660453\n",
      "Epoch = 373 : Training loss = 1074.1104639176842, R2 score : 0.8544524200146142\n",
      "Epoch = 374 : Training loss = 1079.186388852785, R2 score : 0.8514418057500582\n",
      "Epoch = 375 : Training loss = 1072.9944549670322, R2 score : 0.8541598957802359\n",
      "Epoch = 376 : Training loss = 1082.259390563416, R2 score : 0.8491708598299024\n",
      "Epoch = 377 : Training loss = 1074.4638506319884, R2 score : 0.855210945271113\n",
      "Epoch = 378 : Training loss = 1131.3830600127899, R2 score : 0.8556521577765501\n",
      "Epoch = 379 : Training loss = 1171.3139829175184, R2 score : 0.8495815429554282\n",
      "Epoch = 380 : Training loss = 1071.6328158893173, R2 score : 0.8550836184552218\n",
      "Epoch = 381 : Training loss = 1072.521813835386, R2 score : 0.8517815150680423\n",
      "Epoch = 382 : Training loss = 1087.2185558689584, R2 score : 0.854948234922412\n",
      "Epoch = 383 : Training loss = 1135.4374343358356, R2 score : 0.8488367106118446\n",
      "Epoch = 384 : Training loss = 1064.1459456828002, R2 score : 0.8533901398970228\n",
      "Epoch = 385 : Training loss = 1158.985027774686, R2 score : 0.8525694988146826\n",
      "Epoch = 386 : Training loss = 1148.2184170198848, R2 score : 0.8545051457266504\n",
      "Epoch = 387 : Training loss = 1111.7425922660304, R2 score : 0.852752444763981\n",
      "Epoch = 388 : Training loss = 1071.5958067636482, R2 score : 0.8546292517721645\n",
      "Epoch = 389 : Training loss = 1084.6719970655956, R2 score : 0.8553576185721417\n",
      "Epoch = 390 : Training loss = 1059.8155042387598, R2 score : 0.8516199429900613\n",
      "Epoch = 391 : Training loss = 1088.3494882513132, R2 score : 0.8542914865349971\n",
      "Epoch = 392 : Training loss = 1055.6873789725544, R2 score : 0.8531842053789673\n",
      "Epoch = 393 : Training loss = 1070.385882806435, R2 score : 0.852441062031266\n",
      "Epoch = 394 : Training loss = 1074.0276480167033, R2 score : 0.8556454001437536\n",
      "Epoch = 395 : Training loss = 1073.1303502604258, R2 score : 0.8548904201121637\n",
      "Epoch = 396 : Training loss = 1060.432102950357, R2 score : 0.8541687384773751\n",
      "Epoch = 397 : Training loss = 1086.7483466992276, R2 score : 0.8541034174672382\n",
      "Epoch = 398 : Training loss = 1132.5861173928213, R2 score : 0.8539483186088813\n",
      "Epoch = 399 : Training loss = 1061.601859480357, R2 score : 0.8543185056488616\n",
      "Epoch = 400 : Training loss = 1150.7083234030406, R2 score : 0.8576086560569434\n",
      "Epoch = 401 : Training loss = 1046.7791914356699, R2 score : 0.8574148877182968\n",
      "Epoch = 402 : Training loss = 1034.7657555504668, R2 score : 0.8567234666023575\n",
      "Epoch = 403 : Training loss = 1068.7110413715993, R2 score : 0.8565928713160317\n",
      "Epoch = 404 : Training loss = 1043.1500809106894, R2 score : 0.8560840197510611\n",
      "Epoch = 405 : Training loss = 1050.4233437270568, R2 score : 0.8567599340864609\n",
      "Epoch = 406 : Training loss = 1050.5201816357296, R2 score : 0.8570936754303891\n",
      "Epoch = 407 : Training loss = 1056.7268647525807, R2 score : 0.8580088687013312\n",
      "Epoch = 408 : Training loss = 1074.8582402510608, R2 score : 0.8593739487192162\n",
      "Epoch = 409 : Training loss = 1063.2280439335666, R2 score : 0.8575606067637889\n",
      "Epoch = 410 : Training loss = 1033.808539467321, R2 score : 0.8593762836878074\n",
      "Epoch = 411 : Training loss = 1041.6173730685557, R2 score : 0.8578167615204731\n",
      "Epoch = 412 : Training loss = 1027.3635192740735, R2 score : 0.8602364259560837\n",
      "Epoch = 413 : Training loss = 1035.470290340108, R2 score : 0.856676608420763\n",
      "Epoch = 414 : Training loss = 1097.122320182032, R2 score : 0.8580957410044068\n",
      "Epoch = 415 : Training loss = 1107.1261399793002, R2 score : 0.8570533110039548\n",
      "Epoch = 416 : Training loss = 1018.4998274398365, R2 score : 0.8574336471583961\n",
      "Epoch = 417 : Training loss = 1044.0201724381755, R2 score : 0.8584659539798297\n",
      "Epoch = 418 : Training loss = 1024.2964855166647, R2 score : 0.8575463543074852\n",
      "Epoch = 419 : Training loss = 1046.342892025872, R2 score : 0.8559026784549597\n",
      "Epoch = 420 : Training loss = 1066.1718353985025, R2 score : 0.8591160016435109\n",
      "Epoch = 421 : Training loss = 1023.7939149321412, R2 score : 0.8589334328706546\n",
      "Epoch = 422 : Training loss = 1030.9464531510855, R2 score : 0.8586850592664339\n",
      "Epoch = 423 : Training loss = 1044.0388424919663, R2 score : 0.8571116580864395\n",
      "Epoch = 424 : Training loss = 1045.2504739349695, R2 score : 0.8580359157123308\n",
      "Epoch = 425 : Training loss = 1063.590373262227, R2 score : 0.8589974837896647\n",
      "Epoch = 426 : Training loss = 1011.7669229301617, R2 score : 0.8581868966267496\n",
      "Epoch = 427 : Training loss = 1036.9878330299323, R2 score : 0.8614450127519211\n",
      "Epoch = 428 : Training loss = 1056.1248064452795, R2 score : 0.8590139651603688\n",
      "Epoch = 429 : Training loss = 1085.7303248343708, R2 score : 0.8610324618862357\n",
      "Epoch = 430 : Training loss = 1021.1493629757449, R2 score : 0.8575814851432286\n",
      "Epoch = 431 : Training loss = 1030.6961750023656, R2 score : 0.8606575784561408\n",
      "Epoch = 432 : Training loss = 1014.3828109425607, R2 score : 0.8591453289028779\n",
      "Epoch = 433 : Training loss = 1016.1515168148836, R2 score : 0.8628731497527211\n",
      "Epoch = 434 : Training loss = 1015.0243994812314, R2 score : 0.8618791288098435\n",
      "Epoch = 435 : Training loss = 1026.2884551205223, R2 score : 0.8584605796819873\n",
      "Epoch = 436 : Training loss = 1016.581749379206, R2 score : 0.8634784315080336\n",
      "Epoch = 437 : Training loss = 1077.4945687904633, R2 score : 0.8600958878741088\n",
      "Epoch = 438 : Training loss = 1019.6982207195364, R2 score : 0.8632074692159376\n",
      "Epoch = 439 : Training loss = 1053.5452441104133, R2 score : 0.8641415917493844\n",
      "Epoch = 440 : Training loss = 1004.8975141683071, R2 score : 0.86312389099556\n",
      "Epoch = 441 : Training loss = 1033.7333824788923, R2 score : 0.8621664577602806\n",
      "Epoch = 442 : Training loss = 999.5332212653949, R2 score : 0.8627359591921182\n",
      "Epoch = 443 : Training loss = 993.1310857079869, R2 score : 0.8625301275371935\n",
      "Epoch = 444 : Training loss = 1089.028784577795, R2 score : 0.8630126543536927\n",
      "Epoch = 445 : Training loss = 1054.476706882175, R2 score : 0.8622000981582474\n",
      "Epoch = 446 : Training loss = 1062.9098475837022, R2 score : 0.8637306228727676\n",
      "Epoch = 447 : Training loss = 1021.7857592877724, R2 score : 0.8644938669834963\n",
      "Epoch = 448 : Training loss = 997.5647042783902, R2 score : 0.8615225063416649\n",
      "Epoch = 449 : Training loss = 995.7989803591221, R2 score : 0.8657681045199619\n",
      "Epoch = 450 : Training loss = 1004.4574289079621, R2 score : 0.8636772439215991\n",
      "Epoch = 451 : Training loss = 1019.204519189519, R2 score : 0.8641940522539386\n",
      "Epoch = 452 : Training loss = 991.3093925383773, R2 score : 0.8642470585149449\n",
      "Epoch = 453 : Training loss = 989.6024563912865, R2 score : 0.8634734614658675\n",
      "Epoch = 454 : Training loss = 999.8548416559645, R2 score : 0.8648351423806855\n",
      "Epoch = 455 : Training loss = 1019.7949527296231, R2 score : 0.8631762455757909\n",
      "Epoch = 456 : Training loss = 983.0464782856351, R2 score : 0.8648369671320405\n",
      "Epoch = 457 : Training loss = 1038.9072697077402, R2 score : 0.8632657083645052\n",
      "Epoch = 458 : Training loss = 993.5564397659233, R2 score : 0.8668212335956026\n",
      "Epoch = 459 : Training loss = 1132.6586872909565, R2 score : 0.8659573910150107\n",
      "Epoch = 460 : Training loss = 987.4793176342257, R2 score : 0.8673992340580114\n",
      "Epoch = 461 : Training loss = 1073.4349844404262, R2 score : 0.8654330880252138\n",
      "Epoch = 462 : Training loss = 1044.1118328382643, R2 score : 0.8666471651269423\n",
      "Epoch = 463 : Training loss = 995.4730954067312, R2 score : 0.8662667015633174\n",
      "Epoch = 464 : Training loss = 983.5382228172083, R2 score : 0.8674041250166746\n",
      "Epoch = 465 : Training loss = 964.7142986822471, R2 score : 0.8665476925170974\n",
      "Epoch = 466 : Training loss = 992.3983370691752, R2 score : 0.8646753864918313\n",
      "Epoch = 467 : Training loss = 1063.0274603864273, R2 score : 0.8689747944356574\n",
      "Epoch = 468 : Training loss = 970.3471430737337, R2 score : 0.8677667080032985\n",
      "Epoch = 469 : Training loss = 1015.6143192318704, R2 score : 0.8692412409801267\n",
      "Epoch = 470 : Training loss = 1037.073101084867, R2 score : 0.8685134863706987\n",
      "Epoch = 471 : Training loss = 1057.4306131321534, R2 score : 0.8644525499236\n",
      "Epoch = 472 : Training loss = 1002.1433135245344, R2 score : 0.8688841633918903\n",
      "Epoch = 473 : Training loss = 1007.7280917133359, R2 score : 0.870933518704415\n",
      "Epoch = 474 : Training loss = 968.1378280173103, R2 score : 0.8694229540335902\n",
      "Epoch = 475 : Training loss = 975.3763593563931, R2 score : 0.8697215417486411\n",
      "Epoch = 476 : Training loss = 944.9759762990388, R2 score : 0.8679604543289545\n",
      "Epoch = 477 : Training loss = 989.0144800432295, R2 score : 0.8684043969223674\n",
      "Epoch = 478 : Training loss = 992.978052883697, R2 score : 0.8667794277757052\n",
      "Epoch = 479 : Training loss = 955.482841168269, R2 score : 0.8688513715076243\n",
      "Epoch = 480 : Training loss = 1054.9427994222735, R2 score : 0.8685287309605256\n",
      "Epoch = 481 : Training loss = 1072.5139806459276, R2 score : 0.8711536076699905\n",
      "Epoch = 482 : Training loss = 944.5301283966724, R2 score : 0.871263458505419\n",
      "Epoch = 483 : Training loss = 968.0510558944812, R2 score : 0.8714713677110075\n",
      "Epoch = 484 : Training loss = 971.1374382595365, R2 score : 0.8724479933102619\n",
      "Epoch = 485 : Training loss = 953.8928997242193, R2 score : 0.8712500946523478\n",
      "Epoch = 486 : Training loss = 966.7192806736599, R2 score : 0.8702457522271491\n",
      "Epoch = 487 : Training loss = 1008.5529855138107, R2 score : 0.8693049281764246\n",
      "Epoch = 488 : Training loss = 965.8795754643653, R2 score : 0.8695446983933323\n",
      "Epoch = 489 : Training loss = 945.4319605312759, R2 score : 0.8714008940622462\n",
      "Epoch = 490 : Training loss = 950.4239265884427, R2 score : 0.872238003313857\n",
      "Epoch = 491 : Training loss = 957.4451131649155, R2 score : 0.8711330771223411\n",
      "Epoch = 492 : Training loss = 936.7978731951267, R2 score : 0.8724336520046655\n",
      "Epoch = 493 : Training loss = 984.0227465801102, R2 score : 0.8683883612822538\n",
      "Epoch = 494 : Training loss = 944.229501545858, R2 score : 0.8699826347916333\n",
      "Epoch = 495 : Training loss = 936.7623875569955, R2 score : 0.8729509754409993\n",
      "Epoch = 496 : Training loss = 1051.1244769336508, R2 score : 0.8753548903219404\n",
      "Epoch = 497 : Training loss = 943.1686405095694, R2 score : 0.8746020386480498\n",
      "Epoch = 498 : Training loss = 943.8585782081103, R2 score : 0.8727395493564408\n",
      "Epoch = 499 : Training loss = 1048.7066942942229, R2 score : 0.8684775824601152\n",
      "Epoch = 500 : Training loss = 955.0408008390193, R2 score : 0.8692478327597789\n",
      "Epoch = 501 : Training loss = 933.5866230486108, R2 score : 0.8720801459361776\n",
      "Epoch = 502 : Training loss = 916.772243976593, R2 score : 0.8717748789137774\n",
      "Epoch = 503 : Training loss = 936.2549660754719, R2 score : 0.8773279521115346\n",
      "Epoch = 504 : Training loss = 978.5197203313704, R2 score : 0.8664044129351367\n",
      "Epoch = 505 : Training loss = 931.529213596591, R2 score : 0.8714509112358958\n",
      "Epoch = 506 : Training loss = 964.1384852978823, R2 score : 0.8761679232365056\n",
      "Epoch = 507 : Training loss = 978.8597926407409, R2 score : 0.872992577769519\n",
      "Epoch = 508 : Training loss = 905.2406075532488, R2 score : 0.8734348529735583\n",
      "Epoch = 509 : Training loss = 908.3069458728214, R2 score : 0.8751609518151189\n",
      "Epoch = 510 : Training loss = 902.1208482406122, R2 score : 0.875244508570449\n",
      "Epoch = 511 : Training loss = 912.649296177377, R2 score : 0.8735659298766962\n",
      "Epoch = 512 : Training loss = 957.5932454001561, R2 score : 0.8731255544412633\n",
      "Epoch = 513 : Training loss = 939.767286334964, R2 score : 0.8735436793713048\n",
      "Epoch = 514 : Training loss = 1008.8723909859177, R2 score : 0.8757030864955158\n",
      "Epoch = 515 : Training loss = 937.8641121679073, R2 score : 0.8741038280979299\n",
      "Epoch = 516 : Training loss = 913.4040276481094, R2 score : 0.8747717495302474\n",
      "Epoch = 517 : Training loss = 929.2274789930248, R2 score : 0.8779319138286089\n",
      "Epoch = 518 : Training loss = 991.1583560971047, R2 score : 0.8747169619328764\n",
      "Epoch = 519 : Training loss = 906.2962065017481, R2 score : 0.8743574745899466\n",
      "Epoch = 520 : Training loss = 935.4474611925564, R2 score : 0.872924640836892\n",
      "Epoch = 521 : Training loss = 917.4930659506819, R2 score : 0.8731388005698257\n",
      "Epoch = 522 : Training loss = 913.9747362720022, R2 score : 0.8767754540590246\n",
      "Epoch = 523 : Training loss = 906.5225544559012, R2 score : 0.876108968837622\n",
      "Epoch = 524 : Training loss = 911.3050561534415, R2 score : 0.8769150446872243\n",
      "Epoch = 525 : Training loss = 900.9415747124514, R2 score : 0.8754216721749586\n",
      "Epoch = 526 : Training loss = 905.9385763209501, R2 score : 0.8761016821119545\n",
      "Epoch = 527 : Training loss = 896.2209222402504, R2 score : 0.8779245201479262\n",
      "Epoch = 528 : Training loss = 895.7247406235701, R2 score : 0.8790285028786673\n",
      "Epoch = 529 : Training loss = 882.9391148287615, R2 score : 0.8753861018706409\n",
      "Epoch = 530 : Training loss = 884.2125681698751, R2 score : 0.8778734390375502\n",
      "Epoch = 531 : Training loss = 924.263980669941, R2 score : 0.8793941379008221\n",
      "Epoch = 532 : Training loss = 901.1102539103666, R2 score : 0.8757972576511204\n",
      "Epoch = 533 : Training loss = 929.2361149545625, R2 score : 0.8756891243598822\n",
      "Epoch = 534 : Training loss = 926.6922211132461, R2 score : 0.879654668323109\n",
      "Epoch = 535 : Training loss = 918.9494649506302, R2 score : 0.8749048407126216\n",
      "Epoch = 536 : Training loss = 888.7239933768623, R2 score : 0.8763283235358509\n",
      "Epoch = 537 : Training loss = 989.2736114254958, R2 score : 0.874694993022722\n",
      "Epoch = 538 : Training loss = 906.751690814821, R2 score : 0.878186713543964\n",
      "Epoch = 539 : Training loss = 903.6606295185981, R2 score : 0.87937021630392\n",
      "Epoch = 540 : Training loss = 881.8992974689538, R2 score : 0.8807851272804876\n",
      "Epoch = 541 : Training loss = 895.6915536132648, R2 score : 0.8789322645340912\n",
      "Epoch = 542 : Training loss = 892.5310202708347, R2 score : 0.8785663743235326\n",
      "Epoch = 543 : Training loss = 871.0252080409647, R2 score : 0.8811716180959428\n",
      "Epoch = 544 : Training loss = 880.8847552237751, R2 score : 0.8822053115461661\n",
      "Epoch = 545 : Training loss = 897.4977905767427, R2 score : 0.878945111933337\n",
      "Epoch = 546 : Training loss = 889.322318340377, R2 score : 0.8801762353154509\n",
      "Epoch = 547 : Training loss = 920.4367920889272, R2 score : 0.8811219152376197\n",
      "Epoch = 548 : Training loss = 914.1136172452419, R2 score : 0.882200910175524\n",
      "Epoch = 549 : Training loss = 864.7622947006774, R2 score : 0.8816407108695707\n",
      "Epoch = 550 : Training loss = 892.8865606081572, R2 score : 0.8814853046423743\n",
      "Epoch = 551 : Training loss = 896.7233177174767, R2 score : 0.8801173007333661\n",
      "Epoch = 552 : Training loss = 936.9666590107431, R2 score : 0.8833267779305205\n",
      "Epoch = 553 : Training loss = 930.4410461572757, R2 score : 0.8821413277896558\n",
      "Epoch = 554 : Training loss = 899.3481309499672, R2 score : 0.8812304009654022\n",
      "Epoch = 555 : Training loss = 896.1184019802286, R2 score : 0.8804128879635011\n",
      "Epoch = 556 : Training loss = 865.8874306781687, R2 score : 0.8818786136455494\n",
      "Epoch = 557 : Training loss = 874.9631219527704, R2 score : 0.8799870708228736\n",
      "Epoch = 558 : Training loss = 872.2174154528611, R2 score : 0.8811598716826475\n",
      "Epoch = 559 : Training loss = 868.2842454601534, R2 score : 0.8836195423932034\n",
      "Epoch = 560 : Training loss = 852.2806596550153, R2 score : 0.8837112320603746\n",
      "Epoch = 561 : Training loss = 895.9507245571493, R2 score : 0.8762646492568492\n",
      "Epoch = 562 : Training loss = 860.9104513264389, R2 score : 0.8834063385954806\n",
      "Epoch = 563 : Training loss = 848.7929627329326, R2 score : 0.8837147035092948\n",
      "Epoch = 564 : Training loss = 885.9843837623116, R2 score : 0.8833627897467966\n",
      "Epoch = 565 : Training loss = 868.2924911015325, R2 score : 0.8827352648334497\n",
      "Epoch = 566 : Training loss = 853.9322543796018, R2 score : 0.8816896807541156\n",
      "Epoch = 567 : Training loss = 845.3014781749506, R2 score : 0.8835074477337314\n",
      "Epoch = 568 : Training loss = 850.8284423660032, R2 score : 0.8840313603328364\n",
      "Epoch = 569 : Training loss = 844.7968175196819, R2 score : 0.886279661811869\n",
      "Epoch = 570 : Training loss = 876.8435188334623, R2 score : 0.8829755224860198\n",
      "Epoch = 571 : Training loss = 873.2095334718554, R2 score : 0.8830695779799876\n",
      "Epoch = 572 : Training loss = 896.5862504763784, R2 score : 0.885075039539332\n",
      "Epoch = 573 : Training loss = 866.2195031248408, R2 score : 0.882886581447211\n",
      "Epoch = 574 : Training loss = 844.0626515175799, R2 score : 0.8856606775300327\n",
      "Epoch = 575 : Training loss = 877.5297632903504, R2 score : 0.8845876003959574\n",
      "Epoch = 576 : Training loss = 894.0967826706043, R2 score : 0.8869301748356786\n",
      "Epoch = 577 : Training loss = 895.528007150554, R2 score : 0.8877823162039772\n",
      "Epoch = 578 : Training loss = 936.9378785623921, R2 score : 0.886851250642178\n",
      "Epoch = 579 : Training loss = 882.2334329996178, R2 score : 0.8860798482659205\n",
      "Epoch = 580 : Training loss = 844.8040971927505, R2 score : 0.8867939650848478\n",
      "Epoch = 581 : Training loss = 883.4358139003781, R2 score : 0.8875586534648009\n",
      "Epoch = 582 : Training loss = 837.2745842350473, R2 score : 0.8876703419784922\n",
      "Epoch = 583 : Training loss = 847.5746703319412, R2 score : 0.887171398272878\n",
      "Epoch = 584 : Training loss = 860.595669845883, R2 score : 0.8869462993848775\n",
      "Epoch = 585 : Training loss = 839.1793340916256, R2 score : 0.8864748278525618\n",
      "Epoch = 586 : Training loss = 880.0669164400307, R2 score : 0.8875073270249669\n",
      "Epoch = 587 : Training loss = 839.9251235423328, R2 score : 0.8880408513746303\n",
      "Epoch = 588 : Training loss = 849.1276542471467, R2 score : 0.8868109550573918\n",
      "Epoch = 589 : Training loss = 821.682415200652, R2 score : 0.8895952819345632\n",
      "Epoch = 590 : Training loss = 835.6330598103914, R2 score : 0.8866478679248088\n",
      "Epoch = 591 : Training loss = 818.4336640611826, R2 score : 0.8885064568908737\n",
      "Epoch = 592 : Training loss = 856.925329273982, R2 score : 0.8832733843807216\n",
      "Epoch = 593 : Training loss = 838.3660827300531, R2 score : 0.8876331345257744\n",
      "Epoch = 594 : Training loss = 868.4468961619644, R2 score : 0.8902792116303249\n",
      "Epoch = 595 : Training loss = 904.0558989804318, R2 score : 0.888900000428545\n",
      "Epoch = 596 : Training loss = 847.3967079979053, R2 score : 0.8915761460710953\n",
      "Epoch = 597 : Training loss = 847.2621953127195, R2 score : 0.8903430384245828\n",
      "Epoch = 598 : Training loss = 831.9047194213318, R2 score : 0.8918944103362824\n",
      "Epoch = 599 : Training loss = 864.6784123611108, R2 score : 0.889533077686828\n",
      "Epoch = 600 : Training loss = 821.8127770183755, R2 score : 0.889411233598998\n",
      "Epoch = 601 : Training loss = 821.3954250932597, R2 score : 0.8907172816971302\n",
      "Epoch = 602 : Training loss = 839.8938379630767, R2 score : 0.8873316429139231\n",
      "Epoch = 603 : Training loss = 859.6206006552998, R2 score : 0.8910904166885373\n",
      "Epoch = 604 : Training loss = 823.572542149386, R2 score : 0.888468656053347\n",
      "Epoch = 605 : Training loss = 852.2511089379839, R2 score : 0.8896815612280747\n",
      "Epoch = 606 : Training loss = 821.2869972239296, R2 score : 0.8913081519589675\n",
      "Epoch = 607 : Training loss = 816.5200749335529, R2 score : 0.8903946024217668\n",
      "Epoch = 608 : Training loss = 847.3897478083055, R2 score : 0.8911621936105728\n",
      "Epoch = 609 : Training loss = 877.1378669301383, R2 score : 0.8872617415827029\n",
      "Epoch = 610 : Training loss = 854.7342807989327, R2 score : 0.8930706612531516\n",
      "Epoch = 611 : Training loss = 811.4860249766343, R2 score : 0.8935260734004095\n",
      "Epoch = 612 : Training loss = 811.8934148129799, R2 score : 0.8927944814378578\n",
      "Epoch = 613 : Training loss = 825.7576621556453, R2 score : 0.8929347836331134\n",
      "Epoch = 614 : Training loss = 831.0007561127917, R2 score : 0.8947432549774004\n",
      "Epoch = 615 : Training loss = 809.4122429614445, R2 score : 0.8914563386354382\n",
      "Epoch = 616 : Training loss = 817.9812462758675, R2 score : 0.894821874090845\n",
      "Epoch = 617 : Training loss = 941.9193765380078, R2 score : 0.8944516207220374\n",
      "Epoch = 618 : Training loss = 905.9141099967545, R2 score : 0.8908515319995584\n",
      "Epoch = 619 : Training loss = 826.8424259792987, R2 score : 0.8914730489034663\n",
      "Epoch = 620 : Training loss = 834.3336436319694, R2 score : 0.8945578022339111\n",
      "Epoch = 621 : Training loss = 809.4778795928406, R2 score : 0.8931449321550413\n",
      "Epoch = 622 : Training loss = 823.0519721902532, R2 score : 0.8915279438784183\n",
      "Epoch = 623 : Training loss = 813.1337947982678, R2 score : 0.8927949829758132\n",
      "Epoch = 624 : Training loss = 822.620170943171, R2 score : 0.8953299136097008\n",
      "Epoch = 625 : Training loss = 801.2866625168341, R2 score : 0.8951499910047622\n",
      "Epoch = 626 : Training loss = 808.8656485578139, R2 score : 0.893680375240026\n",
      "Epoch = 627 : Training loss = 829.5045715407501, R2 score : 0.8974890176107188\n",
      "Epoch = 628 : Training loss = 807.1685197113229, R2 score : 0.893820532389135\n",
      "Epoch = 629 : Training loss = 805.9846559154043, R2 score : 0.8960836850041338\n",
      "Epoch = 630 : Training loss = 828.8338779373993, R2 score : 0.8960257017757688\n",
      "Epoch = 631 : Training loss = 808.777026594114, R2 score : 0.8946410516062662\n",
      "Epoch = 632 : Training loss = 834.7580349874154, R2 score : 0.8947543832180801\n",
      "Epoch = 633 : Training loss = 810.7774454638255, R2 score : 0.8946490734774547\n",
      "Epoch = 634 : Training loss = 843.4365440459667, R2 score : 0.8966406128822597\n",
      "Epoch = 635 : Training loss = 802.4189244894673, R2 score : 0.8932094713343808\n",
      "Epoch = 636 : Training loss = 794.0525658422237, R2 score : 0.8945101688885776\n",
      "Epoch = 637 : Training loss = 821.3971676912239, R2 score : 0.896182786883801\n",
      "Epoch = 638 : Training loss = 804.2679530836696, R2 score : 0.8977666044287417\n",
      "Epoch = 639 : Training loss = 792.5218651963653, R2 score : 0.8970953790258231\n",
      "Epoch = 640 : Training loss = 800.3342340284114, R2 score : 0.8961983610279946\n",
      "Epoch = 641 : Training loss = 802.0282806136626, R2 score : 0.8977724437692902\n",
      "Epoch = 642 : Training loss = 819.7533830875973, R2 score : 0.8970196580374111\n",
      "Epoch = 643 : Training loss = 875.7845349071695, R2 score : 0.8966761742854269\n",
      "Epoch = 644 : Training loss = 790.1191851492408, R2 score : 0.8972117785331241\n",
      "Epoch = 645 : Training loss = 812.4460122087877, R2 score : 0.8971068538908427\n",
      "Epoch = 646 : Training loss = 807.9358293409828, R2 score : 0.8978555030220177\n",
      "Epoch = 647 : Training loss = 834.0081161389248, R2 score : 0.8953971860082991\n",
      "Epoch = 648 : Training loss = 811.8954509488112, R2 score : 0.8963259228668444\n",
      "Epoch = 649 : Training loss = 821.7034549301477, R2 score : 0.8976401228793778\n",
      "Epoch = 650 : Training loss = 813.9956210568654, R2 score : 0.898319417917246\n",
      "Epoch = 651 : Training loss = 834.9402627653355, R2 score : 0.896889098152898\n",
      "Epoch = 652 : Training loss = 823.7157584248687, R2 score : 0.8972433624102001\n",
      "Epoch = 653 : Training loss = 826.8399016153899, R2 score : 0.8976643708419656\n",
      "Epoch = 654 : Training loss = 792.3857340521092, R2 score : 0.8991142436954445\n",
      "Epoch = 655 : Training loss = 805.3722098500286, R2 score : 0.8958066700732402\n",
      "Epoch = 656 : Training loss = 791.2147383651287, R2 score : 0.897958681164482\n",
      "Epoch = 657 : Training loss = 807.5723383512428, R2 score : 0.8992423347724451\n",
      "Epoch = 658 : Training loss = 795.5895576717185, R2 score : 0.899492584286827\n",
      "Epoch = 659 : Training loss = 784.6737857551026, R2 score : 0.899404282278652\n",
      "Epoch = 660 : Training loss = 874.2160650843339, R2 score : 0.8984457164891867\n",
      "Epoch = 661 : Training loss = 816.0244857595978, R2 score : 0.900787602114433\n",
      "Epoch = 662 : Training loss = 821.9557933395715, R2 score : 0.9000254782750922\n",
      "Epoch = 663 : Training loss = 814.9679076105571, R2 score : 0.8993649387276735\n",
      "Epoch = 664 : Training loss = 812.693309900572, R2 score : 0.8977058427708015\n",
      "Epoch = 665 : Training loss = 785.577435037215, R2 score : 0.8993746756233864\n",
      "Epoch = 666 : Training loss = 787.9661307840896, R2 score : 0.8974147877365092\n",
      "Epoch = 667 : Training loss = 858.7588123211758, R2 score : 0.9023656712631953\n",
      "Epoch = 668 : Training loss = 841.1538770250279, R2 score : 0.9013759072570685\n",
      "Epoch = 669 : Training loss = 852.3185132561828, R2 score : 0.899946511786352\n",
      "Epoch = 670 : Training loss = 791.6225668509229, R2 score : 0.8995988267434796\n",
      "Epoch = 671 : Training loss = 784.9710770046217, R2 score : 0.8990174596248102\n",
      "Epoch = 672 : Training loss = 790.8144040725214, R2 score : 0.8994032980062886\n",
      "Epoch = 673 : Training loss = 805.1723668832573, R2 score : 0.9000712873299279\n",
      "Epoch = 674 : Training loss = 816.1654328819659, R2 score : 0.9013899363769791\n",
      "Epoch = 675 : Training loss = 872.8048405338534, R2 score : 0.8998291901836052\n",
      "Epoch = 676 : Training loss = 773.6644988917618, R2 score : 0.9025912528137798\n",
      "Epoch = 677 : Training loss = 862.2967538100353, R2 score : 0.8980822187429538\n",
      "Epoch = 678 : Training loss = 806.9669484886334, R2 score : 0.9017277810614911\n",
      "Epoch = 679 : Training loss = 799.727881349248, R2 score : 0.8998835690995989\n",
      "Epoch = 680 : Training loss = 804.7573230798296, R2 score : 0.9005406666539697\n",
      "Epoch = 681 : Training loss = 784.1077758734175, R2 score : 0.9028815062429087\n",
      "Epoch = 682 : Training loss = 777.1262576494286, R2 score : 0.900783528696185\n",
      "Epoch = 683 : Training loss = 821.733539334304, R2 score : 0.9032195634318086\n",
      "Epoch = 684 : Training loss = 786.8473538743506, R2 score : 0.9040495314705985\n",
      "Epoch = 685 : Training loss = 795.362917910377, R2 score : 0.9024279923885951\n",
      "Epoch = 686 : Training loss = 783.8784487813497, R2 score : 0.9028385052510971\n",
      "Epoch = 687 : Training loss = 827.2225496580274, R2 score : 0.9011698527619962\n",
      "Epoch = 688 : Training loss = 771.178615240742, R2 score : 0.9025938037153554\n",
      "Epoch = 689 : Training loss = 789.9942778443261, R2 score : 0.9038690249137232\n",
      "Epoch = 690 : Training loss = 780.5095849500285, R2 score : 0.901970726057321\n",
      "Epoch = 691 : Training loss = 835.301375584315, R2 score : 0.9029170499175934\n",
      "Epoch = 692 : Training loss = 798.0600862228613, R2 score : 0.902388084363985\n",
      "Epoch = 693 : Training loss = 777.0791416451228, R2 score : 0.9016535097436417\n",
      "Epoch = 694 : Training loss = 776.6871963267704, R2 score : 0.9054761630304777\n",
      "Epoch = 695 : Training loss = 768.1764227160447, R2 score : 0.902353614344233\n",
      "Epoch = 696 : Training loss = 804.1828755509082, R2 score : 0.9011858878552715\n",
      "Epoch = 697 : Training loss = 782.2563023327066, R2 score : 0.9003953104470268\n",
      "Epoch = 698 : Training loss = 796.6458566514708, R2 score : 0.9014860879220266\n",
      "Epoch = 699 : Training loss = 823.3563642759117, R2 score : 0.9015025609885509\n",
      "Epoch = 700 : Training loss = 770.9648100249201, R2 score : 0.9022844609169308\n",
      "Epoch = 701 : Training loss = 780.7864708891875, R2 score : 0.9043920160192823\n",
      "Epoch = 702 : Training loss = 794.6582388843564, R2 score : 0.9048639024647885\n",
      "Epoch = 703 : Training loss = 808.125407388742, R2 score : 0.9040322129303944\n",
      "Epoch = 704 : Training loss = 806.6689229869156, R2 score : 0.903102733444238\n",
      "Epoch = 705 : Training loss = 769.4086559213323, R2 score : 0.904798981788637\n",
      "Epoch = 706 : Training loss = 779.7623151738009, R2 score : 0.904564795921699\n",
      "Epoch = 707 : Training loss = 770.9349622314783, R2 score : 0.9067451071434528\n",
      "Epoch = 708 : Training loss = 779.1236691543525, R2 score : 0.9015678522403945\n",
      "Epoch = 709 : Training loss = 799.5631196481719, R2 score : 0.9035415236081431\n",
      "Epoch = 710 : Training loss = 774.2729747895714, R2 score : 0.9056134484545401\n",
      "Epoch = 711 : Training loss = 776.2574501037598, R2 score : 0.9035631894749987\n",
      "Epoch = 712 : Training loss = 795.6911712927784, R2 score : 0.9027706886075583\n",
      "Epoch = 713 : Training loss = 766.8681470198597, R2 score : 0.9046878728090407\n",
      "Epoch = 714 : Training loss = 795.3926330401744, R2 score : 0.9030874713876491\n",
      "Epoch = 715 : Training loss = 777.9615806950083, R2 score : 0.9037427216037569\n",
      "Epoch = 716 : Training loss = 795.4375304215246, R2 score : 0.9047377980197526\n",
      "Epoch = 717 : Training loss = 777.7049074550326, R2 score : 0.9051773581932587\n",
      "Epoch = 718 : Training loss = 790.6828400659904, R2 score : 0.9035927310698219\n",
      "Epoch = 719 : Training loss = 797.487147283211, R2 score : 0.9035486143775066\n",
      "Epoch = 720 : Training loss = 784.4242908452912, R2 score : 0.9058583451761715\n",
      "Epoch = 721 : Training loss = 765.7975165072105, R2 score : 0.9041527475391468\n",
      "Epoch = 722 : Training loss = 817.2007193908416, R2 score : 0.9074056416287277\n",
      "Epoch = 723 : Training loss = 790.0331124830589, R2 score : 0.9022894739569791\n",
      "Epoch = 724 : Training loss = 828.7290692818251, R2 score : 0.9063142760479495\n",
      "Epoch = 725 : Training loss = 779.8917027064365, R2 score : 0.9041308518101742\n",
      "Epoch = 726 : Training loss = 763.4340114524896, R2 score : 0.905207926525003\n",
      "Epoch = 727 : Training loss = 799.8784427231164, R2 score : 0.9067882446953137\n",
      "Epoch = 728 : Training loss = 813.7477662516155, R2 score : 0.9083617491690451\n",
      "Epoch = 729 : Training loss = 774.7573062155744, R2 score : 0.9083065463964973\n",
      "Epoch = 730 : Training loss = 755.2778859172794, R2 score : 0.907989962114717\n",
      "Epoch = 731 : Training loss = 764.5059417340395, R2 score : 0.9055536677613141\n",
      "Epoch = 732 : Training loss = 782.9720676957274, R2 score : 0.9084189929860531\n",
      "Epoch = 733 : Training loss = 793.9087976414522, R2 score : 0.9094998482294289\n",
      "Epoch = 734 : Training loss = 762.010035617746, R2 score : 0.9074804844194216\n",
      "Epoch = 735 : Training loss = 763.0504858648177, R2 score : 0.9077914031029742\n",
      "Epoch = 736 : Training loss = 770.5285105533737, R2 score : 0.9101737702262149\n",
      "Epoch = 737 : Training loss = 750.2338128604478, R2 score : 0.9070145872149958\n",
      "Epoch = 738 : Training loss = 782.4095789202684, R2 score : 0.9055338671998128\n",
      "Epoch = 739 : Training loss = 764.9068417231814, R2 score : 0.9086118431358381\n",
      "Epoch = 740 : Training loss = 788.6688783631907, R2 score : 0.9078232947438116\n",
      "Epoch = 741 : Training loss = 759.7148805590842, R2 score : 0.9100368189251302\n",
      "Epoch = 742 : Training loss = 778.5476782682131, R2 score : 0.9109469959303217\n",
      "Epoch = 743 : Training loss = 761.1092428303451, R2 score : 0.911409008656374\n",
      "Epoch = 744 : Training loss = 760.3873936632555, R2 score : 0.9056823887384999\n",
      "Epoch = 745 : Training loss = 790.4948150854317, R2 score : 0.904779019725649\n",
      "Epoch = 746 : Training loss = 750.8566305311464, R2 score : 0.9111544837447239\n",
      "Epoch = 747 : Training loss = 796.0832681175616, R2 score : 0.9114703983920966\n",
      "Epoch = 748 : Training loss = 783.3090761994287, R2 score : 0.9099949123676047\n",
      "Epoch = 749 : Training loss = 773.8440381743068, R2 score : 0.906464721084455\n",
      "Epoch = 750 : Training loss = 755.7257139905752, R2 score : 0.9099221238807856\n",
      "Epoch = 751 : Training loss = 754.1314322279511, R2 score : 0.9107859406190318\n",
      "Epoch = 752 : Training loss = 787.2591816452767, R2 score : 0.9067485628224621\n",
      "Epoch = 753 : Training loss = 756.3739373598168, R2 score : 0.9096386393069731\n",
      "Epoch = 754 : Training loss = 754.0806636673084, R2 score : 0.9095043678803753\n",
      "Epoch = 755 : Training loss = 782.1184668232211, R2 score : 0.9102768795277071\n",
      "Epoch = 756 : Training loss = 758.4911577375673, R2 score : 0.9117694640810335\n",
      "Epoch = 757 : Training loss = 761.5718783817703, R2 score : 0.9079877869248145\n",
      "Epoch = 758 : Training loss = 750.8218957297236, R2 score : 0.9105920577575669\n",
      "Epoch = 759 : Training loss = 740.78571539131, R2 score : 0.9107126069110376\n",
      "Epoch = 760 : Training loss = 773.1690140345114, R2 score : 0.9080823259625102\n",
      "Epoch = 761 : Training loss = 763.0472487116889, R2 score : 0.9107394914458685\n",
      "Epoch = 762 : Training loss = 786.8642815017014, R2 score : 0.9076471883662705\n",
      "Epoch = 763 : Training loss = 770.0294403035006, R2 score : 0.9109575775904837\n",
      "Epoch = 764 : Training loss = 748.8300110933592, R2 score : 0.9096936438781494\n",
      "Epoch = 765 : Training loss = 749.3045533509563, R2 score : 0.9094831558015113\n",
      "Epoch = 766 : Training loss = 761.4717015877045, R2 score : 0.9106824635335592\n",
      "Epoch = 767 : Training loss = 809.1404837464257, R2 score : 0.9073860639309238\n",
      "Epoch = 768 : Training loss = 767.2417678627179, R2 score : 0.9116556148655071\n",
      "Epoch = 769 : Training loss = 738.4511125070586, R2 score : 0.9104979483664607\n",
      "Epoch = 770 : Training loss = 744.3010075795564, R2 score : 0.909622141496683\n",
      "Epoch = 771 : Training loss = 805.0655547526243, R2 score : 0.9083813922971399\n",
      "Epoch = 772 : Training loss = 750.8740193929603, R2 score : 0.9108245945681049\n",
      "Epoch = 773 : Training loss = 784.660939786074, R2 score : 0.9143728021721649\n",
      "Epoch = 774 : Training loss = 748.0740136345513, R2 score : 0.912093632794035\n",
      "Epoch = 775 : Training loss = 747.2756863292173, R2 score : 0.9115743720338636\n",
      "Epoch = 776 : Training loss = 779.1146193854242, R2 score : 0.9110624590828037\n",
      "Epoch = 777 : Training loss = 764.0613052313277, R2 score : 0.912001424926463\n",
      "Epoch = 778 : Training loss = 796.3767322975096, R2 score : 0.909478470291949\n",
      "Epoch = 779 : Training loss = 742.0205775405005, R2 score : 0.9121024092757053\n",
      "Epoch = 780 : Training loss = 740.4788797502038, R2 score : 0.9123647057162829\n",
      "Epoch = 781 : Training loss = 744.2361513213287, R2 score : 0.9116555100217096\n",
      "Epoch = 782 : Training loss = 738.307786186822, R2 score : 0.9136689970357783\n",
      "Epoch = 783 : Training loss = 759.2196365329002, R2 score : 0.90979825624478\n",
      "Epoch = 784 : Training loss = 785.5585306634148, R2 score : 0.9130927187765394\n",
      "Epoch = 785 : Training loss = 782.0394255686149, R2 score : 0.9151614961930861\n",
      "Epoch = 786 : Training loss = 759.989819231222, R2 score : 0.9139789976774606\n",
      "Epoch = 787 : Training loss = 789.3339009182058, R2 score : 0.9168011401032619\n",
      "Epoch = 788 : Training loss = 750.9526575692266, R2 score : 0.9142159570408257\n",
      "Epoch = 789 : Training loss = 750.908902559349, R2 score : 0.9111496209608653\n",
      "Epoch = 790 : Training loss = 751.509054801447, R2 score : 0.9142515831183052\n",
      "Epoch = 791 : Training loss = 778.1806471570791, R2 score : 0.9120277098941998\n",
      "Epoch = 792 : Training loss = 779.6085516840434, R2 score : 0.9142522174836264\n",
      "Epoch = 793 : Training loss = 732.9919718255242, R2 score : 0.9115800027075108\n",
      "Epoch = 794 : Training loss = 741.4259294194284, R2 score : 0.9132975171271364\n",
      "Epoch = 795 : Training loss = 736.8587246078381, R2 score : 0.9157099183639744\n",
      "Epoch = 796 : Training loss = 805.0217078665821, R2 score : 0.913266903585505\n",
      "Epoch = 797 : Training loss = 749.7659755061857, R2 score : 0.9149422730527179\n",
      "Epoch = 798 : Training loss = 827.6900641626592, R2 score : 0.9153813337059875\n",
      "Epoch = 799 : Training loss = 733.8297812647099, R2 score : 0.913507064878473\n",
      "Epoch = 800 : Training loss = 785.8713246764039, R2 score : 0.9186044956961199\n",
      "Epoch = 801 : Training loss = 745.7737078220724, R2 score : 0.9131135341866842\n",
      "Epoch = 802 : Training loss = 748.9333199556354, R2 score : 0.9157854148424703\n",
      "Epoch = 803 : Training loss = 769.3969806286929, R2 score : 0.9090555931533156\n",
      "Epoch = 804 : Training loss = 771.5428356884195, R2 score : 0.9162355744936319\n",
      "Epoch = 805 : Training loss = 743.3821185407021, R2 score : 0.9120163335438871\n",
      "Epoch = 806 : Training loss = 745.6107496117517, R2 score : 0.9148506082381012\n",
      "Epoch = 807 : Training loss = 731.1483245684947, R2 score : 0.9148227262917162\n",
      "Epoch = 808 : Training loss = 725.759675814951, R2 score : 0.9134257983276549\n",
      "Epoch = 809 : Training loss = 748.7286470811144, R2 score : 0.9171750468320045\n",
      "Epoch = 810 : Training loss = 725.1208638939069, R2 score : 0.9128554059083522\n",
      "Epoch = 811 : Training loss = 730.0787184118367, R2 score : 0.9143984705492437\n",
      "Epoch = 812 : Training loss = 807.1575729589669, R2 score : 0.915465140611377\n",
      "Epoch = 813 : Training loss = 741.0901528090882, R2 score : 0.9122045190885655\n",
      "Epoch = 814 : Training loss = 802.8350313723945, R2 score : 0.9147457066196816\n",
      "Epoch = 815 : Training loss = 812.9431610640219, R2 score : 0.9152268631298007\n",
      "Epoch = 816 : Training loss = 738.7257192872411, R2 score : 0.9131260224409956\n",
      "Epoch = 817 : Training loss = 783.6713976971537, R2 score : 0.9148284539896799\n",
      "Epoch = 818 : Training loss = 737.986295329581, R2 score : 0.9140750790150655\n",
      "Epoch = 819 : Training loss = 757.1182774622663, R2 score : 0.9168465930381098\n",
      "Epoch = 820 : Training loss = 724.1643292234955, R2 score : 0.9155136765428674\n",
      "Epoch = 821 : Training loss = 729.3843015217952, R2 score : 0.9169005449456924\n",
      "Epoch = 822 : Training loss = 782.7184419666263, R2 score : 0.9157818378296604\n",
      "Epoch = 823 : Training loss = 755.154286650445, R2 score : 0.913967766591772\n",
      "Epoch = 824 : Training loss = 759.4280821127858, R2 score : 0.9170400503880003\n",
      "Epoch = 825 : Training loss = 727.6472574275175, R2 score : 0.915916621858295\n",
      "Epoch = 826 : Training loss = 740.5485472190294, R2 score : 0.9162193172465961\n",
      "Epoch = 827 : Training loss = 725.2310838064701, R2 score : 0.9131549319405181\n",
      "Epoch = 828 : Training loss = 719.1234388214222, R2 score : 0.9167441984200716\n",
      "Epoch = 829 : Training loss = 774.4363111780701, R2 score : 0.9185526623957626\n",
      "Epoch = 830 : Training loss = 751.8761092055615, R2 score : 0.9144213151409056\n",
      "Epoch = 831 : Training loss = 763.3566779267016, R2 score : 0.9197116714442976\n",
      "Epoch = 832 : Training loss = 741.7403496786845, R2 score : 0.9149502285348374\n",
      "Epoch = 833 : Training loss = 758.9220589322152, R2 score : 0.91773761447545\n",
      "Epoch = 834 : Training loss = 736.408479841493, R2 score : 0.9131398465536904\n",
      "Epoch = 835 : Training loss = 757.7421523101038, R2 score : 0.9127078477586239\n",
      "Epoch = 836 : Training loss = 721.3355878102693, R2 score : 0.9163767552104831\n",
      "Epoch = 837 : Training loss = 742.0889630763651, R2 score : 0.9177637980293724\n",
      "Epoch = 838 : Training loss = 721.9747867584229, R2 score : 0.9158538089450105\n",
      "Epoch = 839 : Training loss = 746.1277965298659, R2 score : 0.9167715259714504\n",
      "Epoch = 840 : Training loss = 733.4550576107107, R2 score : 0.9164984040899674\n",
      "Epoch = 841 : Training loss = 768.288852773982, R2 score : 0.9166202472269891\n",
      "Epoch = 842 : Training loss = 749.414635678847, R2 score : 0.9196483195868942\n",
      "Epoch = 843 : Training loss = 738.4328192086529, R2 score : 0.9150101176386374\n",
      "Epoch = 844 : Training loss = 719.9360812379302, R2 score : 0.9147704733228447\n",
      "Epoch = 845 : Training loss = 721.5745050821373, R2 score : 0.9153423859749397\n",
      "Epoch = 846 : Training loss = 735.9920322637764, R2 score : 0.9171703943084608\n",
      "Epoch = 847 : Training loss = 737.8352036647659, R2 score : 0.9146787964881357\n",
      "Epoch = 848 : Training loss = 732.555489766512, R2 score : 0.9169069751874073\n",
      "Epoch = 849 : Training loss = 719.8098832548951, R2 score : 0.9162758943207917\n",
      "Epoch = 850 : Training loss = 712.998022847896, R2 score : 0.9192431314527794\n",
      "Epoch = 851 : Training loss = 715.1833478323847, R2 score : 0.9179545715100819\n",
      "Epoch = 852 : Training loss = 724.6055257371861, R2 score : 0.9157710211468496\n",
      "Epoch = 853 : Training loss = 709.4176544354116, R2 score : 0.9164182887689528\n",
      "Epoch = 854 : Training loss = 770.0555923105144, R2 score : 0.9201746515742932\n",
      "Epoch = 855 : Training loss = 716.9200252560403, R2 score : 0.9157190352407141\n",
      "Epoch = 856 : Training loss = 725.1343537852061, R2 score : 0.9196905741932418\n",
      "Epoch = 857 : Training loss = 710.6868991148558, R2 score : 0.9174577917060801\n",
      "Epoch = 858 : Training loss = 766.0719869188267, R2 score : 0.9182900260853928\n",
      "Epoch = 859 : Training loss = 758.5315212414419, R2 score : 0.9178521637297365\n",
      "Epoch = 860 : Training loss = 705.0611204312002, R2 score : 0.916868875434075\n",
      "Epoch = 861 : Training loss = 745.1189398250991, R2 score : 0.9144926772012825\n",
      "Epoch = 862 : Training loss = 735.4501179619659, R2 score : 0.920310034716123\n",
      "Epoch = 863 : Training loss = 733.2610737162528, R2 score : 0.9169623866782698\n",
      "Epoch = 864 : Training loss = 843.0911329019841, R2 score : 0.9178610033665974\n",
      "Epoch = 865 : Training loss = 747.106566834364, R2 score : 0.917231763417127\n",
      "Epoch = 866 : Training loss = 709.0368073827071, R2 score : 0.9183223566112133\n",
      "Epoch = 867 : Training loss = 752.0955652058553, R2 score : 0.9181063603527336\n",
      "Epoch = 868 : Training loss = 709.5301973150788, R2 score : 0.9175546015657852\n",
      "Epoch = 869 : Training loss = 725.2559025647829, R2 score : 0.9166366078440652\n",
      "Epoch = 870 : Training loss = 724.5747032714405, R2 score : 0.9148667831033046\n",
      "Epoch = 871 : Training loss = 704.7802491634012, R2 score : 0.9186011162098969\n",
      "Epoch = 872 : Training loss = 698.9164658141651, R2 score : 0.9172570525908992\n",
      "Epoch = 873 : Training loss = 771.3427454653404, R2 score : 0.9124500427752701\n",
      "Epoch = 874 : Training loss = 703.9155470484452, R2 score : 0.9178182221359198\n",
      "Epoch = 875 : Training loss = 726.839149001691, R2 score : 0.917488777715557\n",
      "Epoch = 876 : Training loss = 714.1753786622191, R2 score : 0.9158307350654805\n",
      "Epoch = 877 : Training loss = 732.467639854486, R2 score : 0.9182768401320538\n",
      "Epoch = 878 : Training loss = 708.3936661095928, R2 score : 0.9197050429445129\n",
      "Epoch = 879 : Training loss = 734.6615041554403, R2 score : 0.9168096686069634\n",
      "Epoch = 880 : Training loss = 699.1997999150118, R2 score : 0.9189547375536964\n",
      "Epoch = 881 : Training loss = 737.2349959071591, R2 score : 0.9202055356100255\n",
      "Epoch = 882 : Training loss = 711.9346883760081, R2 score : 0.919370037977348\n",
      "Epoch = 883 : Training loss = 711.6350794799037, R2 score : 0.9171480268586484\n",
      "Epoch = 884 : Training loss = 726.3353767051972, R2 score : 0.920804610333914\n",
      "Epoch = 885 : Training loss = 720.4876542983295, R2 score : 0.9207671827909153\n",
      "Epoch = 886 : Training loss = 717.9128828769108, R2 score : 0.921592436395194\n",
      "Epoch = 887 : Training loss = 744.2409878325977, R2 score : 0.9234492966809011\n",
      "Epoch = 888 : Training loss = 713.7000227180316, R2 score : 0.9229033196781322\n",
      "Epoch = 889 : Training loss = 751.7901204747262, R2 score : 0.9226210264699717\n",
      "Epoch = 890 : Training loss = 710.6094132687548, R2 score : 0.9219334866113698\n",
      "Epoch = 891 : Training loss = 735.1709439908858, R2 score : 0.9168857532411371\n",
      "Epoch = 892 : Training loss = 723.8207180791621, R2 score : 0.9183353370972241\n",
      "Epoch = 893 : Training loss = 722.1764805882955, R2 score : 0.915163416726832\n",
      "Epoch = 894 : Training loss = 720.6076450896778, R2 score : 0.9229870091721352\n",
      "Epoch = 895 : Training loss = 745.1550380531833, R2 score : 0.9208435810320116\n",
      "Epoch = 896 : Training loss = 734.7726341357334, R2 score : 0.9209154636082969\n",
      "Epoch = 897 : Training loss = 722.6757436999314, R2 score : 0.9234506003419262\n",
      "Epoch = 898 : Training loss = 737.3607159141156, R2 score : 0.9195223094068549\n",
      "Epoch = 899 : Training loss = 700.0574729768492, R2 score : 0.9209006798973095\n",
      "Epoch = 900 : Training loss = 756.3436383240514, R2 score : 0.9185056449406682\n",
      "Epoch = 901 : Training loss = 732.3733331659715, R2 score : 0.9174888683019693\n",
      "Epoch = 902 : Training loss = 736.5450707854127, R2 score : 0.9219144975998195\n",
      "Epoch = 903 : Training loss = 728.9803649367188, R2 score : 0.9183996082226455\n",
      "Epoch = 904 : Training loss = 727.4782227543618, R2 score : 0.9214523793579042\n",
      "Epoch = 905 : Training loss = 751.6840917326564, R2 score : 0.9172873732499164\n",
      "Epoch = 906 : Training loss = 743.0748208409591, R2 score : 0.923538568283377\n",
      "Epoch = 907 : Training loss = 700.8467584170884, R2 score : 0.9211853943871284\n",
      "Epoch = 908 : Training loss = 716.6126196435887, R2 score : 0.9214321231474664\n",
      "Epoch = 909 : Training loss = 716.3221766657109, R2 score : 0.9201087995504493\n",
      "Epoch = 910 : Training loss = 723.8501246610134, R2 score : 0.9203542501309471\n",
      "Epoch = 911 : Training loss = 729.7883448429245, R2 score : 0.9184563126026376\n",
      "Epoch = 912 : Training loss = 717.4483707774457, R2 score : 0.9205745569359021\n",
      "Epoch = 913 : Training loss = 712.3087649036654, R2 score : 0.9218375221223803\n",
      "Epoch = 914 : Training loss = 687.8663852060441, R2 score : 0.9213632599683991\n",
      "Epoch = 915 : Training loss = 718.0682378672867, R2 score : 0.9198280527582856\n",
      "Epoch = 916 : Training loss = 749.3164133652509, R2 score : 0.9215085100246774\n",
      "Epoch = 917 : Training loss = 729.5343319460643, R2 score : 0.918238580713423\n",
      "Epoch = 918 : Training loss = 758.8870601062295, R2 score : 0.9243375073653304\n",
      "Epoch = 919 : Training loss = 700.0974942282807, R2 score : 0.9210673496282197\n",
      "Epoch = 920 : Training loss = 727.6582437625034, R2 score : 0.9220620812354314\n",
      "Epoch = 921 : Training loss = 711.2049337702689, R2 score : 0.9240030386028241\n",
      "Epoch = 922 : Training loss = 769.4555767663092, R2 score : 0.9181490603743069\n",
      "Epoch = 923 : Training loss = 734.5074967343172, R2 score : 0.9219304025267623\n",
      "Epoch = 924 : Training loss = 702.4336784143242, R2 score : 0.9203833589123156\n",
      "Epoch = 925 : Training loss = 717.1887284834607, R2 score : 0.9196145727716224\n",
      "Epoch = 926 : Training loss = 711.32851146451, R2 score : 0.923343674692937\n",
      "Epoch = 927 : Training loss = 684.7524966095849, R2 score : 0.9222310042471973\n",
      "Epoch = 928 : Training loss = 732.5694484847912, R2 score : 0.9241277024940234\n",
      "Epoch = 929 : Training loss = 690.3326581810876, R2 score : 0.9212790861506672\n",
      "Epoch = 930 : Training loss = 705.5562590592199, R2 score : 0.9252872727895196\n",
      "Epoch = 931 : Training loss = 684.5369147293859, R2 score : 0.9228424816284793\n",
      "Epoch = 932 : Training loss = 676.9073920352854, R2 score : 0.9231171316678719\n",
      "Epoch = 933 : Training loss = 708.2586850776947, R2 score : 0.9208227021890134\n",
      "Epoch = 934 : Training loss = 693.4420464742097, R2 score : 0.9244256812078383\n",
      "Epoch = 935 : Training loss = 710.1348225572984, R2 score : 0.924574798931185\n",
      "Epoch = 936 : Training loss = 758.6912405962566, R2 score : 0.925912425853017\n",
      "Epoch = 937 : Training loss = 686.4948528619121, R2 score : 0.9235361537275415\n",
      "Epoch = 938 : Training loss = 718.2200520741853, R2 score : 0.9195853819158675\n",
      "Epoch = 939 : Training loss = 730.8873276398015, R2 score : 0.923281418719196\n",
      "Epoch = 940 : Training loss = 686.7806037450008, R2 score : 0.9251575652371431\n",
      "Epoch = 941 : Training loss = 691.3749339151725, R2 score : 0.9221113959818378\n",
      "Epoch = 942 : Training loss = 692.1324066601211, R2 score : 0.9253395540392301\n",
      "Epoch = 943 : Training loss = 692.7377154123869, R2 score : 0.9251720077783672\n",
      "Epoch = 944 : Training loss = 709.6257066383637, R2 score : 0.9225137933987106\n",
      "Epoch = 945 : Training loss = 724.5726749228058, R2 score : 0.922392076119826\n",
      "Epoch = 946 : Training loss = 739.5631895285073, R2 score : 0.9233404341766075\n",
      "Epoch = 947 : Training loss = 689.1034516190454, R2 score : 0.923002374114424\n",
      "Epoch = 948 : Training loss = 695.5823373451508, R2 score : 0.9225408801116319\n",
      "Epoch = 949 : Training loss = 694.2073127966133, R2 score : 0.9223335044658708\n",
      "Epoch = 950 : Training loss = 749.9196051179076, R2 score : 0.9259408640252791\n",
      "Epoch = 951 : Training loss = 689.476072592701, R2 score : 0.9248904030141172\n",
      "Epoch = 952 : Training loss = 734.3125472583359, R2 score : 0.9251640683656955\n",
      "Epoch = 953 : Training loss = 674.3000151682243, R2 score : 0.9240243494978897\n",
      "Epoch = 954 : Training loss = 702.8171467506628, R2 score : 0.9234024264757184\n",
      "Epoch = 955 : Training loss = 680.9642055429143, R2 score : 0.924341041210009\n",
      "Epoch = 956 : Training loss = 682.2544888901195, R2 score : 0.9245988992025431\n",
      "Epoch = 957 : Training loss = 668.2288454042064, R2 score : 0.9234820208951465\n",
      "Epoch = 958 : Training loss = 681.5959376465503, R2 score : 0.9257021343560172\n",
      "Epoch = 959 : Training loss = 682.552909686411, R2 score : 0.9253665419758361\n",
      "Epoch = 960 : Training loss = 711.4069347244373, R2 score : 0.9210849776737333\n",
      "Epoch = 961 : Training loss = 708.1657272585862, R2 score : 0.9252166410540249\n",
      "Epoch = 962 : Training loss = 682.8582965521504, R2 score : 0.9226886170117183\n",
      "Epoch = 963 : Training loss = 673.517034873688, R2 score : 0.9252430397090474\n",
      "Epoch = 964 : Training loss = 685.5628503209396, R2 score : 0.9243764712550012\n",
      "Epoch = 965 : Training loss = 681.3831646116518, R2 score : 0.9240746501882028\n",
      "Epoch = 966 : Training loss = 724.0217558634367, R2 score : 0.9258242461868554\n",
      "Epoch = 967 : Training loss = 682.3194824465745, R2 score : 0.926039262325958\n",
      "Epoch = 968 : Training loss = 703.0783111242939, R2 score : 0.9269216930545637\n",
      "Epoch = 969 : Training loss = 699.3470780352037, R2 score : 0.9265027447948306\n",
      "Epoch = 970 : Training loss = 755.2186857264677, R2 score : 0.9239245035792225\n",
      "Epoch = 971 : Training loss = 701.3390462106938, R2 score : 0.9262823097449894\n",
      "Epoch = 972 : Training loss = 722.8456997768484, R2 score : 0.9258484352751889\n",
      "Epoch = 973 : Training loss = 686.1196819689634, R2 score : 0.9259397231396076\n",
      "Epoch = 974 : Training loss = 688.7473871930898, R2 score : 0.9237354506283673\n",
      "Epoch = 975 : Training loss = 665.1552235033872, R2 score : 0.923626108418895\n",
      "Epoch = 976 : Training loss = 679.0668810700341, R2 score : 0.9249502294681831\n",
      "Epoch = 977 : Training loss = 679.0602405946032, R2 score : 0.9277545245499939\n",
      "Epoch = 978 : Training loss = 692.532167297473, R2 score : 0.9254731372099809\n",
      "Epoch = 979 : Training loss = 680.4269063867254, R2 score : 0.9257709850049898\n",
      "Epoch = 980 : Training loss = 673.9775807085655, R2 score : 0.9246799479623569\n",
      "Epoch = 981 : Training loss = 676.6060155004049, R2 score : 0.9229532185005822\n",
      "Epoch = 982 : Training loss = 697.8370002362368, R2 score : 0.9282258437640705\n",
      "Epoch = 983 : Training loss = 715.3903407887589, R2 score : 0.9237016006900151\n",
      "Epoch = 984 : Training loss = 687.6110972946497, R2 score : 0.9273324026338403\n",
      "Epoch = 985 : Training loss = 698.8302647844492, R2 score : 0.9252832571074486\n",
      "Epoch = 986 : Training loss = 734.5422896395485, R2 score : 0.9284935190267314\n",
      "Epoch = 987 : Training loss = 665.074755071736, R2 score : 0.9274172914036957\n",
      "Epoch = 988 : Training loss = 663.0139160019031, R2 score : 0.9257814669432599\n",
      "Epoch = 989 : Training loss = 674.2533967580727, R2 score : 0.9275954405006135\n",
      "Epoch = 990 : Training loss = 693.2191083379787, R2 score : 0.924918130304435\n",
      "Epoch = 991 : Training loss = 665.5147414653421, R2 score : 0.9247535875286904\n",
      "Epoch = 992 : Training loss = 695.5893913863374, R2 score : 0.9253105837602331\n",
      "Epoch = 993 : Training loss = 714.9591977098863, R2 score : 0.9280063147872033\n",
      "Epoch = 994 : Training loss = 712.1652326378033, R2 score : 0.9265596441510617\n",
      "Epoch = 995 : Training loss = 657.036622719799, R2 score : 0.9269241502981406\n",
      "Epoch = 996 : Training loss = 654.6042717858185, R2 score : 0.9276910213050632\n",
      "Epoch = 997 : Training loss = 684.3920067917529, R2 score : 0.9253185252939046\n",
      "Epoch = 998 : Training loss = 654.202147820013, R2 score : 0.9281262717784992\n",
      "Epoch = 999 : Training loss = 682.5972456897763, R2 score : 0.9240335458884766\n",
      "Epoch = 1000 : Training loss = 711.8686751221582, R2 score : 0.928343810013127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Main.P2H_CapacityExpansion.Surrogate(Chain(Dense(12 => 500, relu), Dense(500 => 1)), [2703.004150390625, 1217.3284912109375, 1451.1793212890625, 2535.618408203125, 1284.1793212890625, 1828.0203857421875, 1358.8826904296875, 1972.9832763671875, 480.77734375, 1978.3953857421875  …  1281.7955322265625, 1421.1868896484375, 480.59344482421875, 2426.528076171875, 1922.0726318359375, 2087.947509765625, 43686.04296875, 10802.0322265625, 1332.9617919921875, 32554.541015625])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### train ML model and compute R2 ### \n",
    "sg = P2H_CapacityExpansion.neural_network_model_flux(X_train, y_train, X_test, y_test; hidden_layer=500, epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Hybrid Modeling Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Each time-series is averaged in 10-hourly steps\n",
      "└ @ Main.P2H_CapacityExpansion /cluster/home/danare/git/P2H_CapacityExpansion/utils/load_data.jl:76\n"
     ]
    }
   ],
   "source": [
    "# load input\n",
    "config = P2H_CapacityExpansion.read_yaml_file();\n",
    "data = P2H_CapacityExpansion.load_cep_data(config=config);\n",
    "ts_data = P2H_CapacityExpansion.load_timeseries_data_full(config=config);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Reading the data ...\n",
      "└ @ Main.P2H_CapacityExpansion /cluster/home/danare/git/P2H_CapacityExpansion/src/opt.jl:19\n",
      "┌ Info: Investment mode is on.\n",
      "└ @ Main.P2H_CapacityExpansion /cluster/home/danare/git/P2H_CapacityExpansion/src/opt.jl:88\n"
     ]
    }
   ],
   "source": [
    "cep = P2H_CapacityExpansion.run_opt(ts_data=ts_data, data=data, config=config, surrogate=true, solver=Ipopt.Optimizer)\n",
    "\n",
    "@unpack 𝓖, 𝓨, 𝓣, 𝓡, 𝓢, 𝓛, 𝓒 = P2H_CapacityExpansion.get_sets(cep=cep)\n",
    "data = data.data;\n",
    "\n",
    "##################### cost optimization #####################\n",
    "\n",
    "P2H_CapacityExpansion.setup_opt_costs_fix!(cep, config, data,vcat(cep.sets[\"non_dispatch\"], cep.sets[\"dispatch\"], 𝓢, String[s for s in cep.sets[\"discharging\"]], cep.sets[\"conversion\"]))\n",
    "\n",
    "#JuMP.fix.(cep.model[:COST][\"var\", :, :], 0; force=true);\n",
    "@variable(cep.model, COST_VAR[y ∈ 𝓨] ≥ 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "techs = [f for f ∈ cep.sets[\"invest_tech\"] if f != \"ENS\"]\n",
    "\n",
    "for y ∈ 𝓨, r ∈ 𝓡\n",
    "    x_vec = [cep.model[:TotalCapacityAnnual][r, g, y] for g ∈ techs]\n",
    "    prediction, formulation = MathOptAI.add_predictor(cep.model, sg.model, x_vec)\n",
    "    @constraint(cep.model, COST_VAR[y] .>= prediction)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ 1.4802442849183444 COST_{cap,2030,P\\_Wind\\_Offshore\\_Transitional} + 1.4802442849183444 COST_{cap,2030,S\\_Battery\\_Li-Ion} + 1.4802442849183444 COST_{cap,2030,P\\_Wind\\_Onshore\\_Avg} + 1.4802442849183444 COST_{cap,2030,X\\_Electrolysis} + 1.4802442849183444 COST_{cap,2030,trans\\_H2} + 1.4802442849183444 COST_{cap,2030,P\\_PV\\_Utility\\_Avg} + 1.4802442849183444 COST_{cap,2030,P\\_Gas\\_CCGT} + 1.4802442849183444 COST_{cap,2030,D\\_Gas\\_H2\\_out} + 1.4802442849183444 COST_{cap,2030,trans\\_elec} + 1.4802442849183444 COST_{cap,2030,D\\_Battery\\_Li-Ion\\_out} + 1.4802442849183444 COST_{cap,2030,ENS} + 1.4802442849183444 COST_{cap,2030,P\\_Biomass} + 1.4802442849183444 COST_{cap,2030,S\\_Gas\\_H2} + 1.4802442849183444 COST_{cap,2030,P\\_H2\\_OCGT} + 1.4802442849183444 COST_{cap,2030,X\\_ATR\\_CCS} + COST_{cap,2040,P\\_Wind\\_Offshore\\_Transitional} + COST_{cap,2040,S\\_Battery\\_Li-Ion} + COST_{cap,2040,P\\_Wind\\_Onshore\\_Avg} + COST_{cap,2040,X\\_Electrolysis} + COST_{cap,2040,trans\\_H2} + COST_{cap,2040,P\\_PV\\_Utility\\_Avg} + COST_{cap,2040,P\\_Gas\\_CCGT} + COST_{cap,2040,D\\_Gas\\_H2\\_out} + COST_{cap,2040,trans\\_elec} + COST_{cap,2040,D\\_Battery\\_Li-Ion\\_out} + COST_{cap,2040,ENS} + COST_{cap,2040,P\\_Biomass} + COST_{cap,2040,S\\_Gas\\_H2} + COST_{cap,2040,P\\_H2\\_OCGT} + COST_{cap,2040,X\\_ATR\\_CCS} + [[\\ldots\\text{60 terms omitted}\\ldots]] + COST_{fix,2040,P\\_H2\\_OCGT} + COST_{fix,2040,S\\_PHS} + COST_{fix,2040,D\\_Battery\\_Li-Ion\\_in} + COST_{fix,2040,X\\_ATR\\_CCS} + COST\\_VAR_{2040} + 0.6755641688257986 COST_{fix,2050,P\\_Wind\\_Offshore\\_Transitional} + 0.6755641688257986 COST_{fix,2050,S\\_Battery\\_Li-Ion} + 0.6755641688257986 COST_{fix,2050,D\\_Hydro\\_Reservoir\\_out} + 0.6755641688257986 COST_{fix,2050,P\\_Wind\\_Onshore\\_Avg} + 0.6755641688257986 COST_{fix,2050,X\\_Electrolysis} + 0.6755641688257986 COST_{fix,2050,trans\\_H2} + 0.6755641688257986 COST_{fix,2050,P\\_PV\\_Utility\\_Avg} + 0.6755641688257986 COST_{fix,2050,P\\_Coal\\_Hardcoal} + 0.6755641688257986 COST_{fix,2050,P\\_Gas\\_CCGT} + 0.6755641688257986 COST_{fix,2050,D\\_Gas\\_H2\\_out} + 0.6755641688257986 COST_{fix,2050,S\\_Hydro\\_Reservoir} + 0.6755641688257986 COST_{fix,2050,trans\\_elec} + 0.6755641688257986 COST_{fix,2050,D\\_Gas\\_H2\\_in} + 0.6755641688257986 COST_{fix,2050,P\\_Nuclear} + 0.6755641688257986 COST_{fix,2050,D\\_Battery\\_Li-Ion\\_out} + 0.6755641688257986 COST_{fix,2050,D\\_PHS\\_in} + 0.6755641688257986 COST_{fix,2050,ENS} + 0.6755641688257986 COST_{fix,2050,D\\_PHS\\_out} + 0.6755641688257986 COST_{fix,2050,P\\_Biomass} + 0.6755641688257986 COST_{fix,2050,S\\_Gas\\_H2} + 0.6755641688257986 COST_{fix,2050,P\\_H2\\_OCGT} + 0.6755641688257986 COST_{fix,2050,S\\_PHS} + 0.6755641688257986 COST_{fix,2050,D\\_Battery\\_Li-Ion\\_in} + 0.6755641688257986 COST_{fix,2050,X\\_ATR\\_CCS} + 0.6755641688257986 COST\\_VAR_{2050} $"
      ],
      "text/plain": [
       "1.4802442849183444 COST[cap,2030,P_Wind_Offshore_Transitional] + 1.4802442849183444 COST[cap,2030,S_Battery_Li-Ion] + 1.4802442849183444 COST[cap,2030,P_Wind_Onshore_Avg] + 1.4802442849183444 COST[cap,2030,X_Electrolysis] + 1.4802442849183444 COST[cap,2030,trans_H2] + 1.4802442849183444 COST[cap,2030,P_PV_Utility_Avg] + 1.4802442849183444 COST[cap,2030,P_Gas_CCGT] + 1.4802442849183444 COST[cap,2030,D_Gas_H2_out] + 1.4802442849183444 COST[cap,2030,trans_elec] + 1.4802442849183444 COST[cap,2030,D_Battery_Li-Ion_out] + 1.4802442849183444 COST[cap,2030,ENS] + 1.4802442849183444 COST[cap,2030,P_Biomass] + 1.4802442849183444 COST[cap,2030,S_Gas_H2] + 1.4802442849183444 COST[cap,2030,P_H2_OCGT] + 1.4802442849183444 COST[cap,2030,X_ATR_CCS] + COST[cap,2040,P_Wind_Offshore_Transitional] + COST[cap,2040,S_Battery_Li-Ion] + COST[cap,2040,P_Wind_Onshore_Avg] + COST[cap,2040,X_Electrolysis] + COST[cap,2040,trans_H2] + COST[cap,2040,P_PV_Utility_Avg] + COST[cap,2040,P_Gas_CCGT] + COST[cap,2040,D_Gas_H2_out] + COST[cap,2040,trans_elec] + COST[cap,2040,D_Battery_Li-Ion_out] + COST[cap,2040,ENS] + COST[cap,2040,P_Biomass] + COST[cap,2040,S_Gas_H2] + COST[cap,2040,P_H2_OCGT] + COST[cap,2040,X_ATR_CCS] + [[...60 terms omitted...]] + COST[fix,2040,P_H2_OCGT] + COST[fix,2040,S_PHS] + COST[fix,2040,D_Battery_Li-Ion_in] + COST[fix,2040,X_ATR_CCS] + COST_VAR[2040] + 0.6755641688257986 COST[fix,2050,P_Wind_Offshore_Transitional] + 0.6755641688257986 COST[fix,2050,S_Battery_Li-Ion] + 0.6755641688257986 COST[fix,2050,D_Hydro_Reservoir_out] + 0.6755641688257986 COST[fix,2050,P_Wind_Onshore_Avg] + 0.6755641688257986 COST[fix,2050,X_Electrolysis] + 0.6755641688257986 COST[fix,2050,trans_H2] + 0.6755641688257986 COST[fix,2050,P_PV_Utility_Avg] + 0.6755641688257986 COST[fix,2050,P_Coal_Hardcoal] + 0.6755641688257986 COST[fix,2050,P_Gas_CCGT] + 0.6755641688257986 COST[fix,2050,D_Gas_H2_out] + 0.6755641688257986 COST[fix,2050,S_Hydro_Reservoir] + 0.6755641688257986 COST[fix,2050,trans_elec] + 0.6755641688257986 COST[fix,2050,D_Gas_H2_in] + 0.6755641688257986 COST[fix,2050,P_Nuclear] + 0.6755641688257986 COST[fix,2050,D_Battery_Li-Ion_out] + 0.6755641688257986 COST[fix,2050,D_PHS_in] + 0.6755641688257986 COST[fix,2050,ENS] + 0.6755641688257986 COST[fix,2050,D_PHS_out] + 0.6755641688257986 COST[fix,2050,P_Biomass] + 0.6755641688257986 COST[fix,2050,S_Gas_H2] + 0.6755641688257986 COST[fix,2050,P_H2_OCGT] + 0.6755641688257986 COST[fix,2050,S_PHS] + 0.6755641688257986 COST[fix,2050,D_Battery_Li-Ion_in] + 0.6755641688257986 COST[fix,2050,X_ATR_CCS] + 0.6755641688257986 COST_VAR[2050]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opex_discounted = sum(\n",
    "    1 / ((1 + config[\"r\"])^(y - 𝓨[1] - 10)) * (\n",
    "        sum(cep.model[:COST][\"fix\", y, g] for g ∈ 𝓖) +\n",
    "        COST_VAR[y]\n",
    "    ) for y ∈ 𝓨\n",
    ")\n",
    "\n",
    "@objective(cep.model, Min, sum(\n",
    "    1 / ((1 + config[\"r\"])^(y - 𝓨[1] - 10)) *\n",
    "    sum(cep.model[:COST][\"cap\", y, g] for g ∈ cep.sets[\"invest_all\"])\n",
    "    for y ∈ 𝓨 \n",
    ") + opex_discounted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = P2H_CapacityExpansion.optimize_and_output(cep=cep, config=config, data=data, ts_data=ts_data, name=\"scenario_v3\", short_sol=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{VariableRef}:\n",
       " moai_Affine[1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total variables: 6369\n"
     ]
    },
    {
     "ename": "UndefKeywordError",
     "evalue": "UndefKeywordError: keyword argument `count_variable_in_set_constraints` not assigned",
     "output_type": "error",
     "traceback": [
      "UndefKeywordError: keyword argument `count_variable_in_set_constraints` not assigned\n",
      "\n",
      "Stacktrace:\n",
      " [1] num_constraints(model::Model)\n",
      "   @ JuMP ~/.julia/packages/JuMP/LKjRR/src/constraints.jl:1716\n",
      " [2] top-level scope\n",
      "   @ ~/git/P2H_CapacityExpansion/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X20sdnNjb2RlLXJlbW90ZQ==.jl:2"
     ]
    }
   ],
   "source": [
    "println(\"Total variables: \", JuMP.num_variables(cep.model))\n",
    "println(\"Total constraints: \", JuMP.num_constraints(cep.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VariableRef\u001b[90m (alias for \u001b[39m\u001b[90mGenericVariableRef{Float64}\u001b[39m\u001b[90m)\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "typeof(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
