{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module P2H_CapacityExpansion.\n",
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/git`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "include(\"./P2H_CapacityExpansion.jl\")\n",
    "cd(\"/cluster/home/danare/git\")\n",
    "Pkg.activate(\".\")\n",
    "using .P2H_CapacityExpansion\n",
    "using DataFrames\n",
    "using Parameters\n",
    "using Flux\n",
    "using Surrogates\n",
    "using ScikitLearn\n",
    "using LinearAlgebra, Random, Statistics\n",
    "using JuMP\n",
    "using XLSX\n",
    "using PlotlyJS\n",
    "using Clustering\n",
    "using CSV\n",
    "using Dates\n",
    "using StatsBase, MultivariateStats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/cluster/home/danare/git/P2H_CapacityExpansion/results/500_scenarios_V3.txt\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file = \"/cluster/home/danare/git/P2H_CapacityExpansion/results/aggregated_results/500_scenarios.txt\"\n",
    "file = \"/cluster/home/danare/git/P2H_CapacityExpansion/results/500_scenarios_V3.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Data into Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([34.0 46.0 … 22.0 0.0; 6.0 8.0 … 18.0 0.0; … ; 56.0 9.0 … 23.0 0.0; 0.0 26.0 … 21.0 0.0], [1291.0 43809.0 1.45124993e8; 1918.0 47135.0 1.32575014e8; … ; 5438.0 54206.0 1.33274952e8; 1162.0 43992.0 1.06995688e8], [62.0 519.0 … 68.0 0.0; 12.0 15.0 … 23.0 0.0; … ; 32.0 36.0 … 22.0 0.0; 6.0 16.0 … 20.0 0.0], [580.0 40764.0 0.0; 1624.0 43308.0 1.24961636e8; … ; 1385.0 44664.0 1.52371092e8; 2088.0 46037.0 1.26214918e8])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_raw = P2H_CapacityExpansion.read_txt_file(file);\n",
    "df_raw = select(df_raw, Not(:ENS))\n",
    "X_train, y_train, X_test, y_test = P2H_CapacityExpansion.partitionTrainTest(df_raw, [:Cost, :Generation, :Emission], 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### scale the data ###\n",
    "X_train_scaled, μX, σX  = P2H_CapacityExpansion.scaling(X_train)\n",
    "X_test_scaled = (X_test .- μX) ./ σX\n",
    "y_train_scaled, μy, σy  = P2H_CapacityExpansion.scaling(y_train)\n",
    "    \n",
    "# remove np.nan #\n",
    "for i in eachindex(X_test_scaled)\n",
    "    if isnan(X_test_scaled[i])\n",
    "        X_test_scaled[i] = 0.0\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = P2H_CapacityExpansion.simple_neural_network_sklearn(X_train_scaled, y_train_scaled, X_test_scaled; hidden_layer=500, max_iter=1000)\n",
    "ŷ_rescaled = sg.prediction .* σy .+ μy\n",
    "r2 = P2H_CapacityExpansion.r2_score(y_test, ŷ_rescaled)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1 : Training loss = 3163.8379208432543, R2 score : 0.5509832833045079\n",
      "Epoch = 2 : Training loss = 3146.9467851370014, R2 score : 0.535571198408062\n",
      "Epoch = 3 : Training loss = 3129.201504257183, R2 score : 0.542369738697831\n",
      "Epoch = 4 : Training loss = 3127.2756022193867, R2 score : 0.5802355140022023\n",
      "Epoch = 5 : Training loss = 3107.7510050194546, R2 score : 0.5359800425746403\n",
      "Epoch = 6 : Training loss = 3127.8592949620947, R2 score : 0.6385859661249067\n",
      "Epoch = 7 : Training loss = 3163.8600988771746, R2 score : 0.6117857457033713\n",
      "Epoch = 8 : Training loss = 3106.8735151875344, R2 score : 0.6194601389876269\n",
      "Epoch = 9 : Training loss = 3101.845655543839, R2 score : 0.6475607471840359\n",
      "Epoch = 10 : Training loss = 3095.0118884578724, R2 score : 0.6480378248103981\n",
      "Epoch = 11 : Training loss = 3074.239939045554, R2 score : 0.6255249053571457\n",
      "Epoch = 12 : Training loss = 3090.4453180708633, R2 score : 0.6299045433336312\n",
      "Epoch = 13 : Training loss = 3094.134779166943, R2 score : 0.5835425809250177\n",
      "Epoch = 14 : Training loss = 3070.516580718678, R2 score : 0.5709122945886096\n",
      "Epoch = 15 : Training loss = 3060.3608763082566, R2 score : 0.5295411414640064\n",
      "Epoch = 16 : Training loss = 3072.0341483430734, R2 score : 0.541939166285244\n",
      "Epoch = 17 : Training loss = 3058.908301237532, R2 score : 0.6275670045851138\n",
      "Epoch = 18 : Training loss = 3053.584107807982, R2 score : 0.5408415235301315\n",
      "Epoch = 19 : Training loss = 3037.7011766664477, R2 score : 0.5664442152173434\n",
      "Epoch = 20 : Training loss = 3050.8121612405926, R2 score : 0.6275628429468711\n",
      "Epoch = 21 : Training loss = 3040.4694194199424, R2 score : 0.5827417082021741\n",
      "Epoch = 22 : Training loss = 3058.961493115188, R2 score : 0.5267969578892518\n",
      "Epoch = 23 : Training loss = 3034.7836217743898, R2 score : 0.5347032428342864\n",
      "Epoch = 24 : Training loss = 3030.0952684202093, R2 score : 0.5563510343727138\n",
      "Epoch = 25 : Training loss = 3041.151901215303, R2 score : 0.564741343308991\n",
      "Epoch = 26 : Training loss = 3034.342288185414, R2 score : 0.551800056205076\n",
      "Epoch = 27 : Training loss = 3034.5230495266114, R2 score : 0.5638338802181865\n",
      "Epoch = 28 : Training loss = 3057.179960894942, R2 score : 0.4975444699020173\n",
      "Epoch = 29 : Training loss = 3033.7910273708344, R2 score : 0.5961679434497673\n",
      "Epoch = 30 : Training loss = 3045.036148899621, R2 score : 0.5928327386133766\n",
      "Epoch = 31 : Training loss = 3004.831330305671, R2 score : 0.5582294645129744\n",
      "Epoch = 32 : Training loss = 3041.8277148190696, R2 score : 0.5421501587370087\n",
      "Epoch = 33 : Training loss = 3019.3778084794076, R2 score : 0.5492466702995885\n",
      "Epoch = 34 : Training loss = 3014.689511160277, R2 score : 0.5547130987743902\n",
      "Epoch = 35 : Training loss = 3015.6636000866174, R2 score : 0.6446710012697234\n",
      "Epoch = 36 : Training loss = 3010.728882067656, R2 score : 0.5964396266309113\n",
      "Epoch = 37 : Training loss = 3018.8771305522946, R2 score : 0.6494003175426148\n",
      "Epoch = 38 : Training loss = 3010.4199966338556, R2 score : 0.6026273757432927\n",
      "Epoch = 39 : Training loss = 3011.3929820155345, R2 score : 0.6077305341507947\n",
      "Epoch = 40 : Training loss = 2995.1779811153656, R2 score : 0.5280950914556961\n",
      "Epoch = 41 : Training loss = 2990.4234926759505, R2 score : 0.6008115471799332\n",
      "Epoch = 42 : Training loss = 2998.8287282012716, R2 score : 0.5222789753681236\n",
      "Epoch = 43 : Training loss = 3004.681785844588, R2 score : 0.5517179533186793\n",
      "Epoch = 44 : Training loss = 3004.1915694085283, R2 score : 0.5843156986692711\n",
      "Epoch = 45 : Training loss = 2976.453530918206, R2 score : 0.58545287938008\n",
      "Epoch = 46 : Training loss = 2980.9321354020926, R2 score : 0.6516728070513549\n",
      "Epoch = 47 : Training loss = 2985.794731460186, R2 score : 0.6488495448755844\n",
      "Epoch = 48 : Training loss = 2980.164330295126, R2 score : 0.5905605151753668\n",
      "Epoch = 49 : Training loss = 2983.21875536572, R2 score : 0.6131463103993315\n",
      "Epoch = 50 : Training loss = 3006.297320741427, R2 score : 0.6011657970338709\n",
      "Epoch = 51 : Training loss = 2981.8684207503766, R2 score : 0.6206461435265799\n",
      "Epoch = 52 : Training loss = 2976.5044183527853, R2 score : 0.5295729643954963\n",
      "Epoch = 53 : Training loss = 2974.3066998443833, R2 score : 0.5477196702509368\n",
      "Epoch = 54 : Training loss = 2965.734718921003, R2 score : 0.508373602918009\n",
      "Epoch = 55 : Training loss = 2973.5340481369794, R2 score : 0.4968098071831384\n",
      "Epoch = 56 : Training loss = 3018.8478395197044, R2 score : 0.5351064595408435\n",
      "Epoch = 57 : Training loss = 3008.4145062495236, R2 score : 0.5518925626326256\n",
      "Epoch = 58 : Training loss = 2947.4032827762694, R2 score : 0.6035980169804017\n",
      "Epoch = 59 : Training loss = 2953.3859864053084, R2 score : 0.5875869243790706\n",
      "Epoch = 60 : Training loss = 2956.970979305447, R2 score : 0.598312890978201\n",
      "Epoch = 61 : Training loss = 2945.471877418624, R2 score : 0.5666307467613233\n",
      "Epoch = 62 : Training loss = 2963.683332311927, R2 score : 0.634636037861819\n",
      "Epoch = 63 : Training loss = 2995.069491552707, R2 score : 0.4166423369361184\n",
      "Epoch = 64 : Training loss = 2950.623201122892, R2 score : 0.5772209984518442\n",
      "Epoch = 65 : Training loss = 2958.353742470468, R2 score : 0.6568768795760171\n",
      "Epoch = 66 : Training loss = 2979.147906006565, R2 score : 0.6285179422623455\n",
      "Epoch = 67 : Training loss = 2944.7925829653127, R2 score : 0.5898316081268753\n",
      "Epoch = 68 : Training loss = 2972.959096229726, R2 score : 0.5429262881530444\n",
      "Epoch = 69 : Training loss = 2924.6565508654567, R2 score : 0.6031480904332551\n",
      "Epoch = 70 : Training loss = 2933.8574441013534, R2 score : 0.5824712436617037\n",
      "Epoch = 71 : Training loss = 2987.548955855842, R2 score : 0.5967142666666279\n",
      "Epoch = 72 : Training loss = 2963.4808944735087, R2 score : 0.5213217330331197\n",
      "Epoch = 73 : Training loss = 2958.768635050258, R2 score : 0.6203341756559788\n",
      "Epoch = 74 : Training loss = 2958.339404806914, R2 score : 0.5354983046139974\n",
      "Epoch = 75 : Training loss = 2926.1506141200603, R2 score : 0.5900201553150437\n",
      "Epoch = 76 : Training loss = 2933.3365354160183, R2 score : 0.5493664891911173\n",
      "Epoch = 77 : Training loss = 2918.3991140867056, R2 score : 0.5770198369201808\n",
      "Epoch = 78 : Training loss = 2935.930816833521, R2 score : 0.4830797228852891\n",
      "Epoch = 79 : Training loss = 2944.6857425396356, R2 score : 0.5383541727579726\n",
      "Epoch = 80 : Training loss = 2924.181992026174, R2 score : 0.5784056464905062\n",
      "Epoch = 81 : Training loss = 2926.3967887962226, R2 score : 0.5801410662980507\n",
      "Epoch = 82 : Training loss = 2927.685919755322, R2 score : 0.6506943370010239\n",
      "Epoch = 83 : Training loss = 2919.919323968004, R2 score : 0.5399602613535044\n",
      "Epoch = 84 : Training loss = 2941.749651944694, R2 score : 0.5215468605250038\n",
      "Epoch = 85 : Training loss = 2920.177699471011, R2 score : 0.5135968325331584\n",
      "Epoch = 86 : Training loss = 2896.8110281335394, R2 score : 0.5825075832803928\n",
      "Epoch = 87 : Training loss = 2918.7882327271777, R2 score : 0.5356523054976912\n",
      "Epoch = 88 : Training loss = 2915.4164915562073, R2 score : 0.49713383679492895\n",
      "Epoch = 89 : Training loss = 2909.971271439431, R2 score : 0.6137316271841367\n",
      "Epoch = 90 : Training loss = 2908.261688852594, R2 score : 0.48951316210968965\n",
      "Epoch = 91 : Training loss = 2912.5137178006044, R2 score : 0.6126023329822463\n",
      "Epoch = 92 : Training loss = 2897.1526613463648, R2 score : 0.5834106435037246\n",
      "Epoch = 93 : Training loss = 2893.5523400314023, R2 score : 0.5434541811321343\n",
      "Epoch = 94 : Training loss = 2944.695441168868, R2 score : 0.4760504068447109\n",
      "Epoch = 95 : Training loss = 2933.325570734437, R2 score : 0.4244787390056487\n",
      "Epoch = 96 : Training loss = 2906.1999964205706, R2 score : 0.49570568004043825\n",
      "Epoch = 97 : Training loss = 2912.173942037098, R2 score : 0.529254065896287\n",
      "Epoch = 98 : Training loss = 2923.108976852134, R2 score : 0.6865656609891513\n",
      "Epoch = 99 : Training loss = 2893.843443258688, R2 score : 0.6172787470257769\n",
      "Epoch = 100 : Training loss = 2904.5189939507018, R2 score : 0.4230532283931322\n",
      "Epoch = 101 : Training loss = 2875.414354529049, R2 score : 0.5290471304633817\n",
      "Epoch = 102 : Training loss = 2937.139591722511, R2 score : 0.6124889944196505\n",
      "Epoch = 103 : Training loss = 2905.2901185609353, R2 score : 0.47401095541617333\n",
      "Epoch = 104 : Training loss = 2927.0055571199487, R2 score : 0.6182616800337701\n",
      "Epoch = 105 : Training loss = 2900.614212547789, R2 score : 0.5303831487297042\n",
      "Epoch = 106 : Training loss = 2926.889629911498, R2 score : 0.6045054982105198\n",
      "Epoch = 107 : Training loss = 2865.9087340296055, R2 score : 0.5970652465666524\n",
      "Epoch = 108 : Training loss = 2916.488474026044, R2 score : 0.529512327902516\n",
      "Epoch = 109 : Training loss = 2908.865625458565, R2 score : 0.6188226398086336\n",
      "Epoch = 110 : Training loss = 2888.5455857324837, R2 score : 0.5248414456254828\n",
      "Epoch = 111 : Training loss = 2864.550225197908, R2 score : 0.507877096703969\n",
      "Epoch = 112 : Training loss = 2886.8827154795927, R2 score : 0.4872547942518338\n",
      "Epoch = 113 : Training loss = 2862.530739162493, R2 score : 0.5727959967131477\n",
      "Epoch = 114 : Training loss = 2860.051242463127, R2 score : 0.5267524698861857\n",
      "Epoch = 115 : Training loss = 2889.7460697551483, R2 score : 0.5952291194839658\n",
      "Epoch = 116 : Training loss = 2870.453392263331, R2 score : 0.5602025703263602\n",
      "Epoch = 117 : Training loss = 2867.6317425160887, R2 score : 0.582525404854803\n",
      "Epoch = 118 : Training loss = 2875.00002927861, R2 score : 0.5028178501789313\n",
      "Epoch = 119 : Training loss = 2848.4670059045557, R2 score : 0.5768896326040873\n",
      "Epoch = 120 : Training loss = 2843.7646555367737, R2 score : 0.5652503806036508\n",
      "Epoch = 121 : Training loss = 2886.120317043716, R2 score : 0.6391374412644674\n",
      "Epoch = 122 : Training loss = 2882.771382483833, R2 score : 0.5538849234376777\n",
      "Epoch = 123 : Training loss = 2856.8240040844926, R2 score : 0.47674671348773257\n",
      "Epoch = 124 : Training loss = 2869.8785890108775, R2 score : 0.46793282745620124\n",
      "Epoch = 125 : Training loss = 2893.958108268259, R2 score : 0.6220429048770058\n",
      "Epoch = 126 : Training loss = 2853.408902249128, R2 score : 0.5473479362198705\n",
      "Epoch = 127 : Training loss = 2833.451200160931, R2 score : 0.48992591317579315\n",
      "Epoch = 128 : Training loss = 2825.946481454438, R2 score : 0.5641855000581463\n",
      "Epoch = 129 : Training loss = 2829.2008963322796, R2 score : 0.5634328014209211\n",
      "Epoch = 130 : Training loss = 2837.9481479407677, R2 score : 0.5828476485537449\n",
      "Epoch = 131 : Training loss = 2828.8276460784855, R2 score : 0.5751735425356781\n",
      "Epoch = 132 : Training loss = 2854.449306741466, R2 score : 0.5747374181221858\n",
      "Epoch = 133 : Training loss = 2836.0297830482345, R2 score : 0.6085208482591321\n",
      "Epoch = 134 : Training loss = 2827.1120658498853, R2 score : 0.5844781554618186\n",
      "Epoch = 135 : Training loss = 2827.056014562412, R2 score : 0.5223929779946658\n",
      "Epoch = 136 : Training loss = 2815.9766606619505, R2 score : 0.5352584680936167\n",
      "Epoch = 137 : Training loss = 2860.5943789863013, R2 score : 0.5093954253309492\n",
      "Epoch = 138 : Training loss = 2824.034274739109, R2 score : 0.5842650305779113\n",
      "Epoch = 139 : Training loss = 2824.372183221368, R2 score : 0.5318973034977891\n",
      "Epoch = 140 : Training loss = 2835.0314391995894, R2 score : 0.6332644573062098\n",
      "Epoch = 141 : Training loss = 2826.2348465895066, R2 score : 0.5541644234790783\n",
      "Epoch = 142 : Training loss = 2847.2736994938987, R2 score : 0.5815042276678659\n",
      "Epoch = 143 : Training loss = 2817.5568688125504, R2 score : 0.5565032494264408\n",
      "Epoch = 144 : Training loss = 2826.6398026305633, R2 score : 0.520412217567225\n",
      "Epoch = 145 : Training loss = 2831.913129315347, R2 score : 0.5367917413173752\n",
      "Epoch = 146 : Training loss = 2847.6346166175294, R2 score : 0.586652782605343\n",
      "Epoch = 147 : Training loss = 2808.0694003993444, R2 score : 0.5432867717286227\n",
      "Epoch = 148 : Training loss = 2857.6090667346134, R2 score : 0.4083938786164498\n",
      "Epoch = 149 : Training loss = 2806.487061114939, R2 score : 0.5227317603963298\n",
      "Epoch = 150 : Training loss = 2868.015150771782, R2 score : 0.46554348806047996\n",
      "Epoch = 151 : Training loss = 2838.163476329536, R2 score : 0.5881145319476807\n",
      "Epoch = 152 : Training loss = 2810.433309319388, R2 score : 0.5269109250423504\n",
      "Epoch = 153 : Training loss = 2811.2079338335434, R2 score : 0.5833928144510914\n",
      "Epoch = 154 : Training loss = 2794.568509265083, R2 score : 0.5174511356382678\n",
      "Epoch = 155 : Training loss = 2826.8426261008653, R2 score : 0.6298773509775322\n",
      "Epoch = 156 : Training loss = 2811.7452327544515, R2 score : 0.5790594878147055\n",
      "Epoch = 157 : Training loss = 2832.1568435349623, R2 score : 0.5797544790581443\n",
      "Epoch = 158 : Training loss = 2813.0207707782793, R2 score : 0.4973029444360747\n",
      "Epoch = 159 : Training loss = 2807.2873256164285, R2 score : 0.5684194695787043\n",
      "Epoch = 160 : Training loss = 2808.6044606548176, R2 score : 0.5636406562345959\n",
      "Epoch = 161 : Training loss = 2814.30928583327, R2 score : 0.44822162018604184\n",
      "Epoch = 162 : Training loss = 2841.9749404410345, R2 score : 0.4875549129364154\n",
      "Epoch = 163 : Training loss = 2794.7940410952488, R2 score : 0.5608722908168113\n",
      "Epoch = 164 : Training loss = 2783.0128547702184, R2 score : 0.5485983092715552\n",
      "Epoch = 165 : Training loss = 2835.5950374768245, R2 score : 0.5197006336099046\n",
      "Epoch = 166 : Training loss = 2805.499147291662, R2 score : 0.5579283262563417\n",
      "Epoch = 167 : Training loss = 2810.3289104133128, R2 score : 0.5716446093329643\n",
      "Epoch = 168 : Training loss = 2801.5948382856313, R2 score : 0.5732768936734347\n",
      "Epoch = 169 : Training loss = 2819.713437318484, R2 score : 0.5949662652716512\n",
      "Epoch = 170 : Training loss = 2798.9432609194955, R2 score : 0.5547725890371025\n",
      "Epoch = 171 : Training loss = 2805.7914696708517, R2 score : 0.441675462553181\n",
      "Epoch = 172 : Training loss = 2809.707408809264, R2 score : 0.6032977699508075\n",
      "Epoch = 173 : Training loss = 2802.9277222909204, R2 score : 0.48032708851557493\n",
      "Epoch = 174 : Training loss = 2786.733300778493, R2 score : 0.5698798174470647\n",
      "Epoch = 175 : Training loss = 2793.238790789576, R2 score : 0.5021886571809482\n",
      "Epoch = 176 : Training loss = 2782.795874218218, R2 score : 0.5313971746035494\n",
      "Epoch = 177 : Training loss = 2788.6326303668493, R2 score : 0.5519486974243153\n",
      "Epoch = 178 : Training loss = 2765.2361451987736, R2 score : 0.6050720564748111\n",
      "Epoch = 179 : Training loss = 2806.26193303401, R2 score : 0.5856728159967903\n",
      "Epoch = 180 : Training loss = 2779.5999213073264, R2 score : 0.4811711450480982\n",
      "Epoch = 181 : Training loss = 2812.8315541500647, R2 score : 0.6162073745714821\n",
      "Epoch = 182 : Training loss = 2787.700054808769, R2 score : 0.5137399649731953\n",
      "Epoch = 183 : Training loss = 2797.6404652445744, R2 score : 0.5159492994822917\n",
      "Epoch = 184 : Training loss = 2753.5897374157908, R2 score : 0.549914396825476\n",
      "Epoch = 185 : Training loss = 2764.897145046866, R2 score : 0.5087666423220456\n",
      "Epoch = 186 : Training loss = 2777.502660611787, R2 score : 0.5767538077564849\n",
      "Epoch = 187 : Training loss = 2784.9514340306905, R2 score : 0.5186864722340893\n",
      "Epoch = 188 : Training loss = 2784.8438809796644, R2 score : 0.5745012965742471\n",
      "Epoch = 189 : Training loss = 2773.2233556093897, R2 score : 0.5037557911866859\n",
      "Epoch = 190 : Training loss = 2744.6198991462834, R2 score : 0.5417497134004721\n",
      "Epoch = 191 : Training loss = 2771.0896349429513, R2 score : 0.6389087209668123\n",
      "Epoch = 192 : Training loss = 2757.1168324476876, R2 score : 0.488163272718127\n",
      "Epoch = 193 : Training loss = 2752.6255848003802, R2 score : 0.537792934360688\n",
      "Epoch = 194 : Training loss = 2780.5891282456673, R2 score : 0.6215820626214558\n",
      "Epoch = 195 : Training loss = 2758.0881870062412, R2 score : 0.534505501707798\n",
      "Epoch = 196 : Training loss = 2809.6142705644625, R2 score : 0.5149987965557333\n",
      "Epoch = 197 : Training loss = 2749.0354836707465, R2 score : 0.5066253207891208\n",
      "Epoch = 198 : Training loss = 2747.2393446454316, R2 score : 0.5462319385675805\n",
      "Epoch = 199 : Training loss = 2749.0585964933384, R2 score : 0.5212495248173397\n",
      "Epoch = 200 : Training loss = 2754.980639139298, R2 score : 0.4941131590040245\n",
      "Epoch = 201 : Training loss = 2765.903064827865, R2 score : 0.48149981751385174\n",
      "Epoch = 202 : Training loss = 2756.3002853285548, R2 score : 0.5573912688779598\n",
      "Epoch = 203 : Training loss = 2746.4293536271903, R2 score : 0.4984272880758568\n",
      "Epoch = 204 : Training loss = 2743.883936773085, R2 score : 0.5192460432139828\n",
      "Epoch = 205 : Training loss = 2767.001982295159, R2 score : 0.5821493259560975\n",
      "Epoch = 206 : Training loss = 2759.7842253847443, R2 score : 0.541111999985538\n",
      "Epoch = 207 : Training loss = 2733.0641400592317, R2 score : 0.5146683264942407\n",
      "Epoch = 208 : Training loss = 2746.204248320322, R2 score : 0.5335793829660873\n",
      "Epoch = 209 : Training loss = 2790.9109984048837, R2 score : 0.508677344361101\n",
      "Epoch = 210 : Training loss = 2752.9750223587607, R2 score : 0.5811230385343438\n",
      "Epoch = 211 : Training loss = 2748.258342892951, R2 score : 0.5709273107065866\n",
      "Epoch = 212 : Training loss = 2750.1981995602073, R2 score : 0.5160188258587253\n",
      "Epoch = 213 : Training loss = 2731.9747003033035, R2 score : 0.5529433737971718\n",
      "Epoch = 214 : Training loss = 2743.093696046555, R2 score : 0.5401960853220913\n",
      "Epoch = 215 : Training loss = 2750.2131576923807, R2 score : 0.5591607997330127\n",
      "Epoch = 216 : Training loss = 2765.6276581259926, R2 score : 0.4406469296203882\n",
      "Epoch = 217 : Training loss = 2733.143240793622, R2 score : 0.5410245729222589\n",
      "Epoch = 218 : Training loss = 2781.6723218968045, R2 score : 0.6384414856882475\n",
      "Epoch = 219 : Training loss = 2732.8859694029925, R2 score : 0.5401489585445867\n",
      "Epoch = 220 : Training loss = 2766.497609150354, R2 score : 0.6154330269861411\n",
      "Epoch = 221 : Training loss = 2715.8678764896076, R2 score : 0.4794520998564704\n",
      "Epoch = 222 : Training loss = 2709.2083859997833, R2 score : 0.5253490862058315\n",
      "Epoch = 223 : Training loss = 2725.888114948547, R2 score : 0.6137954857526786\n",
      "Epoch = 224 : Training loss = 2784.0413237262487, R2 score : 0.4941634930837657\n",
      "Epoch = 225 : Training loss = 2752.864238596131, R2 score : 0.53073039938368\n",
      "Epoch = 226 : Training loss = 2753.711669611104, R2 score : 0.5670198130245665\n",
      "Epoch = 227 : Training loss = 2755.6938844921638, R2 score : 0.5102283402377902\n",
      "Epoch = 228 : Training loss = 2747.9301042091283, R2 score : 0.5916436597829562\n",
      "Epoch = 229 : Training loss = 2739.15723733102, R2 score : 0.5092883026269515\n",
      "Epoch = 230 : Training loss = 2712.490427317298, R2 score : 0.6037438331833536\n",
      "Epoch = 231 : Training loss = 2733.612925485756, R2 score : 0.5637998007356825\n",
      "Epoch = 232 : Training loss = 2706.540364482108, R2 score : 0.5339731389199385\n",
      "Epoch = 233 : Training loss = 2734.1075272674198, R2 score : 0.5426735406250267\n",
      "Epoch = 234 : Training loss = 2737.790942825059, R2 score : 0.5792074034209225\n",
      "Epoch = 235 : Training loss = 2770.326952813524, R2 score : 0.5012868362913969\n",
      "Epoch = 236 : Training loss = 2712.796612118516, R2 score : 0.5294859480974035\n",
      "Epoch = 237 : Training loss = 2704.611891837807, R2 score : 0.571115074610849\n",
      "Epoch = 238 : Training loss = 2694.7399346567354, R2 score : 0.5405298076758682\n",
      "Epoch = 239 : Training loss = 2709.4876200637023, R2 score : 0.542907514945274\n",
      "Epoch = 240 : Training loss = 2696.7861842420753, R2 score : 0.5302508572824909\n",
      "Epoch = 241 : Training loss = 2700.048770063487, R2 score : 0.47987248713748965\n",
      "Epoch = 242 : Training loss = 2720.8555416479185, R2 score : 0.47875516065653223\n",
      "Epoch = 243 : Training loss = 2750.688486054857, R2 score : 0.5569876592068241\n",
      "Epoch = 244 : Training loss = 2702.0869635026515, R2 score : 0.5348015851910146\n",
      "Epoch = 245 : Training loss = 2723.396341243576, R2 score : 0.5657628970943691\n",
      "Epoch = 246 : Training loss = 2692.140753785443, R2 score : 0.465296471864702\n",
      "Epoch = 247 : Training loss = 2678.380366918283, R2 score : 0.5590112259001608\n",
      "Epoch = 248 : Training loss = 2706.507472341691, R2 score : 0.6033828044021167\n",
      "Epoch = 249 : Training loss = 2697.548257531156, R2 score : 0.5371805070994968\n",
      "Epoch = 250 : Training loss = 2700.0567588240688, R2 score : 0.4846032372488638\n",
      "Epoch = 251 : Training loss = 2696.1505387786156, R2 score : 0.4802062058396479\n",
      "Epoch = 252 : Training loss = 2741.9669163201625, R2 score : 0.6132538657518435\n",
      "Epoch = 253 : Training loss = 2725.9942241953195, R2 score : 0.5285601724658737\n",
      "Epoch = 254 : Training loss = 2678.179216339446, R2 score : 0.48350459981934035\n",
      "Epoch = 255 : Training loss = 2693.1608706034494, R2 score : 0.5675338900944771\n",
      "Epoch = 256 : Training loss = 2727.2658549201215, R2 score : 0.4573100911355339\n",
      "Epoch = 257 : Training loss = 2682.1047201281517, R2 score : 0.5943065619360004\n",
      "Epoch = 258 : Training loss = 2729.0996561589554, R2 score : 0.5492580165123814\n",
      "Epoch = 259 : Training loss = 2736.7772100604593, R2 score : 0.48738933997147027\n",
      "Epoch = 260 : Training loss = 2672.5977599657895, R2 score : 0.5717539685650872\n",
      "Epoch = 261 : Training loss = 2697.3468798252557, R2 score : 0.5256436497199857\n",
      "Epoch = 262 : Training loss = 2678.2638733988674, R2 score : 0.4700978938269924\n",
      "Epoch = 263 : Training loss = 2672.494767104252, R2 score : 0.48982607320878147\n",
      "Epoch = 264 : Training loss = 2683.088246759601, R2 score : 0.46483719423387115\n",
      "Epoch = 265 : Training loss = 2662.005350880475, R2 score : 0.5005081552862614\n",
      "Epoch = 266 : Training loss = 2680.32556669723, R2 score : 0.46141639340462015\n",
      "Epoch = 267 : Training loss = 2684.9191262002714, R2 score : 0.5354773400020132\n",
      "Epoch = 268 : Training loss = 2667.547370016751, R2 score : 0.5403701496193056\n",
      "Epoch = 269 : Training loss = 2707.7884881217205, R2 score : 0.42208066535410227\n",
      "Epoch = 270 : Training loss = 2684.972532198669, R2 score : 0.5674275853068996\n",
      "Epoch = 271 : Training loss = 2680.219008358767, R2 score : 0.44507558270699\n",
      "Epoch = 272 : Training loss = 2709.2419425723638, R2 score : 0.5591706904896265\n",
      "Epoch = 273 : Training loss = 2668.223104586869, R2 score : 0.47208011243640513\n",
      "Epoch = 274 : Training loss = 2707.6234286204026, R2 score : 0.527937733656995\n",
      "Epoch = 275 : Training loss = 2701.9902341415536, R2 score : 0.49161549640687363\n",
      "Epoch = 276 : Training loss = 2669.7012948360825, R2 score : 0.4793542211117463\n",
      "Epoch = 277 : Training loss = 2688.4522348720484, R2 score : 0.5839018535862776\n",
      "Epoch = 278 : Training loss = 2681.0589218771615, R2 score : 0.5392420019353784\n",
      "Epoch = 279 : Training loss = 2668.659554608177, R2 score : 0.505525451398323\n",
      "Epoch = 280 : Training loss = 2673.023016902899, R2 score : 0.5762718215085432\n",
      "Epoch = 281 : Training loss = 2677.0365713886213, R2 score : 0.560099464859665\n",
      "Epoch = 282 : Training loss = 2671.3077068919047, R2 score : 0.5229488613481825\n",
      "Epoch = 283 : Training loss = 2647.372086029571, R2 score : 0.4950786114837965\n",
      "Epoch = 284 : Training loss = 2712.7892662132845, R2 score : 0.34470711535348275\n",
      "Epoch = 285 : Training loss = 2682.745797539114, R2 score : 0.5690501826399508\n",
      "Epoch = 286 : Training loss = 2642.3278978946405, R2 score : 0.5605749322065269\n",
      "Epoch = 287 : Training loss = 2685.1860139392306, R2 score : 0.5808870229744962\n",
      "Epoch = 288 : Training loss = 2660.2850970437994, R2 score : 0.4971845195236907\n",
      "Epoch = 289 : Training loss = 2667.8270205575363, R2 score : 0.448553178499949\n",
      "Epoch = 290 : Training loss = 2658.412301808177, R2 score : 0.521916770393106\n",
      "Epoch = 291 : Training loss = 2666.756547071681, R2 score : 0.44649437264535696\n",
      "Epoch = 292 : Training loss = 2640.6201283502337, R2 score : 0.5704695520199883\n",
      "Epoch = 293 : Training loss = 2664.2892667443202, R2 score : 0.4596732522999124\n",
      "Epoch = 294 : Training loss = 2700.110462551377, R2 score : 0.6794717760182342\n",
      "Epoch = 295 : Training loss = 2654.1086656513717, R2 score : 0.5703451252350736\n",
      "Epoch = 296 : Training loss = 2665.08751353133, R2 score : 0.4980945325470044\n",
      "Epoch = 297 : Training loss = 2662.9448982430577, R2 score : 0.4493849767579359\n",
      "Epoch = 298 : Training loss = 2631.595380052507, R2 score : 0.5444752836103555\n",
      "Epoch = 299 : Training loss = 2679.5373798917217, R2 score : 0.5095711921839584\n",
      "Epoch = 300 : Training loss = 2618.78852882119, R2 score : 0.5245373331578792\n",
      "Epoch = 301 : Training loss = 2644.4901264165273, R2 score : 0.5927654090944228\n",
      "Epoch = 302 : Training loss = 2631.0021666449343, R2 score : 0.5182883706480764\n",
      "Epoch = 303 : Training loss = 2622.859737948913, R2 score : 0.5132104434901741\n",
      "Epoch = 304 : Training loss = 2641.4429676312643, R2 score : 0.5056690881899193\n",
      "Epoch = 305 : Training loss = 2642.0780859118777, R2 score : 0.5450646533391251\n",
      "Epoch = 306 : Training loss = 2672.666256336075, R2 score : 0.5067344379978849\n",
      "Epoch = 307 : Training loss = 2606.2252068348994, R2 score : 0.526523592566949\n",
      "Epoch = 308 : Training loss = 2633.9809581061854, R2 score : 0.5511544132057906\n",
      "Epoch = 309 : Training loss = 2628.393790104543, R2 score : 0.482439964256951\n",
      "Epoch = 310 : Training loss = 2620.086717138309, R2 score : 0.5479946424941317\n",
      "Epoch = 311 : Training loss = 2608.187646838555, R2 score : 0.5350570904550918\n",
      "Epoch = 312 : Training loss = 2629.470853971963, R2 score : 0.5413707191962817\n",
      "Epoch = 313 : Training loss = 2620.796186171221, R2 score : 0.5413302778434863\n",
      "Epoch = 314 : Training loss = 2635.748287536035, R2 score : 0.5314428042374268\n",
      "Epoch = 315 : Training loss = 2648.241824908724, R2 score : 0.593423544170766\n",
      "Epoch = 316 : Training loss = 2609.712506139418, R2 score : 0.5011776579755012\n",
      "Epoch = 317 : Training loss = 2626.8794840247274, R2 score : 0.5297783667535747\n",
      "Epoch = 318 : Training loss = 2639.455103706948, R2 score : 0.4834174407547126\n",
      "Epoch = 319 : Training loss = 2644.519420154803, R2 score : 0.4560376273182756\n",
      "Epoch = 320 : Training loss = 2619.1444058010175, R2 score : 0.4635576751589501\n",
      "Epoch = 321 : Training loss = 2648.7629870214128, R2 score : 0.470795871580137\n",
      "Epoch = 322 : Training loss = 2629.3832855329283, R2 score : 0.5196169859954998\n",
      "Epoch = 323 : Training loss = 2625.837488929322, R2 score : 0.5615174305786361\n",
      "Epoch = 324 : Training loss = 2607.327652651854, R2 score : 0.6016284374369638\n",
      "Epoch = 325 : Training loss = 2603.826025854307, R2 score : 0.5019875342010518\n",
      "Epoch = 326 : Training loss = 2599.0449091986056, R2 score : 0.5611111400267813\n",
      "Epoch = 327 : Training loss = 2622.0823843600256, R2 score : 0.5009847487157046\n",
      "Epoch = 328 : Training loss = 2584.44212585294, R2 score : 0.4920538212098652\n",
      "Epoch = 329 : Training loss = 2591.7473486268377, R2 score : 0.5032113539554417\n",
      "Epoch = 330 : Training loss = 2619.305323962415, R2 score : 0.5203508880481471\n",
      "Epoch = 331 : Training loss = 2648.7719229249647, R2 score : 0.47691095502874337\n",
      "Epoch = 332 : Training loss = 2658.080671710736, R2 score : 0.47256198211609446\n",
      "Epoch = 333 : Training loss = 2601.038234107963, R2 score : 0.5642272818721745\n",
      "Epoch = 334 : Training loss = 2596.47594890271, R2 score : 0.49562630505038463\n",
      "Epoch = 335 : Training loss = 2588.061154874908, R2 score : 0.573498149630788\n",
      "Epoch = 336 : Training loss = 2638.528931498961, R2 score : 0.5185564465691463\n",
      "Epoch = 337 : Training loss = 2638.4559309597516, R2 score : 0.4437986085212976\n",
      "Epoch = 338 : Training loss = 2603.124518725748, R2 score : 0.47293880163591706\n",
      "Epoch = 339 : Training loss = 2627.5004375004755, R2 score : 0.5238054471841234\n",
      "Epoch = 340 : Training loss = 2595.7152624803884, R2 score : 0.5516914394300177\n",
      "Epoch = 341 : Training loss = 2602.965545202217, R2 score : 0.5335034431483492\n",
      "Epoch = 342 : Training loss = 2605.7270036682185, R2 score : 0.5309654815126983\n",
      "Epoch = 343 : Training loss = 2619.84437585015, R2 score : 0.5816562954165007\n",
      "Epoch = 344 : Training loss = 2588.856817186746, R2 score : 0.5422998900457229\n",
      "Epoch = 345 : Training loss = 2643.364451153421, R2 score : 0.4949841096246138\n",
      "Epoch = 346 : Training loss = 2591.6641666390797, R2 score : 0.5071151336177524\n",
      "Epoch = 347 : Training loss = 2591.8298337463693, R2 score : 0.5011993922548601\n",
      "Epoch = 348 : Training loss = 2615.655017403707, R2 score : 0.5233901801381682\n",
      "Epoch = 349 : Training loss = 2582.4946857269692, R2 score : 0.5109216048508687\n",
      "Epoch = 350 : Training loss = 2572.119030593537, R2 score : 0.5063922857679615\n",
      "Epoch = 351 : Training loss = 2597.6298310746215, R2 score : 0.4341444473725925\n",
      "Epoch = 352 : Training loss = 2588.7628696305164, R2 score : 0.544516870366389\n",
      "Epoch = 353 : Training loss = 2610.9661751829467, R2 score : 0.47575864701751724\n",
      "Epoch = 354 : Training loss = 2609.543766690767, R2 score : 0.4826261730586976\n",
      "Epoch = 355 : Training loss = 2578.871629963825, R2 score : 0.5098999344714177\n",
      "Epoch = 356 : Training loss = 2600.0991062551584, R2 score : 0.47897924753188104\n",
      "Epoch = 357 : Training loss = 2603.2885502457666, R2 score : 0.5550268153537674\n",
      "Epoch = 358 : Training loss = 2606.602403568014, R2 score : 0.4843104314674126\n",
      "Epoch = 359 : Training loss = 2580.6871054800504, R2 score : 0.527222862572563\n",
      "Epoch = 360 : Training loss = 2611.141131075108, R2 score : 0.47979531940846953\n",
      "Epoch = 361 : Training loss = 2606.6760241495167, R2 score : 0.4989646290223291\n",
      "Epoch = 362 : Training loss = 2628.786857656697, R2 score : 0.5595619835115038\n",
      "Epoch = 363 : Training loss = 2595.9458682342606, R2 score : 0.5269195333021983\n",
      "Epoch = 364 : Training loss = 2588.9170964565433, R2 score : 0.4450275280599525\n",
      "Epoch = 365 : Training loss = 2578.739939310945, R2 score : 0.46060658682966027\n",
      "Epoch = 366 : Training loss = 2593.6662751090253, R2 score : 0.45549331583877695\n",
      "Epoch = 367 : Training loss = 2591.263724483345, R2 score : 0.5709066151007223\n",
      "Epoch = 368 : Training loss = 2579.372286691673, R2 score : 0.44788322005306036\n",
      "Epoch = 369 : Training loss = 2594.806545504738, R2 score : 0.510704411010507\n",
      "Epoch = 370 : Training loss = 2637.653557837302, R2 score : 0.5254278264877068\n",
      "Epoch = 371 : Training loss = 2598.6325512683743, R2 score : 0.5481697238563228\n",
      "Epoch = 372 : Training loss = 2578.032312170526, R2 score : 0.38730716614981264\n",
      "Epoch = 373 : Training loss = 2544.612310412699, R2 score : 0.5022204558502936\n",
      "Epoch = 374 : Training loss = 2600.8232803068613, R2 score : 0.5778486691525266\n",
      "Epoch = 375 : Training loss = 2564.6269397693936, R2 score : 0.4241354120315747\n",
      "Epoch = 376 : Training loss = 2574.30775998949, R2 score : 0.5921289961089783\n",
      "Epoch = 377 : Training loss = 2551.886849153968, R2 score : 0.47297520444526575\n",
      "Epoch = 378 : Training loss = 2582.910411233777, R2 score : 0.5360158523139497\n",
      "Epoch = 379 : Training loss = 2565.094518636436, R2 score : 0.48813559106997173\n",
      "Epoch = 380 : Training loss = 2589.8820292184464, R2 score : 0.5665498267595871\n",
      "Epoch = 381 : Training loss = 2568.0106937528017, R2 score : 0.5429175315745018\n",
      "Epoch = 382 : Training loss = 2586.4059410636446, R2 score : 0.436484609952119\n",
      "Epoch = 383 : Training loss = 2577.8480238215384, R2 score : 0.5556741481548237\n",
      "Epoch = 384 : Training loss = 2599.5334829249045, R2 score : 0.5562599762038707\n",
      "Epoch = 385 : Training loss = 2593.2566738459836, R2 score : 0.5088603772168512\n",
      "Epoch = 386 : Training loss = 2543.345758565488, R2 score : 0.5420291384334834\n",
      "Epoch = 387 : Training loss = 2554.395887758741, R2 score : 0.5129805852888191\n",
      "Epoch = 388 : Training loss = 2576.3344339899004, R2 score : 0.4238412797499246\n",
      "Epoch = 389 : Training loss = 2566.473797994094, R2 score : 0.51588613181941\n",
      "Epoch = 390 : Training loss = 2553.935260269194, R2 score : 0.6185303776801476\n",
      "Epoch = 391 : Training loss = 2552.683421743177, R2 score : 0.5207601641496995\n",
      "Epoch = 392 : Training loss = 2605.202736129255, R2 score : 0.46458439327607626\n",
      "Epoch = 393 : Training loss = 2597.149950288469, R2 score : 0.4703735062424189\n",
      "Epoch = 394 : Training loss = 2542.2835510902323, R2 score : 0.4808029951666538\n",
      "Epoch = 395 : Training loss = 2553.8412032903334, R2 score : 0.5431410261058716\n",
      "Epoch = 396 : Training loss = 2535.9188243857825, R2 score : 0.4628172862751737\n",
      "Epoch = 397 : Training loss = 2538.274558640069, R2 score : 0.4740492824261545\n",
      "Epoch = 398 : Training loss = 2565.562476625517, R2 score : 0.47067848580100013\n",
      "Epoch = 399 : Training loss = 2535.8201938795683, R2 score : 0.5594514757513562\n",
      "Epoch = 400 : Training loss = 2539.609230497189, R2 score : 0.497032322412158\n",
      "Epoch = 401 : Training loss = 2538.9165731497824, R2 score : 0.5514255445872493\n",
      "Epoch = 402 : Training loss = 2566.7319145989118, R2 score : 0.5733639859372216\n",
      "Epoch = 403 : Training loss = 2604.309357213443, R2 score : 0.6019774914561667\n",
      "Epoch = 404 : Training loss = 2538.6288670691656, R2 score : 0.5290464202874496\n",
      "Epoch = 405 : Training loss = 2545.3505242387805, R2 score : 0.5147610885119211\n",
      "Epoch = 406 : Training loss = 2579.3719108707814, R2 score : 0.6067320791541513\n",
      "Epoch = 407 : Training loss = 2535.086409907749, R2 score : 0.47994144199901234\n",
      "Epoch = 408 : Training loss = 2536.7221273575465, R2 score : 0.5399728473153927\n",
      "Epoch = 409 : Training loss = 2528.0535942133365, R2 score : 0.5405740374416246\n",
      "Epoch = 410 : Training loss = 2549.8774371959953, R2 score : 0.5746377837932721\n",
      "Epoch = 411 : Training loss = 2534.457157633266, R2 score : 0.5263271454505006\n",
      "Epoch = 412 : Training loss = 2514.906498669684, R2 score : 0.47321077988662563\n",
      "Epoch = 413 : Training loss = 2542.6811475121167, R2 score : 0.4410514361700836\n",
      "Epoch = 414 : Training loss = 2527.8244615515755, R2 score : 0.5587365326474797\n",
      "Epoch = 415 : Training loss = 2550.1649277395886, R2 score : 0.4851820159834537\n",
      "Epoch = 416 : Training loss = 2551.4414333967247, R2 score : 0.515504967759044\n",
      "Epoch = 417 : Training loss = 2531.9081050266445, R2 score : 0.4563268527014527\n",
      "Epoch = 418 : Training loss = 2507.246290006634, R2 score : 0.4982547718896272\n",
      "Epoch = 419 : Training loss = 2534.027957430132, R2 score : 0.5362984093079683\n",
      "Epoch = 420 : Training loss = 2522.5869061014214, R2 score : 0.5245717572351587\n",
      "Epoch = 421 : Training loss = 2560.363783747669, R2 score : 0.4723146504576494\n",
      "Epoch = 422 : Training loss = 2523.6187716108625, R2 score : 0.47812863632546665\n",
      "Epoch = 423 : Training loss = 2539.1805039334845, R2 score : 0.5355334943951875\n",
      "Epoch = 424 : Training loss = 2521.536510915642, R2 score : 0.48344124447179126\n",
      "Epoch = 425 : Training loss = 2562.0818837767574, R2 score : 0.5047592405821223\n",
      "Epoch = 426 : Training loss = 2553.3998686852747, R2 score : 0.5267613443519101\n",
      "Epoch = 427 : Training loss = 2524.5041730716553, R2 score : 0.5543014647855646\n",
      "Epoch = 428 : Training loss = 2529.101026496902, R2 score : 0.4828436516666327\n",
      "Epoch = 429 : Training loss = 2529.084389795623, R2 score : 0.6387331531560616\n",
      "Epoch = 430 : Training loss = 2522.4299358162025, R2 score : 0.4652151361266027\n",
      "Epoch = 431 : Training loss = 2537.0273751997856, R2 score : 0.5081732035967523\n",
      "Epoch = 432 : Training loss = 2516.1675158940516, R2 score : 0.46575770042378417\n",
      "Epoch = 433 : Training loss = 2526.66699842272, R2 score : 0.42081991186393997\n",
      "Epoch = 434 : Training loss = 2492.066793826218, R2 score : 0.5095285495177762\n",
      "Epoch = 435 : Training loss = 2528.075716365417, R2 score : 0.4749731497615819\n",
      "Epoch = 436 : Training loss = 2507.330966939856, R2 score : 0.4543293096197797\n",
      "Epoch = 437 : Training loss = 2521.2518685721843, R2 score : 0.4714701249205022\n",
      "Epoch = 438 : Training loss = 2491.514205367293, R2 score : 0.5291285960697367\n",
      "Epoch = 439 : Training loss = 2491.6987386229775, R2 score : 0.5511975203552628\n",
      "Epoch = 440 : Training loss = 2518.6736975379317, R2 score : 0.4225609027249114\n",
      "Epoch = 441 : Training loss = 2507.423388670727, R2 score : 0.4350005962956698\n",
      "Epoch = 442 : Training loss = 2508.628279217975, R2 score : 0.5451758622810308\n",
      "Epoch = 443 : Training loss = 2497.77054638036, R2 score : 0.5211467453099312\n",
      "Epoch = 444 : Training loss = 2511.414258434843, R2 score : 0.5095375618863789\n",
      "Epoch = 445 : Training loss = 2504.3443098456974, R2 score : 0.4101835142331465\n",
      "Epoch = 446 : Training loss = 2510.180228491193, R2 score : 0.48434593552308136\n",
      "Epoch = 447 : Training loss = 2502.2462821829845, R2 score : 0.4678133841145756\n",
      "Epoch = 448 : Training loss = 2495.2277848971817, R2 score : 0.5514852782159854\n",
      "Epoch = 449 : Training loss = 2531.7996530881455, R2 score : 0.4222858746831021\n",
      "Epoch = 450 : Training loss = 2518.52649035595, R2 score : 0.4408083440019719\n",
      "Epoch = 451 : Training loss = 2486.030228009223, R2 score : 0.5432804342047659\n",
      "Epoch = 452 : Training loss = 2509.408145762259, R2 score : 0.5468590228267717\n",
      "Epoch = 453 : Training loss = 2492.9376205067, R2 score : 0.4801737105873536\n",
      "Epoch = 454 : Training loss = 2477.5833911343766, R2 score : 0.5615110367854272\n",
      "Epoch = 455 : Training loss = 2491.4635194784087, R2 score : 0.5024066181051063\n",
      "Epoch = 456 : Training loss = 2477.322354346922, R2 score : 0.5307905890053182\n",
      "Epoch = 457 : Training loss = 2487.7369827538446, R2 score : 0.4731457811328982\n",
      "Epoch = 458 : Training loss = 2521.7298766495164, R2 score : 0.4202317230731638\n",
      "Epoch = 459 : Training loss = 2487.2472825083364, R2 score : 0.5275684662315172\n",
      "Epoch = 460 : Training loss = 2513.1817404961234, R2 score : 0.5096078056675706\n",
      "Epoch = 461 : Training loss = 2503.054636492345, R2 score : 0.4392137044601059\n",
      "Epoch = 462 : Training loss = 2488.2321343514323, R2 score : 0.5175683391265784\n",
      "Epoch = 463 : Training loss = 2522.2854821374403, R2 score : 0.5459773945342408\n",
      "Epoch = 464 : Training loss = 2503.0657192959234, R2 score : 0.427778038909126\n",
      "Epoch = 465 : Training loss = 2518.4509523479956, R2 score : 0.4505857523088247\n",
      "Epoch = 466 : Training loss = 2582.0718935527675, R2 score : 0.5421538477981565\n",
      "Epoch = 467 : Training loss = 2527.932845049818, R2 score : 0.5814933971703147\n",
      "Epoch = 468 : Training loss = 2467.739344713382, R2 score : 0.43154402768081945\n",
      "Epoch = 469 : Training loss = 2482.767871494561, R2 score : 0.5013706431927105\n",
      "Epoch = 470 : Training loss = 2500.47350556991, R2 score : 0.5431032972179684\n",
      "Epoch = 471 : Training loss = 2522.00953016154, R2 score : 0.634023900364588\n",
      "Epoch = 472 : Training loss = 2530.3540682532334, R2 score : 0.49547246631835573\n",
      "Epoch = 473 : Training loss = 2489.240899823929, R2 score : 0.5505557532882708\n",
      "Epoch = 474 : Training loss = 2470.5322583367633, R2 score : 0.5315292767721596\n",
      "Epoch = 475 : Training loss = 2510.0233997426617, R2 score : 0.4763172947738612\n",
      "Epoch = 476 : Training loss = 2478.5939236902527, R2 score : 0.5592325265173982\n",
      "Epoch = 477 : Training loss = 2531.081526835509, R2 score : 0.4405688630578205\n",
      "Epoch = 478 : Training loss = 2483.1119945134164, R2 score : 0.49214234698503634\n",
      "Epoch = 479 : Training loss = 2549.210415392761, R2 score : 0.4933012045190852\n",
      "Epoch = 480 : Training loss = 2458.602155615288, R2 score : 0.48949614820287823\n",
      "Epoch = 481 : Training loss = 2483.3481525990146, R2 score : 0.47058134597122137\n",
      "Epoch = 482 : Training loss = 2499.0186333752363, R2 score : 0.454997978615197\n",
      "Epoch = 483 : Training loss = 2489.5301605512523, R2 score : 0.3931097705552794\n",
      "Epoch = 484 : Training loss = 2492.5972379715413, R2 score : 0.5379653124775111\n",
      "Epoch = 485 : Training loss = 2459.118885417672, R2 score : 0.46525087521609654\n",
      "Epoch = 486 : Training loss = 2489.0785093646564, R2 score : 0.5277060310191255\n",
      "Epoch = 487 : Training loss = 2544.349505248922, R2 score : 0.5198227492283489\n",
      "Epoch = 488 : Training loss = 2482.099199857727, R2 score : 0.4651437629904108\n",
      "Epoch = 489 : Training loss = 2462.1023180905436, R2 score : 0.4221170916063537\n",
      "Epoch = 490 : Training loss = 2452.6199004386176, R2 score : 0.5222243256601532\n",
      "Epoch = 491 : Training loss = 2476.486398552887, R2 score : 0.4833642202913452\n",
      "Epoch = 492 : Training loss = 2492.977292653535, R2 score : 0.5045222373451176\n",
      "Epoch = 493 : Training loss = 2464.237242997715, R2 score : 0.5474997494123872\n",
      "Epoch = 494 : Training loss = 2480.936619071088, R2 score : 0.4672847417394239\n",
      "Epoch = 495 : Training loss = 2496.6775579595096, R2 score : 0.5312242993412134\n",
      "Epoch = 496 : Training loss = 2459.4407592942925, R2 score : 0.4343177395500879\n",
      "Epoch = 497 : Training loss = 2457.5406335518414, R2 score : 0.4797051184578759\n",
      "Epoch = 498 : Training loss = 2482.2803028738545, R2 score : 0.5084108086388186\n",
      "Epoch = 499 : Training loss = 2464.358606433422, R2 score : 0.44382152783896944\n",
      "Epoch = 500 : Training loss = 2454.8117742621666, R2 score : 0.42525577626058053\n",
      "Epoch = 501 : Training loss = 2436.7871889166595, R2 score : 0.5275313067165343\n",
      "Epoch = 502 : Training loss = 2497.0525539729942, R2 score : 0.3436156512287004\n",
      "Epoch = 503 : Training loss = 2464.8050045827476, R2 score : 0.5637924151371336\n",
      "Epoch = 504 : Training loss = 2488.064582822072, R2 score : 0.4335023045988834\n",
      "Epoch = 505 : Training loss = 2472.036820239281, R2 score : 0.49210423508740286\n",
      "Epoch = 506 : Training loss = 2446.329145180015, R2 score : 0.5483799951273252\n",
      "Epoch = 507 : Training loss = 2478.42089631436, R2 score : 0.47571705462968694\n",
      "Epoch = 508 : Training loss = 2442.777424274518, R2 score : 0.5239292532956215\n",
      "Epoch = 509 : Training loss = 2489.4814317944893, R2 score : 0.4734445186430507\n",
      "Epoch = 510 : Training loss = 2421.902654476301, R2 score : 0.514060525190052\n",
      "Epoch = 511 : Training loss = 2472.9279654499815, R2 score : 0.41222898075064573\n",
      "Epoch = 512 : Training loss = 2474.8005002950695, R2 score : 0.47504219434287787\n",
      "Epoch = 513 : Training loss = 2447.6128558545383, R2 score : 0.5217764762774233\n",
      "Epoch = 514 : Training loss = 2451.269763584176, R2 score : 0.5724651651646167\n",
      "Epoch = 515 : Training loss = 2464.6112639077314, R2 score : 0.41118280234324456\n",
      "Epoch = 516 : Training loss = 2444.7772450931934, R2 score : 0.5587405385004323\n",
      "Epoch = 517 : Training loss = 2446.5675774395067, R2 score : 0.49216593520923957\n",
      "Epoch = 518 : Training loss = 2449.9122810976287, R2 score : 0.4938508651982779\n",
      "Epoch = 519 : Training loss = 2432.7601742726574, R2 score : 0.5680008297358071\n",
      "Epoch = 520 : Training loss = 2443.384730137192, R2 score : 0.5094769749545287\n",
      "Epoch = 521 : Training loss = 2504.6391418791472, R2 score : 0.5013157591329782\n",
      "Epoch = 522 : Training loss = 2422.045184300124, R2 score : 0.48895012399800164\n",
      "Epoch = 523 : Training loss = 2425.370256713347, R2 score : 0.4085488042678863\n",
      "Epoch = 524 : Training loss = 2460.128564090867, R2 score : 0.4312050121626002\n",
      "Epoch = 525 : Training loss = 2436.671812580721, R2 score : 0.4403396651605155\n",
      "Epoch = 526 : Training loss = 2450.1406647260064, R2 score : 0.5147336554449986\n",
      "Epoch = 527 : Training loss = 2525.009763382417, R2 score : 0.5726362981540196\n",
      "Epoch = 528 : Training loss = 2454.6699143412206, R2 score : 0.472525965902995\n",
      "Epoch = 529 : Training loss = 2473.1060973680096, R2 score : 0.5298193527285937\n",
      "Epoch = 530 : Training loss = 2459.5172166114467, R2 score : 0.4800410168394068\n",
      "Epoch = 531 : Training loss = 2451.0498859151785, R2 score : 0.45971856648541165\n",
      "Epoch = 532 : Training loss = 2459.949073839771, R2 score : 0.4493550329488738\n",
      "Epoch = 533 : Training loss = 2432.2298418761056, R2 score : 0.550806217342943\n",
      "Epoch = 534 : Training loss = 2438.5020491906303, R2 score : 0.4171735747425871\n",
      "Epoch = 535 : Training loss = 2437.3204640880153, R2 score : 0.44487474962064955\n",
      "Epoch = 536 : Training loss = 2443.8299767111075, R2 score : 0.5330971722232442\n",
      "Epoch = 537 : Training loss = 2437.811949526124, R2 score : 0.4852046080222704\n",
      "Epoch = 538 : Training loss = 2491.2259302736675, R2 score : 0.4801756794773734\n",
      "Epoch = 539 : Training loss = 2446.0630516608944, R2 score : 0.42680878790983257\n",
      "Epoch = 540 : Training loss = 2417.637405990902, R2 score : 0.4361456336356103\n",
      "Epoch = 541 : Training loss = 2455.0812750441637, R2 score : 0.5011621825477968\n",
      "Epoch = 542 : Training loss = 2452.478948437585, R2 score : 0.36669225457638865\n",
      "Epoch = 543 : Training loss = 2457.565353369707, R2 score : 0.5448603446292661\n",
      "Epoch = 544 : Training loss = 2453.4504419589684, R2 score : 0.5457742077453919\n",
      "Epoch = 545 : Training loss = 2467.6112063568225, R2 score : 0.51469370303799\n",
      "Epoch = 546 : Training loss = 2453.3085268045643, R2 score : 0.5200725662201303\n",
      "Epoch = 547 : Training loss = 2432.626962245424, R2 score : 0.5325055224431567\n",
      "Epoch = 548 : Training loss = 2468.185372644868, R2 score : 0.4038530990132009\n",
      "Epoch = 549 : Training loss = 2432.8601098251497, R2 score : 0.4463413765146331\n",
      "Epoch = 550 : Training loss = 2439.6511969269714, R2 score : 0.38995779188759394\n",
      "Epoch = 551 : Training loss = 2451.262177703686, R2 score : 0.5670311321604833\n",
      "Epoch = 552 : Training loss = 2426.0028060795744, R2 score : 0.4544611517553534\n",
      "Epoch = 553 : Training loss = 2381.5347628132004, R2 score : 0.5033926918159581\n",
      "Epoch = 554 : Training loss = 2397.667633340314, R2 score : 0.4322660123607708\n",
      "Epoch = 555 : Training loss = 2398.2921187961374, R2 score : 0.49085226038437924\n",
      "Epoch = 556 : Training loss = 2473.9572898674624, R2 score : 0.3936954689179458\n",
      "Epoch = 557 : Training loss = 2413.4640636144795, R2 score : 0.5555316074774943\n",
      "Epoch = 558 : Training loss = 2415.2818946784046, R2 score : 0.5401734538199484\n",
      "Epoch = 559 : Training loss = 2384.0520334487983, R2 score : 0.4479281854539038\n",
      "Epoch = 560 : Training loss = 2430.4120775025194, R2 score : 0.49352819496578615\n",
      "Epoch = 561 : Training loss = 2403.7833769433555, R2 score : 0.5426984925115721\n",
      "Epoch = 562 : Training loss = 2452.578741413161, R2 score : 0.5546887759288599\n",
      "Epoch = 563 : Training loss = 2406.9523951104, R2 score : 0.3870101972041097\n",
      "Epoch = 564 : Training loss = 2438.8400829070115, R2 score : 0.484101255996197\n",
      "Epoch = 565 : Training loss = 2394.9413426709293, R2 score : 0.5595130766208612\n",
      "Epoch = 566 : Training loss = 2394.142400524313, R2 score : 0.54675453603133\n",
      "Epoch = 567 : Training loss = 2415.816244722272, R2 score : 0.38672470416453\n",
      "Epoch = 568 : Training loss = 2413.2060031921433, R2 score : 0.4932077808534855\n",
      "Epoch = 569 : Training loss = 2435.415248092827, R2 score : 0.5486536837110048\n",
      "Epoch = 570 : Training loss = 2424.901596954289, R2 score : 0.5162044709266889\n",
      "Epoch = 571 : Training loss = 2418.863214210549, R2 score : 0.4233055374984439\n",
      "Epoch = 572 : Training loss = 2377.329139543066, R2 score : 0.5042091178103659\n",
      "Epoch = 573 : Training loss = 2420.327748007244, R2 score : 0.5588501310757168\n",
      "Epoch = 574 : Training loss = 2426.2864030584947, R2 score : 0.5326734531723416\n",
      "Epoch = 575 : Training loss = 2392.0427725261256, R2 score : 0.45674157001403404\n",
      "Epoch = 576 : Training loss = 2419.4001541288685, R2 score : 0.5314404418517299\n",
      "Epoch = 577 : Training loss = 2416.66703623582, R2 score : 0.4903961696519562\n",
      "Epoch = 578 : Training loss = 2414.3512407975945, R2 score : 0.43935569642818406\n",
      "Epoch = 579 : Training loss = 2435.922049326796, R2 score : 0.5236773481721655\n",
      "Epoch = 580 : Training loss = 2418.7369399457975, R2 score : 0.5159100510897612\n",
      "Epoch = 581 : Training loss = 2397.4534281383417, R2 score : 0.443007704692715\n",
      "Epoch = 582 : Training loss = 2408.288204508276, R2 score : 0.48261961885131777\n",
      "Epoch = 583 : Training loss = 2397.373060879726, R2 score : 0.5636637693385103\n",
      "Epoch = 584 : Training loss = 2421.61654907939, R2 score : 0.5043827701489119\n",
      "Epoch = 585 : Training loss = 2407.820536233255, R2 score : 0.4714793989589058\n",
      "Epoch = 586 : Training loss = 2410.3061992520984, R2 score : 0.4763016769278189\n",
      "Epoch = 587 : Training loss = 2404.8032952169424, R2 score : 0.4134434999963249\n",
      "Epoch = 588 : Training loss = 2376.883587906784, R2 score : 0.4668275810150949\n",
      "Epoch = 589 : Training loss = 2397.8356827959688, R2 score : 0.3836665724768439\n",
      "Epoch = 590 : Training loss = 2454.716145689769, R2 score : 0.5438323669469038\n",
      "Epoch = 591 : Training loss = 2431.71526602047, R2 score : 0.3190105093144372\n",
      "Epoch = 592 : Training loss = 2432.273052146013, R2 score : 0.40032119167000846\n",
      "Epoch = 593 : Training loss = 2396.1630945420925, R2 score : 0.41844830827679513\n",
      "Epoch = 594 : Training loss = 2378.8505216699036, R2 score : 0.5573001543667104\n",
      "Epoch = 595 : Training loss = 2421.3942835762164, R2 score : 0.5982340775910859\n",
      "Epoch = 596 : Training loss = 2416.0279744723716, R2 score : 0.4574789974711705\n",
      "Epoch = 597 : Training loss = 2413.6011839246594, R2 score : 0.49440467617131334\n",
      "Epoch = 598 : Training loss = 2430.165636449671, R2 score : 0.48175189188841094\n",
      "Epoch = 599 : Training loss = 2447.161017577311, R2 score : 0.3543622190547774\n",
      "Epoch = 600 : Training loss = 2404.614577660867, R2 score : 0.3804034215538501\n",
      "Epoch = 601 : Training loss = 2428.452760040268, R2 score : 0.4533863900610414\n",
      "Epoch = 602 : Training loss = 2361.5577691451876, R2 score : 0.4756519277545891\n",
      "Epoch = 603 : Training loss = 2403.9038405237243, R2 score : 0.4868592228365597\n",
      "Epoch = 604 : Training loss = 2394.463822541098, R2 score : 0.48500263077405814\n",
      "Epoch = 605 : Training loss = 2372.3210268083694, R2 score : 0.5054083703047988\n",
      "Epoch = 606 : Training loss = 2350.275450538774, R2 score : 0.4793882170788766\n",
      "Epoch = 607 : Training loss = 2388.5936807190174, R2 score : 0.4447283493047237\n",
      "Epoch = 608 : Training loss = 2380.275213982949, R2 score : 0.5189432605202564\n",
      "Epoch = 609 : Training loss = 2377.4049443225113, R2 score : 0.5602284682378366\n",
      "Epoch = 610 : Training loss = 2388.179854124187, R2 score : 0.5293528322641545\n",
      "Epoch = 611 : Training loss = 2372.479701780775, R2 score : 0.4316804825076396\n",
      "Epoch = 612 : Training loss = 2430.2899903251346, R2 score : 0.41140058478165054\n",
      "Epoch = 613 : Training loss = 2395.9029153579986, R2 score : 0.4114972921102078\n",
      "Epoch = 614 : Training loss = 2386.8570688433992, R2 score : 0.4765611241246205\n",
      "Epoch = 615 : Training loss = 2371.7178866520335, R2 score : 0.44704541568893574\n",
      "Epoch = 616 : Training loss = 2380.232581884934, R2 score : 0.4889657711108658\n",
      "Epoch = 617 : Training loss = 2389.3673084028223, R2 score : 0.4563606856146174\n",
      "Epoch = 618 : Training loss = 2377.526230167836, R2 score : 0.4551644359413306\n",
      "Epoch = 619 : Training loss = 2383.0470952282258, R2 score : 0.42225491178950914\n",
      "Epoch = 620 : Training loss = 2385.0113375534183, R2 score : 0.5296874473508046\n",
      "Epoch = 621 : Training loss = 2407.9762914466414, R2 score : 0.32997691804399243\n",
      "Epoch = 622 : Training loss = 2415.378595554919, R2 score : 0.510744848308081\n",
      "Epoch = 623 : Training loss = 2388.800973649031, R2 score : 0.5176214493277808\n",
      "Epoch = 624 : Training loss = 2379.480139705542, R2 score : 0.47311574964841274\n",
      "Epoch = 625 : Training loss = 2375.9718368564368, R2 score : 0.39132297307574615\n",
      "Epoch = 626 : Training loss = 2380.104912005871, R2 score : 0.5143479841309778\n",
      "Epoch = 627 : Training loss = 2377.7858004354084, R2 score : 0.46992169279705986\n",
      "Epoch = 628 : Training loss = 2375.4891978514906, R2 score : 0.42164609593547686\n",
      "Epoch = 629 : Training loss = 2402.5215862352707, R2 score : 0.5486647851268358\n",
      "Epoch = 630 : Training loss = 2355.505243482451, R2 score : 0.4263939400119747\n",
      "Epoch = 631 : Training loss = 2374.8821560618435, R2 score : 0.5079944809449132\n",
      "Epoch = 632 : Training loss = 2374.180673664201, R2 score : 0.495160065179715\n",
      "Epoch = 633 : Training loss = 2367.6432114145955, R2 score : 0.4363290485809568\n",
      "Epoch = 634 : Training loss = 2445.0363809025594, R2 score : 0.48900378812652034\n",
      "Epoch = 635 : Training loss = 2371.9813272316615, R2 score : 0.5910271201494305\n",
      "Epoch = 636 : Training loss = 2361.668729078421, R2 score : 0.5149033948102436\n",
      "Epoch = 637 : Training loss = 2353.0385041328373, R2 score : 0.3877525896701203\n",
      "Epoch = 638 : Training loss = 2360.619499314388, R2 score : 0.49635551588442284\n",
      "Epoch = 639 : Training loss = 2367.433873612936, R2 score : 0.5685799241638085\n",
      "Epoch = 640 : Training loss = 2412.596791118048, R2 score : 0.46608556598079864\n",
      "Epoch = 641 : Training loss = 2354.257063831628, R2 score : 0.47314838598450604\n",
      "Epoch = 642 : Training loss = 2369.7715260874397, R2 score : 0.44825876894707717\n",
      "Epoch = 643 : Training loss = 2341.7778279275626, R2 score : 0.49596557440751454\n",
      "Epoch = 644 : Training loss = 2394.7118149083426, R2 score : 0.5470071233150493\n",
      "Epoch = 645 : Training loss = 2400.2658520613686, R2 score : 0.5084166678445479\n",
      "Epoch = 646 : Training loss = 2353.4441089276975, R2 score : 0.4904379309912483\n",
      "Epoch = 647 : Training loss = 2376.1268236787837, R2 score : 0.4745682465971658\n",
      "Epoch = 648 : Training loss = 2390.7228264703385, R2 score : 0.4953128963694091\n",
      "Epoch = 649 : Training loss = 2374.064338871528, R2 score : 0.5368645791403788\n",
      "Epoch = 650 : Training loss = 2337.1417102144133, R2 score : 0.4826037473022893\n",
      "Epoch = 651 : Training loss = 2435.0220910660482, R2 score : 0.541390241434275\n",
      "Epoch = 652 : Training loss = 2370.7678289138394, R2 score : 0.5380121429360415\n",
      "Epoch = 653 : Training loss = 2381.5341178136678, R2 score : 0.5167893152103371\n",
      "Epoch = 654 : Training loss = 2355.354597935505, R2 score : 0.5416449985383709\n",
      "Epoch = 655 : Training loss = 2372.969587565129, R2 score : 0.5320497280293434\n",
      "Epoch = 656 : Training loss = 2376.7795509671087, R2 score : 0.41991926528283474\n",
      "Epoch = 657 : Training loss = 2364.9077158199234, R2 score : 0.4993605129428298\n",
      "Epoch = 658 : Training loss = 2343.674364357228, R2 score : 0.46714338805959066\n",
      "Epoch = 659 : Training loss = 2368.950604513465, R2 score : 0.4360787210895869\n",
      "Epoch = 660 : Training loss = 2400.4450780525794, R2 score : 0.5411947713898911\n",
      "Epoch = 661 : Training loss = 2384.215998020427, R2 score : 0.5436661491946677\n",
      "Epoch = 662 : Training loss = 2330.935457980866, R2 score : 0.49963721625797464\n",
      "Epoch = 663 : Training loss = 2347.9823777939973, R2 score : 0.5629597249459151\n",
      "Epoch = 664 : Training loss = 2355.542393695332, R2 score : 0.5129743624041763\n",
      "Epoch = 665 : Training loss = 2304.5199198788787, R2 score : 0.44856489261037935\n",
      "Epoch = 666 : Training loss = 2361.7006338928586, R2 score : 0.4163154740109051\n",
      "Epoch = 667 : Training loss = 2366.247862143073, R2 score : 0.524836193291786\n",
      "Epoch = 668 : Training loss = 2349.8517269351687, R2 score : 0.49475991015578313\n",
      "Epoch = 669 : Training loss = 2341.1415004783607, R2 score : 0.5084296884684539\n",
      "Epoch = 670 : Training loss = 2352.2856559674874, R2 score : 0.4589261231297854\n",
      "Epoch = 671 : Training loss = 2330.2257148068247, R2 score : 0.5256574518502757\n",
      "Epoch = 672 : Training loss = 2343.52500914561, R2 score : 0.5341255942645804\n",
      "Epoch = 673 : Training loss = 2366.4635125399827, R2 score : 0.532736830219557\n",
      "Epoch = 674 : Training loss = 2354.37725112831, R2 score : 0.5096321997338649\n",
      "Epoch = 675 : Training loss = 2361.8861790557758, R2 score : 0.4235651017685429\n",
      "Epoch = 676 : Training loss = 2369.9198061912734, R2 score : 0.4559386292666704\n",
      "Epoch = 677 : Training loss = 2336.9869258067947, R2 score : 0.5665962112810763\n",
      "Epoch = 678 : Training loss = 2337.6768687453123, R2 score : 0.46926401044357613\n",
      "Epoch = 679 : Training loss = 2373.0746952005156, R2 score : 0.4769777101703644\n",
      "Epoch = 680 : Training loss = 2353.817222099765, R2 score : 0.40344841069290627\n",
      "Epoch = 681 : Training loss = 2354.516297302416, R2 score : 0.5176361613816405\n",
      "Epoch = 682 : Training loss = 2332.6694086442444, R2 score : 0.530984461280787\n",
      "Epoch = 683 : Training loss = 2363.101637339187, R2 score : 0.4522105383368018\n",
      "Epoch = 684 : Training loss = 2343.594644043424, R2 score : 0.4983872387789503\n",
      "Epoch = 685 : Training loss = 2359.5985836049313, R2 score : 0.41454139547249524\n",
      "Epoch = 686 : Training loss = 2363.0503125837936, R2 score : 0.4542094743639613\n",
      "Epoch = 687 : Training loss = 2315.0657784913174, R2 score : 0.4372373613840279\n",
      "Epoch = 688 : Training loss = 2297.427615697684, R2 score : 0.4480425689885641\n",
      "Epoch = 689 : Training loss = 2283.4259043013353, R2 score : 0.48442486191441303\n",
      "Epoch = 690 : Training loss = 2364.123687245915, R2 score : 0.41023035622038995\n",
      "Epoch = 691 : Training loss = 2366.1865451271565, R2 score : 0.5623801486655637\n",
      "Epoch = 692 : Training loss = 2353.3626677991742, R2 score : 0.5459706871931793\n",
      "Epoch = 693 : Training loss = 2299.1782749515605, R2 score : 0.521254217370104\n",
      "Epoch = 694 : Training loss = 2305.091764187968, R2 score : 0.4767567965094779\n",
      "Epoch = 695 : Training loss = 2317.851554622644, R2 score : 0.48072170107581325\n",
      "Epoch = 696 : Training loss = 2323.5064061654216, R2 score : 0.49295931607751575\n",
      "Epoch = 697 : Training loss = 2357.45841691057, R2 score : 0.4206793950592904\n",
      "Epoch = 698 : Training loss = 2321.720522909193, R2 score : 0.5031276766473044\n",
      "Epoch = 699 : Training loss = 2322.89064354887, R2 score : 0.5170122768753009\n",
      "Epoch = 700 : Training loss = 2412.567306309207, R2 score : 0.36023125204015904\n",
      "Epoch = 701 : Training loss = 2334.451948284539, R2 score : 0.4590067991750548\n",
      "Epoch = 702 : Training loss = 2313.069097077772, R2 score : 0.40495430437357105\n",
      "Epoch = 703 : Training loss = 2360.489032444754, R2 score : 0.42857413202289385\n",
      "Epoch = 704 : Training loss = 2310.413678110532, R2 score : 0.417886465169235\n",
      "Epoch = 705 : Training loss = 2324.1647856385534, R2 score : 0.5023112876657356\n",
      "Epoch = 706 : Training loss = 2314.7508226711707, R2 score : 0.46263183930936724\n",
      "Epoch = 707 : Training loss = 2339.197814707036, R2 score : 0.4869377716316251\n",
      "Epoch = 708 : Training loss = 2306.6366674871633, R2 score : 0.434796688572201\n",
      "Epoch = 709 : Training loss = 2310.6327370309987, R2 score : 0.5151339647204809\n",
      "Epoch = 710 : Training loss = 2319.367105732881, R2 score : 0.4748473130217298\n",
      "Epoch = 711 : Training loss = 2296.6128514802026, R2 score : 0.4403484267009239\n",
      "Epoch = 712 : Training loss = 2306.606754493247, R2 score : 0.4521985214875439\n",
      "Epoch = 713 : Training loss = 2310.4785920185086, R2 score : 0.43581396189413124\n",
      "Epoch = 714 : Training loss = 2291.9179670382264, R2 score : 0.47433077529176304\n",
      "Epoch = 715 : Training loss = 2299.81046504444, R2 score : 0.4436773200452646\n",
      "Epoch = 716 : Training loss = 2293.4073773174355, R2 score : 0.49623686318258575\n",
      "Epoch = 717 : Training loss = 2320.3970261798313, R2 score : 0.5270508629589111\n",
      "Epoch = 718 : Training loss = 2322.495076752782, R2 score : 0.47253590265073364\n",
      "Epoch = 719 : Training loss = 2312.320073714464, R2 score : 0.48270715586443524\n",
      "Epoch = 720 : Training loss = 2293.1354482188426, R2 score : 0.48978929324959\n",
      "Epoch = 721 : Training loss = 2294.0593776460382, R2 score : 0.4436633979062945\n",
      "Epoch = 722 : Training loss = 2299.808805845687, R2 score : 0.3973665534794285\n",
      "Epoch = 723 : Training loss = 2324.058917737865, R2 score : 0.5671533089047998\n",
      "Epoch = 724 : Training loss = 2344.601584458285, R2 score : 0.46187173068569976\n",
      "Epoch = 725 : Training loss = 2291.8889519979234, R2 score : 0.46523339334913905\n",
      "Epoch = 726 : Training loss = 2313.8503709870647, R2 score : 0.5071521922162541\n",
      "Epoch = 727 : Training loss = 2306.0987823048386, R2 score : 0.42568440535454866\n",
      "Epoch = 728 : Training loss = 2316.722983540948, R2 score : 0.5059426810735641\n",
      "Epoch = 729 : Training loss = 2347.3466358002365, R2 score : 0.40827416815571305\n",
      "Epoch = 730 : Training loss = 2348.9426371474174, R2 score : 0.5375450650036326\n",
      "Epoch = 731 : Training loss = 2267.029506817839, R2 score : 0.49799318216214583\n",
      "Epoch = 732 : Training loss = 2323.140697572756, R2 score : 0.46065542158525774\n",
      "Epoch = 733 : Training loss = 2434.64553344038, R2 score : 0.4064535087979043\n",
      "Epoch = 734 : Training loss = 2310.3099418115808, R2 score : 0.3869948036219174\n",
      "Epoch = 735 : Training loss = 2323.9671236516747, R2 score : 0.4775073503227045\n",
      "Epoch = 736 : Training loss = 2276.9118103419655, R2 score : 0.3762786095019224\n",
      "Epoch = 737 : Training loss = 2298.6625739645397, R2 score : 0.45381770560131585\n",
      "Epoch = 738 : Training loss = 2288.515737344184, R2 score : 0.41779627195270863\n",
      "Epoch = 739 : Training loss = 2297.6859794513903, R2 score : 0.4188576328238104\n",
      "Epoch = 740 : Training loss = 2310.929972669791, R2 score : 0.4714636640160099\n",
      "Epoch = 741 : Training loss = 2359.4068627958713, R2 score : 0.5548254624598159\n",
      "Epoch = 742 : Training loss = 2329.29997066244, R2 score : 0.5531737116908544\n",
      "Epoch = 743 : Training loss = 2306.6428407398407, R2 score : 0.47369777490443865\n",
      "Epoch = 744 : Training loss = 2287.927777590189, R2 score : 0.503012374067952\n",
      "Epoch = 745 : Training loss = 2319.1653364158565, R2 score : 0.3785657928206809\n",
      "Epoch = 746 : Training loss = 2299.1595491999738, R2 score : 0.47728089367246473\n",
      "Epoch = 747 : Training loss = 2368.4958556316733, R2 score : 0.3577283477091838\n",
      "Epoch = 748 : Training loss = 2332.959800139025, R2 score : 0.3683656868060231\n",
      "Epoch = 749 : Training loss = 2298.7401894076716, R2 score : 0.42162697244849634\n",
      "Epoch = 750 : Training loss = 2306.1510614974995, R2 score : 0.40964852936647334\n",
      "Epoch = 751 : Training loss = 2278.6101868527685, R2 score : 0.4792174453883359\n",
      "Epoch = 752 : Training loss = 2319.879079813174, R2 score : 0.57131984203313\n",
      "Epoch = 753 : Training loss = 2371.1854184574295, R2 score : 0.5000721359086647\n",
      "Epoch = 754 : Training loss = 2290.5767356701126, R2 score : 0.5908273403726677\n",
      "Epoch = 755 : Training loss = 2306.947509023118, R2 score : 0.3922859473391791\n",
      "Epoch = 756 : Training loss = 2280.086751961525, R2 score : 0.46375554519999584\n",
      "Epoch = 757 : Training loss = 2362.746421559111, R2 score : 0.3830498364841246\n",
      "Epoch = 758 : Training loss = 2297.249792508721, R2 score : 0.49527567137420714\n",
      "Epoch = 759 : Training loss = 2325.675285318529, R2 score : 0.4089058433561299\n",
      "Epoch = 760 : Training loss = 2270.8621065728166, R2 score : 0.4579953317822286\n",
      "Epoch = 761 : Training loss = 2292.8986327185303, R2 score : 0.4972382616868962\n",
      "Epoch = 762 : Training loss = 2282.004504164941, R2 score : 0.4244051763462785\n",
      "Epoch = 763 : Training loss = 2255.956923206593, R2 score : 0.40148100710389556\n",
      "Epoch = 764 : Training loss = 2376.9908169298715, R2 score : 0.5014958273067984\n",
      "Epoch = 765 : Training loss = 2263.8067872078773, R2 score : 0.4933815557752048\n",
      "Epoch = 766 : Training loss = 2326.2331670989283, R2 score : 0.5070665399191623\n",
      "Epoch = 767 : Training loss = 2294.10475176497, R2 score : 0.4571005956482529\n",
      "Epoch = 768 : Training loss = 2294.5450159960183, R2 score : 0.5067599587516443\n",
      "Epoch = 769 : Training loss = 2333.2954468624266, R2 score : 0.5111296042034073\n",
      "Epoch = 770 : Training loss = 2289.248716117321, R2 score : 0.42903380138878044\n",
      "Epoch = 771 : Training loss = 2274.5597963743485, R2 score : 0.5076450903407673\n",
      "Epoch = 772 : Training loss = 2324.5157305738835, R2 score : 0.3943449144238901\n",
      "Epoch = 773 : Training loss = 2313.5181696425843, R2 score : 0.46090577523581977\n",
      "Epoch = 774 : Training loss = 2299.7783956671055, R2 score : 0.50743457842862\n",
      "Epoch = 775 : Training loss = 2259.110913289086, R2 score : 0.5134542738182866\n",
      "Epoch = 776 : Training loss = 2275.383378274095, R2 score : 0.3923912584089916\n",
      "Epoch = 777 : Training loss = 2276.676355096516, R2 score : 0.4508296994861746\n",
      "Epoch = 778 : Training loss = 2296.110277184365, R2 score : 0.41871224911196325\n",
      "Epoch = 779 : Training loss = 2319.425847328902, R2 score : 0.4729465828469358\n",
      "Epoch = 780 : Training loss = 2296.5354026287528, R2 score : 0.44007166369840534\n",
      "Epoch = 781 : Training loss = 2259.9391461531527, R2 score : 0.4775114885148958\n",
      "Epoch = 782 : Training loss = 2267.0842685628136, R2 score : 0.4586901203271633\n",
      "Epoch = 783 : Training loss = 2286.803512260288, R2 score : 0.5274628198085565\n",
      "Epoch = 784 : Training loss = 2297.362969731382, R2 score : 0.47808553377875773\n",
      "Epoch = 785 : Training loss = 2304.6842304364764, R2 score : 0.48395388674549966\n",
      "Epoch = 786 : Training loss = 2256.1519298622306, R2 score : 0.4347092862237658\n",
      "Epoch = 787 : Training loss = 2297.3692809463673, R2 score : 0.49593766584604426\n",
      "Epoch = 788 : Training loss = 2297.1240841229064, R2 score : 0.44549306744894157\n",
      "Epoch = 789 : Training loss = 2293.328019718272, R2 score : 0.40762895663053955\n",
      "Epoch = 790 : Training loss = 2341.3417580325113, R2 score : 0.417471600315649\n",
      "Epoch = 791 : Training loss = 2261.564032012383, R2 score : 0.4621691788654152\n",
      "Epoch = 792 : Training loss = 2308.5759259979004, R2 score : 0.520564195558405\n",
      "Epoch = 793 : Training loss = 2275.791520591444, R2 score : 0.4395567447337113\n",
      "Epoch = 794 : Training loss = 2315.3818303464004, R2 score : 0.3960343270519383\n",
      "Epoch = 795 : Training loss = 2266.3379710690842, R2 score : 0.5165765947784338\n",
      "Epoch = 796 : Training loss = 2238.9689944539305, R2 score : 0.4827359865076153\n",
      "Epoch = 797 : Training loss = 2254.8704722194657, R2 score : 0.39592358950704376\n",
      "Epoch = 798 : Training loss = 2251.530170704875, R2 score : 0.5003760948885176\n",
      "Epoch = 799 : Training loss = 2260.8042945312873, R2 score : 0.4243826422248126\n",
      "Epoch = 800 : Training loss = 2284.7712604340304, R2 score : 0.4560778352759005\n",
      "Epoch = 801 : Training loss = 2272.955085865934, R2 score : 0.41645971245235125\n",
      "Epoch = 802 : Training loss = 2274.538416691072, R2 score : 0.5256992483341343\n",
      "Epoch = 803 : Training loss = 2295.2478834624017, R2 score : 0.5983594610972821\n",
      "Epoch = 804 : Training loss = 2287.2180929548003, R2 score : 0.501616517866941\n",
      "Epoch = 805 : Training loss = 2280.628105437037, R2 score : 0.47757821583230076\n",
      "Epoch = 806 : Training loss = 2317.8364981477534, R2 score : 0.5191886013719974\n",
      "Epoch = 807 : Training loss = 2276.272772268717, R2 score : 0.5067244347801938\n",
      "Epoch = 808 : Training loss = 2281.387954001898, R2 score : 0.3889368960499431\n",
      "Epoch = 809 : Training loss = 2252.0704130128624, R2 score : 0.5200617499652557\n",
      "Epoch = 810 : Training loss = 2274.9362569282193, R2 score : 0.5885060177247661\n",
      "Epoch = 811 : Training loss = 2275.756815821779, R2 score : 0.3437901887103252\n",
      "Epoch = 812 : Training loss = 2273.620217887563, R2 score : 0.39138544449484813\n",
      "Epoch = 813 : Training loss = 2296.0241599963656, R2 score : 0.46263633099897294\n",
      "Epoch = 814 : Training loss = 2235.764207695962, R2 score : 0.4666060993711708\n",
      "Epoch = 815 : Training loss = 2253.792865205629, R2 score : 0.5287866079100775\n",
      "Epoch = 816 : Training loss = 2261.595260201888, R2 score : 0.4934576354588267\n",
      "Epoch = 817 : Training loss = 2261.3969356782436, R2 score : 0.49861633554963136\n",
      "Epoch = 818 : Training loss = 2246.197311262783, R2 score : 0.3942393139680447\n",
      "Epoch = 819 : Training loss = 2242.0499669981846, R2 score : 0.4754733599865375\n",
      "Epoch = 820 : Training loss = 2264.776917221947, R2 score : 0.36504600043505075\n",
      "Epoch = 821 : Training loss = 2285.6206562395914, R2 score : 0.4620657069735633\n",
      "Epoch = 822 : Training loss = 2258.9397936755568, R2 score : 0.5207254455573931\n",
      "Epoch = 823 : Training loss = 2255.18270029366, R2 score : 0.37004979505697266\n",
      "Epoch = 824 : Training loss = 2247.3043332523516, R2 score : 0.4474397400311001\n",
      "Epoch = 825 : Training loss = 2236.589203170151, R2 score : 0.5391596278302266\n",
      "Epoch = 826 : Training loss = 2317.103178176523, R2 score : 0.4855840890445592\n",
      "Epoch = 827 : Training loss = 2276.909489635552, R2 score : 0.438760306422747\n",
      "Epoch = 828 : Training loss = 2280.689305892408, R2 score : 0.4807391027777841\n",
      "Epoch = 829 : Training loss = 2271.9161335549907, R2 score : 0.47855813215331555\n",
      "Epoch = 830 : Training loss = 2257.125234477234, R2 score : 0.43014465868949503\n",
      "Epoch = 831 : Training loss = 2310.966496949153, R2 score : 0.5560783273164669\n",
      "Epoch = 832 : Training loss = 2235.543193349989, R2 score : 0.4455874041478919\n",
      "Epoch = 833 : Training loss = 2252.732805275762, R2 score : 0.40777675030838556\n",
      "Epoch = 834 : Training loss = 2221.5878938567994, R2 score : 0.43732169881950755\n",
      "Epoch = 835 : Training loss = 2263.1563381838864, R2 score : 0.3570612661266127\n",
      "Epoch = 836 : Training loss = 2253.719932975626, R2 score : 0.41864731385460685\n",
      "Epoch = 837 : Training loss = 2239.984926209802, R2 score : 0.36456725722190364\n",
      "Epoch = 838 : Training loss = 2259.280354379688, R2 score : 0.44364984249054884\n",
      "Epoch = 839 : Training loss = 2257.921583601472, R2 score : 0.4816428693708067\n",
      "Epoch = 840 : Training loss = 2223.760918066485, R2 score : 0.5114803146239819\n",
      "Epoch = 841 : Training loss = 2263.6413923132445, R2 score : 0.5131155044343487\n",
      "Epoch = 842 : Training loss = 2196.5258101513828, R2 score : 0.4675708170835895\n",
      "Epoch = 843 : Training loss = 2281.454907903209, R2 score : 0.30302771057520583\n",
      "Epoch = 844 : Training loss = 2205.8859690634067, R2 score : 0.43508146308210505\n",
      "Epoch = 845 : Training loss = 2206.39053817438, R2 score : 0.5379938826880308\n",
      "Epoch = 846 : Training loss = 2248.7382540531535, R2 score : 0.4702148567966856\n",
      "Epoch = 847 : Training loss = 2228.682094954562, R2 score : 0.5050073340562986\n",
      "Epoch = 848 : Training loss = 2239.803791282238, R2 score : 0.4228880315628212\n",
      "Epoch = 849 : Training loss = 2242.9779013809057, R2 score : 0.5308921840299223\n",
      "Epoch = 850 : Training loss = 2286.768677065358, R2 score : 0.46593026239579827\n",
      "Epoch = 851 : Training loss = 2257.309254959312, R2 score : 0.31501721168936536\n",
      "Epoch = 852 : Training loss = 2271.4095164763544, R2 score : 0.41640200390432847\n",
      "Epoch = 853 : Training loss = 2248.3956764280747, R2 score : 0.45437787289428455\n",
      "Epoch = 854 : Training loss = 2250.110659660366, R2 score : 0.45197080380910604\n",
      "Epoch = 855 : Training loss = 2222.0362706307606, R2 score : 0.45605781086659436\n",
      "Epoch = 856 : Training loss = 2237.091472545738, R2 score : 0.4315982251435847\n",
      "Epoch = 857 : Training loss = 2227.4620650995375, R2 score : 0.3647191124025728\n",
      "Epoch = 858 : Training loss = 2267.818351261488, R2 score : 0.4650357253348528\n",
      "Epoch = 859 : Training loss = 2204.5334298249477, R2 score : 0.4214177872007242\n",
      "Epoch = 860 : Training loss = 2235.305821986429, R2 score : 0.4769682092191351\n",
      "Epoch = 861 : Training loss = 2274.284860297153, R2 score : 0.47397556309212585\n",
      "Epoch = 862 : Training loss = 2240.643185383049, R2 score : 0.4603398376943446\n",
      "Epoch = 863 : Training loss = 2235.5259170593536, R2 score : 0.4724076948979864\n",
      "Epoch = 864 : Training loss = 2203.6490761156792, R2 score : 0.5027813487450209\n",
      "Epoch = 865 : Training loss = 2260.70768472315, R2 score : 0.4458092731370976\n",
      "Epoch = 866 : Training loss = 2273.310407707559, R2 score : 0.4547591955402942\n",
      "Epoch = 867 : Training loss = 2233.911971375066, R2 score : 0.5093531783497491\n",
      "Epoch = 868 : Training loss = 2228.855226938375, R2 score : 0.4952598949356032\n",
      "Epoch = 869 : Training loss = 2257.277034214333, R2 score : 0.4476987764576654\n",
      "Epoch = 870 : Training loss = 2255.5825991813754, R2 score : 0.5096425249271584\n",
      "Epoch = 871 : Training loss = 2252.3658890834586, R2 score : 0.4781404232815981\n",
      "Epoch = 872 : Training loss = 2233.5063312105167, R2 score : 0.3525117768874203\n",
      "Epoch = 873 : Training loss = 2274.551873712578, R2 score : 0.5013025994214748\n",
      "Epoch = 874 : Training loss = 2280.764760398375, R2 score : 0.406973631497735\n",
      "Epoch = 875 : Training loss = 2238.3348627969467, R2 score : 0.5048513975824894\n",
      "Epoch = 876 : Training loss = 2216.498573462868, R2 score : 0.5009645860025489\n",
      "Epoch = 877 : Training loss = 2259.917535226249, R2 score : 0.5197281223478774\n",
      "Epoch = 878 : Training loss = 2203.933205578942, R2 score : 0.5247765214113844\n",
      "Epoch = 879 : Training loss = 2234.8703207678345, R2 score : 0.43522829109595873\n",
      "Epoch = 880 : Training loss = 2317.861515168909, R2 score : 0.3532883048236428\n",
      "Epoch = 881 : Training loss = 2270.3313144487884, R2 score : 0.4295332055964233\n",
      "Epoch = 882 : Training loss = 2223.734729126649, R2 score : 0.4476284665780972\n",
      "Epoch = 883 : Training loss = 2208.078143199125, R2 score : 0.4948397331726848\n",
      "Epoch = 884 : Training loss = 2223.8615390827244, R2 score : 0.40664127308928055\n",
      "Epoch = 885 : Training loss = 2240.8815680013477, R2 score : 0.530775555798896\n",
      "Epoch = 886 : Training loss = 2222.4982690140137, R2 score : 0.4486241124857807\n",
      "Epoch = 887 : Training loss = 2296.921732602255, R2 score : 0.4337358318342076\n",
      "Epoch = 888 : Training loss = 2199.7315073114905, R2 score : 0.45682913890374577\n",
      "Epoch = 889 : Training loss = 2234.5165394357073, R2 score : 0.43253739034884287\n",
      "Epoch = 890 : Training loss = 2243.2555068032243, R2 score : 0.33617890484348256\n",
      "Epoch = 891 : Training loss = 2238.6297964677206, R2 score : 0.43182070978161446\n",
      "Epoch = 892 : Training loss = 2230.188377194864, R2 score : 0.4865726660577647\n",
      "Epoch = 893 : Training loss = 2199.747859325255, R2 score : 0.38844473687380787\n",
      "Epoch = 894 : Training loss = 2201.7011262892997, R2 score : 0.44164657183241696\n",
      "Epoch = 895 : Training loss = 2275.138744228173, R2 score : 0.3335481099069252\n",
      "Epoch = 896 : Training loss = 2212.599150890922, R2 score : 0.5556771885637319\n",
      "Epoch = 897 : Training loss = 2269.6955231349257, R2 score : 0.5591644045227357\n",
      "Epoch = 898 : Training loss = 2245.764042873521, R2 score : 0.5799514377230741\n",
      "Epoch = 899 : Training loss = 2195.2730230536354, R2 score : 0.45408261071857825\n",
      "Epoch = 900 : Training loss = 2216.2986411461134, R2 score : 0.3968128438400259\n",
      "Epoch = 901 : Training loss = 2205.399836766259, R2 score : 0.3912476113521709\n",
      "Epoch = 902 : Training loss = 2189.559703624138, R2 score : 0.4830879693460084\n",
      "Epoch = 903 : Training loss = 2200.8900910676152, R2 score : 0.4552657103598443\n",
      "Epoch = 904 : Training loss = 2227.3456409916857, R2 score : 0.5261899440430893\n",
      "Epoch = 905 : Training loss = 2260.0447241161814, R2 score : 0.5170997572097416\n",
      "Epoch = 906 : Training loss = 2200.7621081373063, R2 score : 0.4084257922000929\n",
      "Epoch = 907 : Training loss = 2221.8202815601985, R2 score : 0.4348308215773885\n",
      "Epoch = 908 : Training loss = 2197.38258009636, R2 score : 0.4881503727693811\n",
      "Epoch = 909 : Training loss = 2195.4789640444988, R2 score : 0.5053867981364261\n",
      "Epoch = 910 : Training loss = 2240.0595449441216, R2 score : 0.40193878123850246\n",
      "Epoch = 911 : Training loss = 2187.7168653477074, R2 score : 0.503727365069912\n",
      "Epoch = 912 : Training loss = 2242.295990566474, R2 score : 0.33011562902468505\n",
      "Epoch = 913 : Training loss = 2188.709088388089, R2 score : 0.36414102473285936\n",
      "Epoch = 914 : Training loss = 2250.2698815543163, R2 score : 0.49029351634405793\n",
      "Epoch = 915 : Training loss = 2281.003490602351, R2 score : 0.4344341025899551\n",
      "Epoch = 916 : Training loss = 2259.065658842526, R2 score : 0.3287931355427719\n",
      "Epoch = 917 : Training loss = 2185.684593493873, R2 score : 0.4927433115786374\n",
      "Epoch = 918 : Training loss = 2199.7993091109006, R2 score : 0.4810215831149478\n",
      "Epoch = 919 : Training loss = 2241.1731732549597, R2 score : 0.40693548144628156\n",
      "Epoch = 920 : Training loss = 2192.682512830839, R2 score : 0.4794286860199217\n",
      "Epoch = 921 : Training loss = 2193.8492165026846, R2 score : 0.3827872947779818\n",
      "Epoch = 922 : Training loss = 2200.4583841327094, R2 score : 0.4051511591724831\n",
      "Epoch = 923 : Training loss = 2233.8078043458963, R2 score : 0.37711875563802255\n",
      "Epoch = 924 : Training loss = 2201.2265227314247, R2 score : 0.4026601165934537\n",
      "Epoch = 925 : Training loss = 2245.6392793338505, R2 score : 0.4944643723655382\n",
      "Epoch = 926 : Training loss = 2196.2532877901563, R2 score : 0.47734640892456726\n",
      "Epoch = 927 : Training loss = 2206.391605510907, R2 score : 0.47903839058235875\n",
      "Epoch = 928 : Training loss = 2171.73761968141, R2 score : 0.4354927478348485\n",
      "Epoch = 929 : Training loss = 2183.4557734898353, R2 score : 0.4625458959271743\n",
      "Epoch = 930 : Training loss = 2187.616152003253, R2 score : 0.4686369565013885\n",
      "Epoch = 931 : Training loss = 2207.3460568647506, R2 score : 0.4695060260775077\n",
      "Epoch = 932 : Training loss = 2201.8067936304715, R2 score : 0.4566088258599238\n",
      "Epoch = 933 : Training loss = 2227.058972040876, R2 score : 0.39519065285914945\n",
      "Epoch = 934 : Training loss = 2210.4867955452128, R2 score : 0.3437875085110891\n",
      "Epoch = 935 : Training loss = 2191.6398502341135, R2 score : 0.5142078948183773\n",
      "Epoch = 936 : Training loss = 2175.498412039665, R2 score : 0.4156393460772021\n",
      "Epoch = 937 : Training loss = 2252.9759000406907, R2 score : 0.5551067159944552\n",
      "Epoch = 938 : Training loss = 2288.8278995452456, R2 score : 0.4357314446765661\n",
      "Epoch = 939 : Training loss = 2221.4310574885567, R2 score : 0.367894887825265\n",
      "Epoch = 940 : Training loss = 2216.460410811331, R2 score : 0.4626010290080831\n",
      "Epoch = 941 : Training loss = 2184.241814930071, R2 score : 0.3944663493233248\n",
      "Epoch = 942 : Training loss = 2230.2258152558616, R2 score : 0.4680368778110169\n",
      "Epoch = 943 : Training loss = 2198.1638174833734, R2 score : 0.505218217319845\n",
      "Epoch = 944 : Training loss = 2178.4202426510965, R2 score : 0.4528549897355235\n",
      "Epoch = 945 : Training loss = 2195.405259879698, R2 score : 0.4395342903247219\n",
      "Epoch = 946 : Training loss = 2179.4631345856537, R2 score : 0.39768315648518293\n",
      "Epoch = 947 : Training loss = 2197.6152201178584, R2 score : 0.38604391874895616\n",
      "Epoch = 948 : Training loss = 2220.3870356994476, R2 score : 0.5433524004750856\n",
      "Epoch = 949 : Training loss = 2167.2141528957814, R2 score : 0.5187922541911033\n",
      "Epoch = 950 : Training loss = 2213.6816352836368, R2 score : 0.48958032841412114\n",
      "Epoch = 951 : Training loss = 2150.2482564861343, R2 score : 0.42903296126286095\n",
      "Epoch = 952 : Training loss = 2210.2340118278144, R2 score : 0.4497283097495137\n",
      "Epoch = 953 : Training loss = 2211.993610222683, R2 score : 0.44545793586400195\n",
      "Epoch = 954 : Training loss = 2180.990849683223, R2 score : 0.42933103956980123\n",
      "Epoch = 955 : Training loss = 2208.891473511614, R2 score : 0.4736212137677357\n",
      "Epoch = 956 : Training loss = 2216.499067386224, R2 score : 0.38605900140726546\n",
      "Epoch = 957 : Training loss = 2217.3005873884226, R2 score : 0.5073180446298811\n",
      "Epoch = 958 : Training loss = 2200.249150767022, R2 score : 0.48918833491939406\n",
      "Epoch = 959 : Training loss = 2174.4893715903495, R2 score : 0.45518627039654336\n",
      "Epoch = 960 : Training loss = 2181.014667867301, R2 score : 0.44194450381707506\n",
      "Epoch = 961 : Training loss = 2188.652502161267, R2 score : 0.43798918590528957\n",
      "Epoch = 962 : Training loss = 2212.029473460798, R2 score : 0.42403764583871095\n",
      "Epoch = 963 : Training loss = 2199.555751085645, R2 score : 0.48167207538138246\n",
      "Epoch = 964 : Training loss = 2176.4419152536293, R2 score : 0.43527953926350516\n",
      "Epoch = 965 : Training loss = 2201.2403079542187, R2 score : 0.5401932187516647\n",
      "Epoch = 966 : Training loss = 2241.815847217569, R2 score : 0.38361203408996514\n",
      "Epoch = 967 : Training loss = 2186.3906236983103, R2 score : 0.4599453777120477\n",
      "Epoch = 968 : Training loss = 2161.583806434144, R2 score : 0.5078582036575001\n",
      "Epoch = 969 : Training loss = 2163.3542347306457, R2 score : 0.4598277466569095\n",
      "Epoch = 970 : Training loss = 2215.3963173940947, R2 score : 0.3605265357614347\n",
      "Epoch = 971 : Training loss = 2191.087937820992, R2 score : 0.48834536203083423\n",
      "Epoch = 972 : Training loss = 2174.470027343272, R2 score : 0.4991108746288394\n",
      "Epoch = 973 : Training loss = 2202.840756153959, R2 score : 0.5254688095495101\n",
      "Epoch = 974 : Training loss = 2176.0106324722483, R2 score : 0.3867728170364523\n",
      "Epoch = 975 : Training loss = 2223.3730525884876, R2 score : 0.3352506345657794\n",
      "Epoch = 976 : Training loss = 2173.7626056372283, R2 score : 0.37222784303168444\n",
      "Epoch = 977 : Training loss = 2226.8075626697982, R2 score : 0.4245204399492313\n",
      "Epoch = 978 : Training loss = 2209.5217496215664, R2 score : 0.3970613261995516\n",
      "Epoch = 979 : Training loss = 2195.1308289644317, R2 score : 0.38031059069846707\n",
      "Epoch = 980 : Training loss = 2240.6113313595965, R2 score : 0.46918694874732925\n",
      "Epoch = 981 : Training loss = 2207.8740131955956, R2 score : 0.4582543894256407\n",
      "Epoch = 982 : Training loss = 2151.5860516032935, R2 score : 0.47508332331851777\n",
      "Epoch = 983 : Training loss = 2173.7380200400175, R2 score : 0.4715732566946793\n",
      "Epoch = 984 : Training loss = 2218.8366510681935, R2 score : 0.45286708895339756\n",
      "Epoch = 985 : Training loss = 2221.3646272439064, R2 score : 0.4069222026340388\n",
      "Epoch = 986 : Training loss = 2179.897550268143, R2 score : 0.4295330450803928\n",
      "Epoch = 987 : Training loss = 2204.877101071264, R2 score : 0.5277860033172537\n",
      "Epoch = 988 : Training loss = 2165.989725081923, R2 score : 0.4579132672485028\n",
      "Epoch = 989 : Training loss = 2150.099922358876, R2 score : 0.4296434366295173\n",
      "Epoch = 990 : Training loss = 2171.2117553679573, R2 score : 0.3738334311080044\n",
      "Epoch = 991 : Training loss = 2165.0223047602904, R2 score : 0.4971591258304957\n",
      "Epoch = 992 : Training loss = 2159.782006079801, R2 score : 0.5095907722899258\n",
      "Epoch = 993 : Training loss = 2195.2734621673067, R2 score : 0.5071173894144303\n",
      "Epoch = 994 : Training loss = 2197.6020603963316, R2 score : 0.44506637052396936\n",
      "Epoch = 995 : Training loss = 2154.511371984499, R2 score : 0.37077708977248514\n",
      "Epoch = 996 : Training loss = 2169.2809015233997, R2 score : 0.30965720028953225\n",
      "Epoch = 997 : Training loss = 2148.218685675374, R2 score : 0.44525357466252624\n",
      "Epoch = 998 : Training loss = 2160.5038457518053, R2 score : 0.4921524709523485\n",
      "Epoch = 999 : Training loss = 2197.130340094872, R2 score : 0.5457213224388469\n",
      "Epoch = 1000 : Training loss = 2153.5897408789338, R2 score : 0.5128168260518953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5128168260518953"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = permutedims(X_train_scaled)                    # shape: features × samples\n",
    "y = reshape(y_train_scaled, size(y_train_scaled, 2), :)                  # shape: 1 × samples\n",
    "\n",
    "m = Flux.Chain(\n",
    "    Flux.Dense(size(X_train_scaled, 2), 1000, relu),\n",
    "    Flux.Dense(1000, size(y, 1))\n",
    ")\n",
    "\n",
    "# track parameters\n",
    "θ = Flux.params(m)\n",
    "# select an optimizer\n",
    "α = 0.001\n",
    "opt = ADAM(α)\n",
    "\n",
    "\n",
    "loss(x, y) = sum((m(x) .- y).^2)\n",
    "#Flux.Losses.mae(m(x), y)\n",
    "loss_fn(m, x, y) = sum((m(x) .- y).^2) #Flux.mae(m(x), y) \n",
    "\n",
    "train_loader = Flux.DataLoader((x, y), batchsize=32, shuffle=true)\n",
    "opt_state = Flux.setup(opt, m)\n",
    "\n",
    "for epoch in 1:1000\n",
    "    # train the model\n",
    "    for (x_batch, y_batch) in train_loader\n",
    "        current_loss, grads = Flux.withgradient(m) do m_in_grad\n",
    "            loss_fn(m_in_grad, x_batch, y_batch)\n",
    "        end\n",
    "        Flux.update!(opt_state, m, grads[1])\n",
    "    end\n",
    "\n",
    "    # print report\n",
    "    ŷ = m(permutedims(X_test_scaled))\n",
    "    ŷ_rescaled = permutedims(ŷ) .* σy .+ μy\n",
    "    r2 = P2H_CapacityExpansion.r2_score(y_test, ŷ_rescaled)\n",
    "    \n",
    "    println(\"Epoch = $epoch : Training loss = $(loss(x, y)), R2 score : $(r2)\")\n",
    "    #push!(r2_list, r2)\n",
    "    #push!(losses, loss(x, y))\n",
    "end \n",
    "ŷ = m(permutedims(X_test_scaled))\n",
    "ŷ_rescaled = permutedims(ŷ) .* σy .+ μy\n",
    "r2 = P2H_CapacityExpansion.r2_score(y_test, ŷ_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "config = P2H_CapacityExpansion.read_yaml_file();\n",
    "data = P2H_CapacityExpansion.load_cep_data(config=config);\n",
    "ts_data = P2H_CapacityExpansion.load_timeseries_data_full(config=config);\n",
    "gas_gen = [gen for (gen, props) ∈ config[\"techs\"] if haskey(props, \"input\") && get(props[\"input\"], \"fuel\", nothing) == \"R_Gas\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data for linear regression\n",
    "x = permutedims(X_train_scaled)  \n",
    "y = reshape(y_train_scaled, size(y_train_scaled, 2), :) \n",
    "\n",
    "# define model architecture\n",
    "\n",
    "model = Flux.Chain(\n",
    "    Flux.Dense(size(X_train_scaled, 2), 1000, relu),\n",
    "    Flux.Dense(1000, size(y, 1)),\n",
    "    softmax\n",
    ")\n",
    "\n",
    "# define loss function\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss(x, y) = sum((model(x) .- y).^2)\n",
    "\n",
    "# track parameters\n",
    "\n",
    "ps = Flux.params(model)\n",
    "\n",
    "opt = ADAM(0.0001)\n",
    "\n",
    "# train model\n",
    "\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in 1:100\n",
    "    # train model\n",
    "    Flux.train!(loss, ps, [(x, y)], opt)\n",
    "    # print report\n",
    "    train_loss = loss(x, y)\n",
    "\n",
    "    ŷ = model(permutedims(X_test_scaled))\n",
    "    ŷ_rescaled = permutedims(ŷ) .* σy .+ μy\n",
    "    r2 = P2H_CapacityExpansion.r2_score(y_test, ŷ_rescaled)\n",
    "\n",
    "    println(\"Epoch = $epoch : Training Loss = $train_loss, R2 score : $(r2)\")\n",
    "end\n",
    "\n",
    "ŷ = model(permutedims(X_test_scaled))\n",
    "ŷ_rescaled = permutedims(ŷ) .* σy .+ μy\n",
    "r2 = P2H_CapacityExpansion.r2_score(y_test, ŷ_rescaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load input\n",
    "using Ipopt, MathOptAI, PyCall\n",
    "config = P2H_CapacityExpansion.read_yaml_file();\n",
    "data = P2H_CapacityExpansion.load_cep_data(config=config);\n",
    "ts_data = P2H_CapacityExpansion.load_timeseries_data_full(config=config);\n",
    "\n",
    "cep = P2H_CapacityExpansion.run_opt(ts_data=ts_data, data=data, config=config, surrogate=true, solver=Ipopt.Optimizer)\n",
    "\n",
    "optimizer = optimizer_with_attributes(\n",
    "    Ipopt.Optimizer,\n",
    "    \"max_iter\" => 10000,  # or higher\n",
    "    \"tol\" => 1e-5,\n",
    "    \"print_level\" => 5,\n",
    ")\n",
    "\n",
    "set_optimizer(cep.model, optimizer)\n",
    "\n",
    "@unpack 𝓖, 𝓨, 𝓣, 𝓡, 𝓢, 𝓛, 𝓒 = P2H_CapacityExpansion.get_sets(cep=cep)\n",
    "data = data.data;\n",
    "\n",
    "##################### cost optimization #####################\n",
    "\n",
    "P2H_CapacityExpansion.setup_opt_costs_fix!(cep, config, data,vcat(cep.sets[\"non_dispatch\"], cep.sets[\"dispatch\"], 𝓢, String[s for s in cep.sets[\"discharging\"]], cep.sets[\"conversion\"]))\n",
    "\n",
    "#JuMP.fix.(cep.model[:COST][\"var\", :, :], 0; force=true);\n",
    "@variable(cep.model, COST_VAR[y ∈ 𝓨] ≥ 0);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "techs = [f for f ∈ cep.sets[\"invest_tech\"] if f != \"ENS\"]\n",
    "\n",
    "for y ∈ 𝓨, r ∈ 𝓡\n",
    "    x_vec = [cep.model[:TotalCapacityAnnual][r, g, y] for g ∈ techs]\n",
    "    prediction, formulation = MathOptAI.add_predictor(cep.model, m, x_vec)\n",
    "    println(prediction[2])\n",
    "    #@constraint(cep.model, COST_VAR[y] .>= prediction)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate though the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = Dict(\n",
    "    \"RandomForest\" => P2H_CapacityExpansion.random_forest_sklearn,\n",
    "    \"DecisionTree\" => P2H_CapacityExpansion.decision_tree_sklearn,\n",
    "    \"LinearRegression\" => P2H_CapacityExpansion.linear_regression_sklearn,\n",
    "    \"NeuralNetwork\" => P2H_CapacityExpansion.simple_neural_network_sklearn,\n",
    "    \"GaussianProcesses\" => P2H_CapacityExpansion.gaussian_process,\n",
    "    \"SVR\" => P2H_CapacityExpansion.svr_sklearn,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function kmeans_subset(X, n)\n",
    "    R = kmeans(Matrix(X)', n) \n",
    "    idx = [findfirst(==(i), R.assignments) for i in 1:n]\n",
    "    return idx\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stochastic_models = Set([\"RandomForest\", \"NeuralNetwork\", \"DecisionTree\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "step_size = 100\n",
    "df_full = DataFrame(Method=String[],  Value=Float64[], Size=Int[]);\n",
    "n_runs = 3\n",
    "\n",
    "for n ∈ 100:step_size:size(df_raw)[1] \n",
    "    \n",
    "    # clustering the entire subspace to identify n samples\n",
    "    idx = kmeans_subset(select(df_raw, Not(:Cost)), n)\n",
    "    df = df_raw[idx,:]\n",
    "\n",
    "    ### split the data into test and training ###\n",
    "    X_train, y_train, X_test, y_test = P2H_CapacityExpansion.partitionTrainTest(df, [:Cost, :Emission, :Generation], 0.8)\n",
    "\n",
    "    ### scale the data ###\n",
    "    X_train_scaled, μX, σX  = P2H_CapacityExpansion.scaling(X_train)\n",
    "    X_test_scaled = (X_test .- μX) ./ σX\n",
    "    y_train_scaled, μy, σy  = P2H_CapacityExpansion.scaling(y_train)\n",
    "    \n",
    "    # remove np.nan #\n",
    "    for i in eachindex(X_test_scaled)\n",
    "        if isnan(X_test_scaled[i])\n",
    "            X_test_scaled[i] = 0.0\n",
    "        end\n",
    "    end\n",
    "\n",
    "    ### train ML model and compute R2 ### \n",
    "    for (name, fun) ∈ models\n",
    "        # determine average for non-deterministic models\n",
    "        iter = name ∈ stochastic_models ? n_runs : 1\n",
    "        \n",
    "        r2 = 0\n",
    "        for k ∈ 1:iter\n",
    "            sg = fun(X_train_scaled, y_train_scaled, X_test_scaled)\n",
    "            ŷ_rescaled = sg.prediction .* σy .+ μy\n",
    "            r2 += P2H_CapacityExpansion.r2_score(y_test, ŷ_rescaled)\n",
    "\n",
    "            ### save the model ###\n",
    "            if n == last(100:step_size:size(df_raw)[1]) && k == iter\n",
    "                model = sg.model\n",
    "                # assume model is trained with ScikitLearn.jl\n",
    "                joblib.dump(model[:model], \"$(dir)$(name).pkl\")\n",
    "            end\n",
    "        end\n",
    "\n",
    "        ### add to the df ### \n",
    "        push!(df_full, (Method = name, Value = r2/iter, Size = size(X_train)[1]))\n",
    "    end \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "X_train, y_train, X_test, y_test = P2H_CapacityExpansion.partitionTrainTest(df_raw, [:Cost, :Emission, :Generation], 0.8)\n",
    "Matrix(DataFrames.dropmissing(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = AbstractTrace[]  # Correct type for individual traces\n",
    "sort!(df_full, [:Method, :Size], rev=true)\n",
    "\n",
    "for m in unique(df_full.Method)\n",
    "    subdf = filter(:Method => ==(m), df_full)\n",
    "    trace = scatter(\n",
    "        x = subdf.Size,\n",
    "        y = subdf.Value,\n",
    "        mode = \"lines+markers\",\n",
    "        name = string(m)\n",
    "    )\n",
    "    push!(traces, trace)\n",
    "end\n",
    "\n",
    "# Define the layout\n",
    "layout = Layout(\n",
    "    title = \"Value vs Size by Method\",\n",
    "    xaxis_title = \"Training Data\",\n",
    "    yaxis_title = \"Accuracy\"\n",
    ")\n",
    "\n",
    "# Create a single Plot from traces and layout\n",
    "plt = plot(traces, layout)\n",
    "\n",
    "# Show the plot\n",
    "display(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-sampling strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = filter(f -> endswith(f, \".txt\"), readdir(dir, join=true));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 50\n",
    "df_full = DataFrame(Method=String[],  Value=Float64[], Size=Int[]);\n",
    "\n",
    "\n",
    "### ALTERNATIVE 1: RANDOM SAMPLING ### \n",
    "for n in 140:step_size:size(df_raw)[1] #unique(ceil(Int, size(df_raw)[1]/n) for n in 140:step_size:size(df_raw)[1])\n",
    "    df = df_raw[StatsBase.sample(1:nrow(df_raw), n; replace=false), :]\n",
    "end\n",
    "\n",
    "### ALTERNATIVE 2: EQUAL SELECTION SAMPLING ### \n",
    "for n in unique(ceil(Int, size(df_raw)[1]/n) for n in 140:step_size:size(df_raw)[1])\n",
    "    df = df_raw[1:n:end, :]\n",
    "    df = select(df, names(df)[[sum(df[!, col]) != 0 for col in names(df)]])\n",
    "end\n",
    "\n",
    "### ALTERNATIVE 3: LHS ### \n",
    "for f in files_list\n",
    "    df = P2H_CapacityExpansion.read_txt_file(f)\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read, normalize and transpose the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = P2H_CapacityExpansion.read_txt_file(file);\n",
    "df_raw = select(df_raw, Not(:Cost))\n",
    "m = Matrix(df_raw)\n",
    "x_norm, μ, σ = P2H_CapacityExpansion.scaling(m)\n",
    "X = x_norm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate PCA model\n",
    "model = fit(PCA, X; maxoutdim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose the data back again \n",
    "X_transform = MultivariateStats.transform(model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca =   DataFrame(permutedims(X_transform), :auto)\n",
    "df_pca.Cost = df_raw.Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.reddit.com/r/deeplearning/comments/14vnfe8/how_to_decrease_high_loss_values/\n",
    "https://discourse.julialang.org/t/how-to-efficiently-and-precisely-fit-a-function-with-neural-networks/73726\n",
    "https://stackoverflow.com/questions/59153248/why-is-my-neural-network-stuck-at-high-loss-value-after-the-first-epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = DataFrame(Method=String[],  Value=Float64[], Size=Int[]);\n",
    "\n",
    "df = P2H_CapacityExpansion.read_txt_file(file);\n",
    "\n",
    "### split the data into test and training ###\n",
    "X_train, y_train, X_test, y_test = P2H_CapacityExpansion.partitionTrainTest(df, :Cost, 0.7)\n",
    "\n",
    "### scale the data ###\n",
    "X_train_scaled, μX, σX  = P2H_CapacityExpansion.scaling(X_train)\n",
    "X_test_scaled = (X_test .- μX) ./ σX\n",
    "\n",
    "    # remove np.nan #\n",
    "for i in eachindex(X_test_scaled)\n",
    "    if isnan(X_test_scaled[i])\n",
    "        X_test_scaled[i] = 0.0\n",
    "    end\n",
    "end\n",
    "y_train_scaled, μy, σy  = P2H_CapacityExpansion.scaling(y_train)\n",
    "\n",
    "### train ML model and compute R2 ### \n",
    "for (name,fun) ∈ models\n",
    "    sg = fun(X_train_scaled, y_train_scaled, X_test_scaled)\n",
    "    ŷ_rescaled = sg.prediction .* σy .+ μy\n",
    "    r2 = P2H_CapacityExpansion.r2_score(y_test, ŷ_rescaled)\n",
    "\n",
    "    ### add to the df ### \n",
    "    push!(df_full, (Method = name, Value = r2, Size = size(X_train)[1]))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = DataFrame(Method=String[],  Value=Float64[], Size=Int[]);\n",
    "\n",
    "df = df_pca\n",
    "\n",
    "### split the data into test and training ###\n",
    "X_train, y_train, X_test, y_test = P2H_CapacityExpansion.partitionTrainTest(df, :Cost, 0.7)\n",
    "\n",
    "### scale the data ###\n",
    "X_train_scaled, μX, σX  = P2H_CapacityExpansion.scaling(X_train)\n",
    "X_test_scaled = (X_test .- μX) ./ σX\n",
    "\n",
    "# remove np.nan #\n",
    "for i in eachindex(X_test_scaled)\n",
    "    if isnan(X_test_scaled[i])\n",
    "        X_test_scaled[i] = 0.0\n",
    "    end\n",
    "end\n",
    "y_train_scaled, μy, σy  = P2H_CapacityExpansion.scaling(y_train)\n",
    "\n",
    "### train ML model and compute R2 ### \n",
    "for (name,fun) ∈ models\n",
    "    sg = fun(X_train_scaled, y_train_scaled, X_test_scaled)\n",
    "    ŷ_rescaled = sg.prediction .* σy .+ μy\n",
    "    r2 = P2H_CapacityExpansion.r2_score(y_test, ŷ_rescaled)\n",
    "\n",
    "    ### add to the df ### \n",
    "    push!(df_full, (Method = name, Value = r2, Size = size(X_train)[1]))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new sampling technique\n",
    "iterate more often through the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Loop through files with index\n",
    "\n",
    "# Parameters\n",
    "techs = setdiff([key for (key, val) ∈ config[\"techs\"] if get(val, \"inv\", \"\")  == true], [key for (key, val) ∈ config[\"techs\"] if get(val, \"tech_group\", \"\")  == \"transmission\"] ) \n",
    "years = config[\"year\"]\n",
    "scenarios = 1:length(txt_files)\n",
    "\n",
    "# Column names\n",
    "columns = [:scenario, :year, :cost] ∪ Symbol.(techs)\n",
    "\n",
    "df = DataFrame(;\n",
    "    :scenario => repeat(scenarios, inner=length(years)),\n",
    "    :year => repeat(years, outer=length(txt_files)),\n",
    "    :cost => fill(0.0, length(txt_files)*length(years)),\n",
    ")\n",
    "\n",
    "# Add technology columns, initialized to 0.0\n",
    "for tech in techs\n",
    "    df[!, Symbol(tech)] = fill(0.0, length(txt_files)*length(years))\n",
    "end\n",
    "\n",
    "## fill in the values\n",
    "for file in txt_files\n",
    "    lines = readlines(file)\n",
    "    \n",
    "    i = parse(Int64, split(split(file, \"/\")[end], \"_\")[1])\n",
    "\n",
    "    # Parse technology capacities\n",
    "    for line in lines\n",
    "        if occursin(\"TotalCapacityAnnual\", line)\n",
    "            g = split(line, \",\")[2]   \n",
    "            if g in techs\n",
    "                val = parse(Float64, strip(split(line, \"=\")[2]))\n",
    "                y = parse(Int64, split(split(line, \"]\")[1], \",\")[end])\n",
    "\n",
    "                # insert into the dataframe\n",
    "                idx = findfirst((df.year .== y) .& (df.scenario .== i))\n",
    "                df[idx, Symbol(g)] = val\n",
    "            end\n",
    "\n",
    "        \n",
    "        elseif occursin(\"COSTvar\", line)\n",
    "            y = parse(Int64, line[8:12])\n",
    "            val = parse(Float64, strip(split(line, \"=\")[2]))\n",
    "            # insert into the dataframe\n",
    "            idx = findfirst((df.year .== y) .& (df.scenario .== i))\n",
    "            df[idx, :cost] = val\n",
    "        end\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df[:, Not(:year, :cost, :scenario)]\n",
    "X = transpose(Matrix(df_agg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ub = [1.25, 620, 460, 300, 0.06, 0.93, 20]\n",
    "lb = [0.75, 420, 260, 100, 0.015, 0.56, 13]\n",
    "\n",
    "\n",
    "# Number of samples\n",
    "n = 3\n",
    "\n",
    "# Latin Hypercube Sampling\n",
    "scenarios = Surrogates.sample(n,lb,ub, Surrogates.LatinHypercubeSample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TRAIN THE MODEL #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function perclass_splits(y, percent)\n",
    "    uniq_class = unique(y)\n",
    "    keep_index = []\n",
    "    for class in uniq_class\n",
    "        class_index = findall(y .== class)\n",
    "        row_index = randsubseq(class_index, percent)\n",
    "        push!(keep_index, row_index...)\n",
    "    end\n",
    "    return keep_index\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[!, :cost]\n",
    "\n",
    "# split data between train and test\n",
    "Random.seed!(1)\n",
    "train_index = perclass_splits(y, 0.67)\n",
    "test_index = setdiff(1:length(y), train_index)\n",
    "\n",
    "# spit features\n",
    "X_train = X[:, train_index]\n",
    "X_test = X[:, test_index]\n",
    "\n",
    "# split classes\n",
    "y_train = transpose(Array{Float64}(y[train_index]))\n",
    "y_test = transpose(Array{Float64}(y[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain(\n",
    "    Dense(12, 32, relu),\n",
    "    Dense(32, 1)  # output: a single float\n",
    ")\n",
    "\n",
    "loss(x, y) = Flux.Losses.mse(model(x), y)  # or Flux.Losses.mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track parameters\n",
    "ps = Flux.params(model)\n",
    " # select an optimizer\n",
    "learning_rate = 0.01\n",
    "opt = ADAM(learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "loss_history = []\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "for epoch in 1:epochs\n",
    "    # train the model\n",
    "    train!(loss, ps, [(X_train, y_train)], opt)\n",
    "    # print report\n",
    "    train_loss = loss(X_train, y_train)\n",
    "    push!(loss_history, train_loss)\n",
    "    println(\"Epoch = $epoch : Training loss = $train_loss\")\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a combined scenario-year column\n",
    "df_long[!, :scenario_year] = string.(df_long.scenario, \"_\", df_long.year)\n",
    "\n",
    "# Step 2: Pivot wide: rows = technology, columns = scenario_year, values = value\n",
    "df_wide = unstack(df_long, :technology, :scenario_year, :value)\n",
    "\n",
    "# Show the result as a matrix\n",
    "X = Matrix(df_wide[:, Not(:technology)])\n",
    "X = coalesce.(X, 0.0)\n",
    "#https://medium.com/@mandarangchekar7/a-neural-network-explained-and-implemented-in-julia-1fbfe4aaf0df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_hat_raw = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = onecold(y_hat_raw) .- 1\n",
    "y = y_test_raw\n",
    "mean(y_hat .== y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
